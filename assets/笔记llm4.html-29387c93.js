import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as i,c as l,a as e,b as n,d as a,f as s}from"./app-80a5df51.js";const c={},h=e("p",null,"在前两篇笔记中，笔者记录了早些年的部分指令微调模型，他们大多数使用大规模的，多种类的公开数据集进行训练。在接下来的笔记中，我们会对 LLaMa 系列的一些指令微调模型进行整理，包括 Alpaca, Vicuna, WizardLM, WizardVicunaLM 等。",-1),p={href:"https://zhuanlan.zhihu.com/p/616830127",target:"_blank",rel:"noopener noreferrer"},u={href:"https://zhuanlan.zhihu.com/p/617302168",target:"_blank",rel:"noopener noreferrer"},d=e("h2",{id:"instructgpt",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#instructgpt","aria-hidden":"true"},"#"),n(),e("strong",null,"InstructGPT")],-1),_={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2203.02155",target:"_blank",rel:"noopener noreferrer"},m={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E5%AF%B9%E9%BD%90%E8%AE%AD%E7%BB%83&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},g=e("p",null,"相比于人工收集数据，以下的几个模型都选择使用 GPT-4 来代替人工，生成模型的训练数据集。",-1),b=e("h2",{id:"alpaca",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#alpaca","aria-hidden":"true"},"#"),n(),e("strong",null,"Alpaca")],-1),f={href:"https://link.zhihu.com/?target=https%3A//github.com/tatsu-lab/stanford_alpaca",target:"_blank",rel:"noopener noreferrer"},v=e("strong",null,"数据：",-1),k={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2212.10560",target:"_blank",rel:"noopener noreferrer"},y={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=2&q=instruction+tuning&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},z=s(`<div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">You are asked to come up with a set of 20 diverse task instructions. These task instructions will be given to a GPT model and we will evaluate the GPT model for completing the instructions.</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">Here are the requirements:</span></span>
<span class="line"><span style="color:#24292e;">1. Try not to repeat the verb for each instruction to maximize diversity.</span></span>
<span class="line"><span style="color:#24292e;">2. The language used for the instruction also should be diverse. For example, you should combine questions with imperative instructions.</span></span>
<span class="line"><span style="color:#24292e;">... 这里会有一些其他的限制</span></span>
<span class="line"><span style="color:#24292e;">9. The output should be an appropriate response to the instruction and the input. Make sure the output is less than 100 words.</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">List of 20 tasks:</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">###</span></span>
<span class="line"><span style="color:#24292e;">1. Instruction: Is there anything I can eat for a breakfast that doesn&#39;t include eggs, yet includes protein, and has roughly 700-1000 calories?</span></span>
<span class="line"><span style="color:#24292e;">1. Inputs: &lt;noinput&gt;</span></span>
<span class="line"><span style="color:#24292e;">1. Output: Yes, you can have 1 oatmeal banana protein shake and 4 strips of bacon. The oatmeal banana protein shake may contain 1/2 cup oatmeal, 60 grams whey protein powder, 1/2 medium banana, 1tbsp flaxseed oil and 1/2 cup water, totalling about 550 calories. The 4 strips of bacon contains about 200 calories.</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">###</span></span>
<span class="line"><span style="color:#24292e;">2. Instruction: Generate an appropriate subjective title for the following email:</span></span>
<span class="line"><span style="color:#24292e;">2. Inputs: Hi [person name],I&#39;m writing to ask you if you are happy to be a panelist of our workshop on multimodality at CVPR. The workshop will be held on June 20, 2023. \\n\\nBest,\\n[my name]</span></span>
<span class="line"><span style="color:#24292e;">2. Output: Invitition to be a panelist for CVPR 2023 workshop on Multimodality</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">### </span></span>
<span class="line"><span style="color:#24292e;">3. Instruction: </span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上述 prompt 模板中，只给了两个案例（在 self-instruct 中称为 qa_seed），实际上 Alpaca 默认的配置是使用 4 个 seed example 来尝试生成 16 个任务。</p><p>基于以上的 prompt，每次发送 OPENAI API 请求后，GPT-4 或者 gpt-turbo-3.5 会续写 10+ 个相关的新任务和输出。</p>`,3),A=e("strong",null,"训练：",-1),L={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E5%85%A8%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},M=e("code",null,"CasualLM",-1),P={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=epoch&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},B=e("strong",null,"效果：",-1),T={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard",target:"_blank",rel:"noopener noreferrer"},w={href:"https://link.zhihu.com/?target=https%3A//chat.lmsys.org/%3Farena",target:"_blank",rel:"noopener noreferrer"},G=e("strong",null,"其他：",-1),x={href:"https://link.zhihu.com/?target=https%3A//github.com/tloen/alpaca-lora",target:"_blank",rel:"noopener noreferrer"},E=e("h2",{id:"vicuna",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#vicuna","aria-hidden":"true"},"#"),n(),e("strong",null,"Vicuna")],-1),V={href:"https://link.zhihu.com/?target=https%3A//github.com/lm-sys/FastChat/tree/main",target:"_blank",rel:"noopener noreferrer"},W=e("strong",null,"数据：",-1),I={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered",target:"_blank",rel:"noopener noreferrer"},q={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2306.05685.pdf",target:"_blank",rel:"noopener noreferrer"},F=e("strong",null,"训练：",-1),C={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1604.06174",target:"_blank",rel:"noopener noreferrer"},S={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2205.14135",target:"_blank",rel:"noopener noreferrer"},H=s(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">human: Who are you?</span></span>
<span class="line"><span style="color:#032F62;">assistant: I am Vicuna, a language model trained by researchers from Large Model Systems Organization (LMSYS).</span></span>
<span class="line"><span style="color:#032F62;">human: What can you do?</span></span>
<span class="line"><span style="color:#032F62;">assistant: I can chat with you.</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),N={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},O=e("strong",null,"效果：",-1),R={href:"https://link.zhihu.com/?target=https%3A//chat.lmsys.org/%3Farena",target:"_blank",rel:"noopener noreferrer"},U=e("strong",null,"其他：",-1),Y={href:"https://link.zhihu.com/?target=https%3A//chat.lmsys.org/%3Farena",target:"_blank",rel:"noopener noreferrer"},D={href:"https://link.zhihu.com/?target=https%3A//github.com/lm-sys/FastChat/tree/main%23api",target:"_blank",rel:"noopener noreferrer"},Q={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},j={href:"https://link.zhihu.com/?target=https%3A//github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge",target:"_blank",rel:"noopener noreferrer"},K=e("h2",{id:"wizardlm",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#wizardlm","aria-hidden":"true"},"#"),n(),e("strong",null,"WizardLM")],-1),X={href:"https://link.zhihu.com/?target=https%3A//github.com/nlpxucan/WizardLM",target:"_blank",rel:"noopener noreferrer"},J=e("strong",null,"数据：",-1),Z={href:"https://link.zhihu.com/?target=https%3A//github.com/nlpxucan/evol-instruct",target:"_blank",rel:"noopener noreferrer"},$={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k",target:"_blank",rel:"noopener noreferrer"},ee=s(`<div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">I want you act as a Prompt Rewriter. Your objective is to rewrite a given prompt into a more complex version to make those famous AI systems (e.g., ChatGPT and GPT4) a bit harder to handle. </span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">But the rewritten prompt must be reasonable and must be understood and responded by humans. </span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">Your rewriting cannot omit the non-text parts such as the table and code in #Given Prompt#:. Also, please do not omit the input in #Given Prompt#. You SHOULD complicate the given prompt using the following method: </span></span>
<span class="line"><span style="color:#24292e;">If #Given Prompt# contains inquiries about certain issues, the depth and breadth of the inquiry can be increased. </span></span>
<span class="line"><span style="color:#24292e;">or You should try your best not to make the #Rewritten Prompt# become verbose, #Rewritten Prompt# can only add 10 to 20 words into #Given Prompt#. </span></span>
<span class="line"><span style="color:#24292e;">‘#Given Prompt#’, ‘#Rewritten Prompt#’, ‘given prompt’ and ‘rewritten prompt’ are not allowed to appear in #Rewritten Prompt# #Given Prompt#: </span></span>
<span class="line"><span style="color:#24292e;">&lt;Here is instruction.&gt; </span></span>
<span class="line"><span style="color:#24292e;">#Rewritten Prompt#:</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),ne=e("strong",null,"训练：",-1),te={href:"https://link.zhihu.com/?target=https%3A//github.com/AetherCortex/Llama-X/tree/main",target:"_blank",rel:"noopener noreferrer"},ae=e("p",null,[e("strong",null,"效果："),n(" 官方指标对比了 GPT-4 评测分数，MMLU，ARC 等指标。根据官方提供的评测数据，同参数量级的 WizardLM 会和 Vicuna 效果差不多。")],-1),se={href:"https://zhuanlan.zhihu.com/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",target:"_blank",rel:"noopener noreferrer"},re=e("h2",{id:"wizardvicunalm",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#wizardvicunalm","aria-hidden":"true"},"#"),n(),e("strong",null,"WizardVicunaLM")],-1),oe={href:"https://link.zhihu.com/?target=https%3A//github.com/melodysdreamj/WizardVicunaLM",target:"_blank",rel:"noopener noreferrer"},ie=e("strong",null,"数据：",-1),le={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/junelee/wizard_vicuna_70k",target:"_blank",rel:"noopener noreferrer"},ce={href:"https://link.zhihu.com/?target=https%3A//sharegpt.com/c/6cmxqq0",target:"_blank",rel:"noopener noreferrer"},he=e("ul",null,[e("li",null,"先用 WizardLM 提出的 evol-instruct 生成单论对话数据集。"),e("li",null,"而后将生成的单论对话填充到下列模板中，生成多轮对话数据：")],-1),pe=e("blockquote",{A:"",answer:"",generated:"",by:"","evol-instruct":""},[e("p",null,"Here is an example of chatgpt answering a question from human. Create 10 more conversations where human asks a question and chatgpt answers. The entire generated sentence should be more then 20000 words and should continue the theme of the first conversation. Think about the intention of the human asking the question in the first conversation and make sure that the conversation is connected by the human asking the next question. Especially when generating human conversations, try to ask difficult questions in a way that requires strong reasoning, deduction, induction, and analogy, and chatgpt gives appropriate answers. The format should be human: chatgpt:"),e("p",null,"human: { A question generated by evol-instruct} chatgpt:")],-1),ue=e("ul",null,[e("li",null,"使用规则对对话数据集进行筛选。")],-1),de=e("strong",null,"训练：",-1),_e={href:"https://link.zhihu.com/?target=https%3A//github.com/lm-sys/FastChat/blob/main/scripts/train_vicuna_13b.sh",target:"_blank",rel:"noopener noreferrer"},me=e("p",null,[e("strong",null,"效果："),n(" WizardVicunaLM 在官方仓库中给出了 GPT-4 打分的测评结果，根据该结果，WizardVicunaLM 的效果会比 WizardLM 和 Vicuna 好一点点。")],-1),ge={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",target:"_blank",rel:"noopener noreferrer"},be={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored",target:"_blank",rel:"noopener noreferrer"},fe=e("h2",{id:"guanaco",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#guanaco","aria-hidden":"true"},"#"),n(" Guanaco")],-1),ve={href:"https://link.zhihu.com/?target=https%3A//github.com/artidoro/qlora",target:"_blank",rel:"noopener noreferrer"},ke=e("strong",null,"数据：",-1),ye={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/timdettmers/openassistant-guanaco",target:"_blank",rel:"noopener noreferrer"},ze={href:"https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/OpenAssistant/oasst1",target:"_blank",rel:"noopener noreferrer"},Ae=e("p",null,[e("strong",null,"训练："),n(" Guanaco 的亮点在于训练，其使用了")],-1),Le=e("li",null,"4-bit NormalFloat：对正态分布数据理论上最优的量化数据类型，它比 4 位整数和 4 位浮点数有更好的实验结果",-1),Me=e("li",null,"Double Quantization：量化量化常数的方法，平均每个参数节省约 0.37 位（对于 65B 模型大约节省 3GB）",-1),Pe={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},Be={href:"https://zhida.zhihu.com/search?content_id=231228206&content_type=Article&match_order=1&q=%E5%86%85%E5%AD%98%E5%B3%B0%E5%80%BC&zhida_source=entity",target:"_blank",rel:"noopener noreferrer"},Te={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2305.14314",target:"_blank",rel:"noopener noreferrer"},we={href:"https://zhuanlan.zhihu.com/p/634256206",target:"_blank",rel:"noopener noreferrer"},Ge=e("p",null,[e("strong",null,"效果："),n(" Guanaco 官方并没有在仓库中展示 Guanaco 的任何评测指标，但根据 Chat Arena 和 Huggingface LLM LeaderBoard，使用 QLora 技术训练的模型，在效果上还是不错的。")],-1),xe=e("h2",{id:"小结",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#小结","aria-hidden":"true"},"#"),n(" 小结")],-1),Ee=e("p",null,"除 InstructGPT 外，以上的几个都是基于 LLaMa 训练。羊驼大家族在 LLM 中的发展也是比较好的，从部署到训练，资源齐全。在后续的笔记中，笔者会对其他 LLaMa 系列模型的训练方式、数据、效果等继续进行记录与对比。",-1);function Ve(We,Ie){const t=o("ExternalLinkIcon");return i(),l("div",null,[h,e("p",null,[e("a",p,[n("笔记 - Instruction Tuning 时代的模型 83 赞同 · 6 评论文章"),a(t)])]),e("p",null,[e("a",u,[n("笔记 - Instruction Tuning 时代的模型 (二)44 赞同 · 1 评论文章"),a(t)])]),d,e("p",null,[n("在 ChatGPT 刚出来时，不少网文宣称 ChatGPT 使用的技术就是 "),e("a",_,[n("InstructGPT"),a(t)]),n("。印象中 InstructGPT 论文提出时大概是 21 年底至 2022 年初，当时 instruction tuning 的一系列模型，如 FLAN，T0，Zero-Prompt，FLAN-T5 等，大多主张在大规模的，多种类的公开数据集上进行指令微调。InstructGPT 的数据集是人工标注的，并且对数据质量要求高。此外，InstructGPT 还使用了 RLHF 对模型进行"),e("a",m,[n("对齐训练"),a(t)]),n("。")]),g,b,e("p",null,[e("a",f,[n("standford_alpaca"),a(t)]),n(" 对 LLaMa 进行了微调，并尝试使用 self-instruct 方法对 gpt-turbo-3.5 进行蒸馏学习。")]),e("p",null,[v,n(" Alpaca 修改了 "),e("a",k,[n("self-instruct"),a(t)]),n(" 提供的方案，并使用 OPENAI API 生成了 52k 的 "),e("a",y,[n("instruction tuning"),a(t)]),n(" 数据集，共花费 $500。Alpaca 的 self-instruct 方案相对简单一些，大致使用的 prompt 为：")]),z,e("p",null,[A,n(" 基于 LLaMa 7B 和 13B 进行了"),e("a",L,[n("全参数微调"),a(t)]),n("，优化目标和传统的 "),M,n(" 优化目标一样。微调总共训练 3 个 "),e("a",P,[n("epoch"),a(t)]),n("，在 8 个 80 GB A100 上面训练 3 个小时。")]),e("p",null,[B,n(" 官方仓库中并没有很严谨的评判，仅让 5 位裁判员根据几个示例样本来对 Alpaca，llama 还有 text-davinci-003 进行打分。参考 "),e("a",T,[n("HF LLM Leaderboard"),a(t)]),n(" 还有 "),e("a",w,[n("chat Arena"),a(t)]),n("，Alpaca 相对 LLaMa 的提升还是有限。")]),e("p",null,[G,n(" Alpaca 推出后，后许多根据 Alpaca 修改的高效微调方案，比如 Alpaca-lora，Alpaca-Adapter 等等。根据笔者的尝试，采用 "),e("a",x,[n("Alpaca-Lora"),a(t)]),n(" 微调后的模型，就人为的对话体验上来看，还是和 gpt-turbo-3.5 差距很大。对于不同类型的指令任务，回复质量差异大。")]),E,e("p",null,[e("a",V,[n("vicuna"),a(t)]),n(" 的效果在 Open Source LLM 中数一数二，目前公开了 7B, 13B, 33B 三个版本。经过几个月的更新， vicuna 版本已经升级到了 v1.3。")]),e("p",null,[W,n(" vicuna 数据来源于 shareGPT 的用户多轮对话数据，vicuna v0 对"),e("a",I,[n("原始 ShareGPT 的对话数据集"),a(t)]),n(" 进行了清洗，筛选了约 70k 数据进行训练。（在 v1.3 中，训练数据集达到了 140k，具体查看 "),e("a",q,[n("paper"),a(t)]),n("）")]),e("p",null,[F,n(" 训练时采用了 "),e("a",C,[n("gradient checkpointing"),a(t)]),n(" 和 "),e("a",S,[n("flash attention"),a(t)]),n(" 降低了训练设备的要求。同时对多轮对话内容进行训练，如以下的对话：")]),H,e("p",null,[n("优化 loss 时，mask 掉 human 部分的 token，仅对所有 assistant 部分的 token 对应的 logits 计算 loss 并进行"),e("a",N,[n("反向传播"),a(t)]),n("优化，优化目标与传统 CasualLM 优化目标相同。")]),e("p",null,[O,n(" LMSYS 使用 GPT-4 作为裁判，设计了让模型和模型之间 PK 的测评方式，并依据这种方式设计了类似排位赛的 "),e("a",R,[n("Chat arena"),a(t)]),n(" （分数相当的模型相互 PK，胜者加分，败者掉分）。参考 LMSYS 发布的这个排行榜，Vicuna 的效果会比 Koala, MPT 等大多数开源模型好。")]),e("p",null,[U,n(" 除了 Vicuna 模型和 "),e("a",Y,[n("Chat arena"),a(t)]),n(" ，LMSYS 还提供了部署 LLM 服务的方式："),e("a",D,[n("FastChat API"),a(t)]),n("，但目前他们的 API 并未对"),e("a",Q,[n("模型推理"),a(t)]),n("做太多优化，推理速度会有点慢。除此外，FastChat 中还提供了 "),e("a",j,[n("MT-Bench 指标"),a(t)]),n("，针对模型进行多轮对话效果测试。")]),K,e("p",null,[n("参考各种排行榜，"),e("a",X,[n("wizardLM"),a(t)]),n(" 的效果和 Vicuna 差不多，但 WizardLM 更侧重于单论对话的指令任务，vicuna 更侧重于多轮对话任务。")]),e("p",null,[J,n(" WizardLM 通过 "),e("a",Z,[n("evol-instruct"),a(t)]),n(" 方法，对 alpaca 的 self-instruct 数据集进行了优化（修改了使用 GPT4 生成样本时候的 prompt，让训练样本变得更复杂），整个 "),e("a",$,[n("evol-instruct 数据"),a(t)]),n("集共 196k。以下是一个 evol-instrcut 使用到的 prompt template，更多的 prompt template 再 WizardLM 论文附录中可以查看到。")]),ee,e("p",null,[ne,n(" WizardLM 使用 "),e("a",te,[n("LLaMa-X"),a(t)]),n(" 仓库提供的代码进行训练，对 LLaMa 7B 和 13B 进行了微调。除了训练时对工程化做了一些优化，超参做了调整，其余训练流程与 Alpaca、vicuna 相同。")]),ae,e("p",null,[n("Wizard 仓库还开源了 WizardCoder 等模型，是基于 Startcoder 进行训练的，主打代码能力的模型。此外，笔者对几个开源的 Wizard 模型进行了 MMLU 测试（"),e("a",se,[n("TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ"),a(t)]),n("，），分数都低地奇怪，只有 35+，不确定是什么原因。")]),re,e("p",null,[e("a",oe,[n("WizardVicunaLM"),a(t)]),n(" 考虑到 WizardLM 数据集是单轮对话，于是将 WizardLM 和 Vicuna 的方法整合到了一起。实现了对论对话 + 更复杂的 instruction 任务训练。")]),e("p",null,[ie,n(" 官方公开了"),e("a",le,[n("WizardVicuna 数据集"),a(t)]),n("，共 70k。笔者并未找到官方生成训练数据的代码，但根据官方提供的 "),e("a",ce,[n("ShareGPT 对话内容"),a(t)]),n(" 以及 github 描述，可以猜测数据生成步骤大致如下：")]),he,pe,ue,e("p",null,[de,n(" 训练 13B LLaMa 模型，在 8 个 A100 上训练 35 小时。使用的 "),e("a",_e,[n("Vicuna 的训练代码"),a(t)]),n("。")]),me,e("p",null,[n("笔者体验了 "),e("a",ge,[n("Wizard-Vicuna-30B-Uncensored-GPTQ"),a(t)]),n(" 及 "),e("a",be,[n("Wizard-Vicuna-7B-Uncensored"),a(t)]),n(" 两个模型，就代码助手（代码续写、备注转代码、代码解释）、笔记助手（表述优化、内容扩展、自动续写）两个任务来说，WizardVicunaLM 在使用体验上与 Vicuna 没有多大差别。")]),fe,e("p",null,[n("Guanaco 来自于 "),e("a",ve,[n("QLora"),a(t)]),n("，基于 LLaMa 模型，对 7B, 13B, 33B 和 65B 集中型号的模型进行了训练和探索。而其中的 QLora 技术似乎比 Guanaco 模型本身更出名，它使得我们能够在消费级别的显卡上，微调一个 33B 的模型。")]),e("p",null,[ke,n(" Guanaco 使用了 oasst1 数据集的一个子集进行训练，整个数据约 9k，数据集可以在 "),e("a",ye,[n("Huggingface"),a(t)]),n(" 查看到。不同于前几个模型，"),e("a",ze,[n("oasst1"),a(t)]),n(" 由 OpenAssistant 公开，是一个人工制造的数据集，包含了约 84k 的样本，不少开源的 LLM 使用了 oasst1 来训练。")]),Ae,e("ul",null,[Le,Me,e("li",null,[n("Paged Optimizers：使用 NVIDIA"),e("a",Pe,[n("统一内存"),a(t)]),n("来避免处理具有长序列长度的小批量时出现的梯度检查点"),e("a",Be,[n("内存峰值"),a(t)]),n("。能够减少 GPU 显存的峰值，对大模型（33B 以上）的训练很有帮助。")])]),e("p",null,[n("具体细节可以查看 "),e("a",Te,[n("paper"),a(t)]),n(" 或者"),e("a",we,[n("网友笔记"),a(t)]),n("。")]),Ge,xe,Ee])}const Ce=r(c,[["render",Ve],["__file","笔记llm4.html.vue"]]);export{Ce as default};
