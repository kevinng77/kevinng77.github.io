const t=JSON.parse('{"key":"v-2bc485d9","path":"/posts/notes/articles/%E7%AC%94%E8%AE%B0vit.html","title":"CV 领域 Transformers 相关笔记","lang":"zh-CN","frontmatter":{"title":"CV 领域 Transformers 相关笔记","date":"2022-10-28T00:00:00.000Z","author":"Kevin 吴嘉文","category":["知识笔记"],"tag":["CV"],"mathjax":true,"toc":true,"comments":"笔记","description":"对 CV 领域的 Transformer 相关任务做个小整理。 AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE 不同于 NLP 中的 transformer，ViT 的输入为不同图片的 patch。 如原始图片 224*224，每个 patch 大小为 16*16，那么输入的序列长度为 14*14。 相关图片","head":[["meta",{"property":"og:url","content":"http://wujiawen.xyz/posts/notes/articles/%E7%AC%94%E8%AE%B0vit.html"}],["meta",{"property":"og:site_name","content":"记忆笔书"}],["meta",{"property":"og:title","content":"CV 领域 Transformers 相关笔记"}],["meta",{"property":"og:description","content":"对 CV 领域的 Transformer 相关任务做个小整理。 AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE 不同于 NLP 中的 transformer，ViT 的输入为不同图片的 patch。 如原始图片 224*224，每个 patch 大小为 16*16，那么输入的序列长度为 14*14。 相关图片"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-02-16T10:09:39.000Z"}],["meta",{"property":"article:author","content":"Kevin 吴嘉文"}],["meta",{"property":"article:tag","content":"CV"}],["meta",{"property":"article:published_time","content":"2022-10-28T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-02-16T10:09:39.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CV 领域 Transformers 相关笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-10-28T00:00:00.000Z\\",\\"dateModified\\":\\"2023-02-16T10:09:39.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin 吴嘉文\\"}]}"]]},"headers":[{"level":2,"title":"其他论文","slug":"其他论文","link":"#其他论文","children":[]}],"git":{"createdTime":1676542179000,"updatedTime":1676542179000,"contributors":[{"name":"kevinng77","email":"417333277@qq.com","commits":1}]},"readingTime":{"minutes":4,"words":1200},"filePathRelative":"posts/notes/articles/笔记vit.md","localizedDate":"2022年10月28日","excerpt":"<p>对 CV 领域的 Transformer 相关任务做个小整理。</p>\\n<h4> AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</h4>\\n<p>不同于 NLP 中的 transformer，ViT 的输入为不同图片的 patch。</p>\\n<p>如原始图片 <code>224*224</code>，每个 patch 大小为 <code>16*16</code>，那么输入的序列长度为 <code>14*14</code>。</p>\\n<figure><img src=\\"/assets/img/vit/image-20221028095737332.png\\" alt=\\"相关图片\\" height=\\"300\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>相关图片</figcaption></figure>","autoDesc":true}');export{t as data};
