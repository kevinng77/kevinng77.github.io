import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as p,c as o,a as s,b as a,d as l,f as t}from"./app-ab9a0e9f.js";const r="/assets/img/info_extract2/image-20220909095553098.png",c="/assets/img/info_extract2/image-20220909102200300.png",m="/assets/img/info_extract2/image-20220909153455544.png",h="/assets/img/info_extract2/image-20220909154419258.png",g="/assets/img/info_extract2/image-20221126230558158.png",d="/assets/img/info_extract2/image-20221126202207374.png",u={},y=s("p",null,"本文对 PURE, TPLINKER, GPLINKER, UIE 四篇文章做部分论文笔记与整理。",-1),v=s("h2",{id:"信息抽取论文小述-实体抽取、关系抽取",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#信息抽取论文小述-实体抽取、关系抽取","aria-hidden":"true"},"#"),a(" 信息抽取论文小述|实体抽取、关系抽取")],-1),b=s("h3",{id:"pure",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#pure","aria-hidden":"true"},"#"),a(" PURE")],-1),_={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2010.12812.pdf",target:"_blank",rel:"noopener noreferrer"},f=t('<figure><img src="'+r+'" alt="image-20220909095553098" tabindex="0" loading="lazy"><figcaption>image-20220909095553098</figcaption></figure><p>陈丹琦组提出的 pipeline 方案，在当时击败了其余的 joint 模型，该方案的特点在于：</p><ul><li>文章同样尝试了共享编码器，与不共享编码器的区别。发现 NER 与关系抽取分别采用两个不同的编码器效果会好一点点。</li><li><strong>实验说明了在关系抽取阶段，加入实体的类别信息很重要。</strong></li><li>跨句信息能提高成绩。</li><li>Mitigating Error （信息抽取中的误差传播问题）理论上还是存在，但是文中提出的一些办法都没能很好的解决。</li></ul><p><strong>PURE 模块一：Span-level NER</strong></p><p>在 NER 阶段，使用了传统的 span-level NER，使用以下公式代表一个 span 的 logits：</p>',5),x=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"h"),s("mi",null,"e")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"s"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"s"),s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"r"),s("mi",null,"t")])]),s("mo",{separator:"true"},";"),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"d")])]),s("mo",{separator:"true"},";"),s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"s"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"}," h_e(s_i)=[X_{start};X_{end};\\phi (s_i)] ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"h"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"e")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"s"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"d")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")]")])])])])],-1),E=s("p",null,[a("其中 X 为 span 开头结尾对应的 logits，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\phi(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a(" 为一个长度编码器。及输入一个长度数字，返回一个 embedding。")],-1),k=s("p",null,[a("这种方法需要遍历所有的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("mi",null,"n"),s("mo",null,"+"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("mn",null,"2")]),s("annotation",{encoding:"application/x-tex"},"n(n+1)/2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/2")])])]),a(" 中头尾排列组合。因此文中提出了我们要限制 span 的长度，来减少计算复杂度。")],-1),w=t('<p>限制 span 的方法也很简单，代码中直接对实体进行了截取。即超过一定长度的实体，头的位置不变，尾 span 的位置调整。</p><p><strong>PURE 模块二：关系抽取</strong></p><p>文中的关系抽取，提出了两种方案：</p><p><strong>方案一：</strong> 首先将实体抽取阶段的结果加入到输入句子中。方式是在实体首尾加入 <code>&lt;S:Md&gt;</code> 或者 <code>&lt;O:Md&gt;</code> 标识符。<code>S</code> 表示 subject，<code>Md</code> 表示实体类别。 <strong>文中指出，实体类别能够很大地提高关系抽取的结果。</strong> 预测时使用标识符位置对应的 logits 进行预测。</p><figure><img src="'+c+'" alt="image-20220909102200300" tabindex="0" loading="lazy"><figcaption>image-20220909102200300</figcaption></figure>',5),z={href:"https://zhuanlan.zhihu.com/p/274938894",target:"_blank",rel:"noopener noreferrer"},M=t("<ul><li><strong>TEXT</strong> ：直接提取原始文本中，实体 span 所对应的编码表示。</li><li><strong>TEXTETYPE</strong> ：在 <strong>TEXT</strong> 的基础上，concatenate 实体类别向量。</li><li><strong>MARKERS</strong> ：将标识符 <strong>S、/S、O、/O</strong> 插入到原始文本中，但是标识符没有实体类别信息。</li><li><strong>MARKERSETYPE</strong> ：在 <strong>MARKERS</strong> 的基础上，concatenate 实体类别向量，这是一种隐式的融入实体类别的方法。</li><li><strong>MARKERSELOSS</strong> ：在关系模型中，构建判别实体类别的辅助 loss。</li><li><strong>TYPEDMARKERS</strong> ：就是本文所采取的方法，实体类别“显式”地插入到文本 input 中，如&lt;S:Md&gt; 和&lt;/S:Md&gt;、&lt;O:Md&gt;和&lt;/O:Md&gt;。</li></ul>",1),L=s("p",null,"从图中可以看出，显示的添加实体的类别(TYPEDMARKERS) 比其他操作效果更好。",-1),P=s("p",null,[a("这种方案的一次只能预测一个实体对之间的关系。因此文章提出了一种 "),s("strong",null,"加速方案"),a(" ：")],-1),C=s("p",null,[s("strong",null,"方案二：加速方案")],-1),q=s("p",null,"将所有实体标识符放在句子最后（参考上文中的图），标识符于其代表的实体共享位置向量，上图中的颜色就表示位置向量。",-1),R=s("p",null,"此外，文中的内容 token 只去 attend 文本 token，而标识符可以 attend 所有原文 token。在预测时使用 subject 和 object 头 span 的标识符位置对应的 logits 预测。这种方案加速效果明显，指标仅仅下降了不到 1%。",-1),S=s("h3",{id:"tplinker",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#tplinker","aria-hidden":"true"},"#"),a(" TPLinker")],-1),T={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2010.13415",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/131250208/TPlinker-joint-extraction",target:"_blank",rel:"noopener noreferrer"},F=t('<p>TPlinker 解决了暴露偏差问题，同时也能针对实体重叠，关系重叠的情况。</p><p><strong>编码方案</strong></p><p>TPlinker 数据标注形式如下</p><figure><img src="'+m+'" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>文中采用三种 0/1 矩阵矩阵来实现了标注，</p><ul><li>Entity Head to Entity Tail（紫色）</li><li>Subject Head to Object head；用于判断关系，每种类型的关系使用一个矩阵实现。(红色)</li><li>subject tail to object tail；用于判断关系，每种类型的关系使用一个矩阵实现。（蓝色）</li></ul><p>因此，标注数据一共是 2*R + 1 个矩阵。同时，为了缓解稀疏矩阵计算，对于标注矩阵左下三角的数据，会被转置到右上部分，并且对应的 1 改为 2。</p><p><strong>解码方案</strong></p><figure><img src="'+h+'" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>首先能够通过 EH to ET 的到所有实体，而后遍历每种关系类型的 SH to OH 和 ST to OT 得到三元组结果。如 <code>mayor</code> 关系：对应的三元组结果就是 (New York City, mayor, De Blasio)</p><p><strong>其他</strong></p>',11),D=s("p",null,[a("假设 "),s("code",null,"len_seq=5"),a("在经过 transformer encoder 编码成 "),s("code",null,"[batch_size, 5, hidden_size]"),a(" 后，采用一个 "),s("code",null,"HandshakingKernel"),a(" 对所有 token pair 的排列组合进行编码 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"h"),s("mrow",null,[s("mi",null,"i"),s("mo",{separator:"true"},","),s("mi",null,"j")])]),s("mo",null,"="),s("mi",null,"tanh"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"W"),s("mi",null,"h")]),s("mo",{separator:"true"},"⋅"),s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"h"),s("mi",null,"i")]),s("mo",{separator:"true"},";"),s("msub",null,[s("mi",null,"h"),s("mi",null,"j")]),s("mo",{stretchy:"false"},"]"),s("mo",null,"+"),s("msub",null,[s("mi",null,"b"),s("mi",null,"h")]),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mi",null,"j"),s("mo",null,"≥"),s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"h_{i,j} = \\tanh(W_h·[h_i;h_j] + b_h), j\\ge i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9805em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"h"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0361em","vertical-align":"-0.2861em"}}),s("span",{class:"mop"},"tanh"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"h"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"h"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},"]"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≥"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a("，"),s("code",null,"hidden states"),a(" 形状变成 "),s("code",null,"[batch_size, 5+4+3+2+1, hidden_size]"),a("，最后经过一层 fc，得到如上图（解码方案部分）所示的结果，可以注意到解码方案中，New 占据 7 个格子，而 York 占据 6 个格子，这就是 "),s("code",null,"HandshakingKernel"),a(" 处理出来的格式。")],-1),N=s("h3",{id:"gplinker",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#gplinker","aria-hidden":"true"},"#"),a(" GPLINKER")],-1),j=s("p",null,"参考自：",-1),I={href:"https://spaces.ac.cn/archives/8373",target:"_blank",rel:"noopener noreferrer"},G={href:"https://spaces.ac.cn/archives/8888",target:"_blank",rel:"noopener noreferrer"},O=t(`<p><strong>GlobalPointer</strong> 大致流程为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, inputs):</span></span>
<span class="line"><span style="color:#24292E;">    qw, kw </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dense_q(inputs), </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dense_k(inputs)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># RoPE 相对位置编码</span></span>
<span class="line"><span style="color:#24292E;">    qw, kw </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.add_RoPE(qw), </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.add_RoPE(kw)</span></span>
<span class="line"><span style="color:#24292E;">	</span><span style="color:#6A737D;"># 计算注意力权重</span></span>
<span class="line"><span style="color:#24292E;">    logits </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> paddle.einsum(</span><span style="color:#032F62;">&quot;bmd,bnd-&gt;bmn&quot;</span><span style="color:#24292E;">, qw, kw) </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.head_size</span><span style="color:#D73A49;">**</span><span style="color:#005CC5;">0.5</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 计算每一种实体类别对应 q, k 的 bias</span></span>
<span class="line"><span style="color:#24292E;">    bias </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> paddle.transpose(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.dense2(inputs), [</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]) </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span></span>
<span class="line"><span style="color:#24292E;">    logits </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> logits[:, </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">] </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> bias[:, ::</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">] </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> bias[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">::</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, :, </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># ... （去除 padding 以及下三角部分的数值）</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> logits</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,2),K={href:"https://spaces.ac.cn/archives/7359",target:"_blank",rel:"noopener noreferrer"},U=s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("mi",null,"n"),s("mo",null,"+"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("mn",null,"2")]),s("annotation",{encoding:"application/x-tex"},"n(n+1)/2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/2")])])],-1),X=s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"O"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"O(1)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")")])])],-1),H=s("p",null,[s("strong",null,"GPLinker")],-1),Y=s("p",null,[a("与 TPLinker 的一个较大结构区别是， "),s("strong",null,"GPLinker 采用乘性注意力，而 TPLinker 采用加性注意力。"),a(" 与 TPLinker 相同的，我们可以采用一个 GlobalPointer 来负责实体的预测（但 GPLinker 将头实体与尾实体分开预测），一个负责 SH to OH 的计算，另一个负责 ST to OT 的计算。")],-1),B=s("p",null,[a("在训练阶段使用 GlobalPointer 中提出的多标签分类交叉熵，这也不同于 TPLinker 采用的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("mi",null,"n"),s("mo",null,"+"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("mn",null,"2")]),s("annotation",{encoding:"application/x-tex"},"n(n+1)/2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/2")])])]),a(" 次分类交叉熵。")],-1),J=t('<h3 id="uie" tabindex="-1"><a class="header-anchor" href="#uie" aria-hidden="true">#</a> UIE</h3><p>提出了 text-to-structure 生成任务，将各种信息抽取任务统一进行编码、学习与训练。</p><p><strong>统一输出</strong> SEL</p><p>采用结构化的方式来构建并且区分不同关系抽取中的任务，如：</p><figure><img src="'+g+'" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p><strong>统一输入</strong> SSI</p><figure><img src="'+d+'" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>输入统一构建成以下格式：</p><p><code>[spot] person [spot] company [asso] work for [text] content</code></p><p>其中 <code>[spot] + Entity_type</code> 用来表示想收取的实体类型，<code>[asso] + relation_type</code> 表示想抽取的关系名称。</p><p>不同任务的输入构建方式：</p><ul><li>关系抽取：<code>[spot] person [spot] company [asso] work for [text] content</code></li><li>事件抽取：<code>[spot] 事件类别 [asso] 论元类别 [text]</code> 观点抽取：<code>[spot] 评价维度 [asso] 观点类别 [text]</code></li></ul><p>对于预训练时候 UIE 采用了什么 prompt 进行输入构建，可以参考论文附件。</p><p><strong>进一步的预训练</strong></p><p>UIE 英文版基于 T5 进行了进一步的预训练。</p><p>预训练的优化目标包括：</p>',16),V=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"p"),s("mi",null,"a"),s("mi",null,"i"),s("mi",null,"r")])])]),s("annotation",{encoding:"application/x-tex"},"L_{pair}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"p"),s("span",{class:"mord mathnormal mtight"},"ai"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),a("：通过 Wikipedia 构建统一的结构化输出 SEL 与输入 SSI。采用生成任务进行预测与训练。训练过程中在 SSI prompt 部分加入无关的实体类别，作为负例噪声训练")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"r"),s("mi",null,"e"),s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"d")])])]),s("annotation",{encoding:"application/x-tex"},"L_{record}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"recor"),s("span",{class:"mord mathnormal mtight"},"d")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("：用来学习信息抽取统一输出的结构。采用生成任务对输出结构 SEL 进行预测与训练。")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"x"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"L_{text}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("：Span corruption based MLM.")])],-1),W=t(`<p><strong>微调方式</strong></p><ul><li>微调过程中，在 prompt 处加入部分不存在的实体类型，作为噪声进行训练。</li></ul><p><strong>关于 UIE 代码</strong></p><p>PaddleNLP 中的 UIE 采用的是 <code>ErnieModel</code> ，为 Encoder 架构，使用 Span 标注，通过 MRC 方式统一解决实体抽取，关系抽取，情感分析等任务。此外，在 <code>taskflow/information-extraction</code> 找到了 <code>uie-data-distill-gp</code> 模型，其中采用的是 GPLINKER 架构。</p><p>以下为部分 paddlenlp/taskflow(ErnieModel</p><p>) 使用笔记：</p><p>对于实体抽取，用户 query 格式为列表：<code>[实体类别，实体类别，...]</code>，采用 <code>[cls] + prompt + [sep] + text</code> 的方法构建输入;</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">schema </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#032F62;">&quot;姓名&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;省份&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;城市&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;县区&quot;</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">ie </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Taskflow(</span><span style="color:#032F62;">&quot;information_extraction&quot;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">schema</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">schema)</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">中间过程变量</span></span>
<span class="line"><span style="color:#032F62;">short inputs [{&#39;text&#39;: &#39;北京市海淀区上地十街 10 号 18888888888 张三&#39;, &#39;prompt&#39;: &#39;姓名&#39;}]</span></span>
<span class="line"><span style="color:#032F62;">result_list [[{&#39;text&#39;: &#39;张三&#39;, &#39;start&#39;: 24, &#39;end&#39;: 26, &#39;probability&#39;: 0.9659837822589807}]]</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对于实体抽取，用户 query 格式为字典：<code>{头实体：[尾实体 1， 尾实体 2，...]}</code>。刚方案默认一个头实体与一个尾实体仅存在一种关系。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">schema </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {</span><span style="color:#032F62;">&#39;歌曲名称&#39;</span><span style="color:#24292E;">: [</span><span style="color:#032F62;">&#39;歌手&#39;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;所属专辑&#39;</span><span style="color:#24292E;">]}  </span></span>
<span class="line"><span style="color:#24292E;">ie.set_schema(schema)</span></span>
<span class="line"><span style="color:#24292E;">ie(</span><span style="color:#032F62;">&#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">过程变量</span></span>
<span class="line"><span style="color:#032F62;">short inputs [{&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;歌曲名称&#39;}]</span></span>
<span class="line"><span style="color:#032F62;">result_list [[{&#39;text&#39;: &#39;告别了&#39;, &#39;start&#39;: 1, &#39;end&#39;: 4, &#39;probability&#39;: 0.6296134126625006}, {&#39;text&#39;: &#39;爱的故事&#39;, &#39;start&#39;: 12, &#39;end&#39;: 16, &#39;probability&#39;: 0.28168733127927226}]]</span></span>
<span class="line"><span style="color:#032F62;"># 这里识别错了爱的故事，因此下面就会出现由于 pipeline 流程导致的</span></span>
<span class="line"><span style="color:#032F62;">short inputs [{&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;告别了的歌手&#39;}, {&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;爱的故事的歌手&#39;}]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#032F62;">result_list [[{&#39;text&#39;: &#39;孙耀威&#39;, &#39;start&#39;: 6, &#39;end&#39;: 9, &#39;probability&#39;: 0.9988381005599081}], [{&#39;text&#39;: &#39;孙耀威&#39;, &#39;start&#39;: 6, &#39;end&#39;: 9, &#39;probability&#39;: 0.9951415104192272}]]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#032F62;">examples: [{&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;告别了的所属专辑&#39;}, {&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;爱的故事的所属专辑&#39;}]</span></span>
<span class="line"><span style="color:#032F62;">short inputs [{&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;告别了的所属专辑&#39;}, {&#39;text&#39;: &#39;《告别了》是孙耀威在专辑爱的故事里面的歌曲&#39;, &#39;prompt&#39;: &#39;爱的故事的所属专辑&#39;}]</span></span>
<span class="line"><span style="color:#032F62;">...</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>该方式与训练描述的输入输出格式不同。但 paddlenlp 中模型支持中文，在 T5 没有中文权重的情况下，使用 ERNIE 中文权重应该会更合适。</p>`,11),Q={href:"https://github.com/universal-ie/UIE/blob/main/run_uie_pretrain.py",target:"_blank",rel:"noopener noreferrer"};function Z($,ss){const n=i("ExternalLinkIcon");return p(),o("div",null,[y,v,b,s("p",null,[a("A Frustratingly Easy Approach for Joint Entity and Relation Extraction "),s("a",_,[a("论文链接"),l(n)])]),f,x,E,k,w,s("blockquote",null,[s("p",null,[a("中文版引用于 "),s("a",z,[a("JayJay 知乎"),l(n)]),a("，论文对表格也有详细的解释。")]),M]),L,P,C,q,R,S,s("p",null,[a("《TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking》"),s("a",T,[a("文章链接"),l(n)]),a(),s("a",A,[a("代码链接"),l(n)])]),F,D,N,j,s("p",null,[s("a",I,[a("GlobalPointer：用统一的方式处理嵌套和非嵌套 NER"),l(n)])]),s("p",null,[s("a",G,[a("GPLinker：基于 GlobalPointer 的实体关系联合抽取"),l(n)])]),O,s("p",null,[a("因此 GlobalPointer 可以看做一个加上了 RoPE 相对位置信息的多头注意力机制。笔记特别的是，该论文作者提出采用多标签分类损失函数（参考： "),s("a",K,[a("《将“softmax+交叉熵”推广到多标签分类问题》"),l(n)]),a(" ），代替 "),U,a(" 次二分类，这样解码在并行的情况下能够达到 "),X,a(" 的时间复杂度。并且 GlobalPointer 计算 F1 指标时候，会相对容易很多。")]),H,Y,B,J,V,W,s("p",null,[a("论文官方的源码为： "),s("a",Q,[a("universal-ie/UIE"),l(n)]),a("。输入输出处理方式与论文相同。")])])}const ls=e(u,[["render",Z],["__file","笔记info_extract2.html.vue"]]);export{ls as default};
