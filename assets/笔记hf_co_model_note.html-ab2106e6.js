import{_ as i,P as t,U as o,Y as s,a1 as n,X as l,aQ as a,E as c}from"./framework-6cee4965.js";const p="/assets/img/hf_co_model_note/image-20230618104618316.png",d="/assets/img/hf_co_model_note/image-20230618105000372.png",r="/assets/img/hf_co_model_note/image-20230618105310988.png",u="/assets/img/hf_co_model_note/image-20230618104108012.png",m="/assets/img/hf_co_model_note/image-20230618110257421.png",g={},v=a(`<p>将本地模型训练完后，除了用 huggingface transformers 自带的 <code>push_to_hub</code> 功能之外，我们还可以实用 <code>git lfs</code> 等工具将模型上传到 huggingface.co 上。</p><p>本文对 huggingface 模型上传，下载进行介绍。模型上传成功后，我们就可以使用 transformers 的 <code>from_pretrained()</code> 功能加载我们的模型了，如：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel
model_id <span class="token operator">=</span> <span class="token string">&quot;kevinng77/unsup_bert_L3&quot;</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>

question <span class="token operator">=</span> <span class="token string">&quot;周末玩什么？&quot;</span>
inputs <span class="token operator">=</span> tokenzier<span class="token punctuation">(</span>question<span class="token punctuation">,</span> return_tensor<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="hf-模型上传快速上手" tabindex="-1"><a class="header-anchor" href="#hf-模型上传快速上手" aria-hidden="true">#</a> HF 模型上传快速上手</h2><h3 id="_1-创建账户与仓库" tabindex="-1"><a class="header-anchor" href="#_1-创建账户与仓库" aria-hidden="true">#</a> 1. <strong>创建账户与仓库</strong></h3><p>首先在 huggingface 上注册账户，而后点击用户头像选择添加新模型: <code>+ New Model</code></p><p>同创建 github 仓库一样，选择创建一个用于储存模型的仓库，如 <code>kevinng77/text_to_sql_t5_distill</code></p><figure><img src="`+p+'" alt="HF 用户界面示例" height="300" tabindex="0" loading="lazy"><figcaption>HF 用户界面示例</figcaption></figure><h3 id="_2-链接到你创建的仓库" tabindex="-1"><a class="header-anchor" href="#_2-链接到你创建的仓库" aria-hidden="true">#</a> 2. <strong>链接到你创建的仓库</strong></h3><p>创建仓库后，在仓库主页下，点击 Train 旁边的按钮，选择 clone。</p><figure><img src="'+d+'" alt="HF 模型仓库界面示例" tabindex="0" loading="lazy"><figcaption>HF 模型仓库界面示例</figcaption></figure><p>点击 clone repository 后，复制对应的代码，并在本地上执行。</p><figure><img src="'+r+`" alt="点击 clone repository 后弹出界面" height="300" tabindex="0" loading="lazy"><figcaption>点击 clone repository 后弹出界面</figcaption></figure><p>Huggingface 可以支持用 http 连接（使用该 http 连接时，上传文件需要输入用户和 Access Token），如：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># Make sure you have git-lfs installed (https://git-lfs.com)</span>
<span class="token function">git</span> lfs <span class="token function">install</span>
<span class="token function">git</span> clone https://huggingface.co/kevinng77/text_to_sql_t5_distill

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container info"><p class="hint-container-title">相关信息</p><p>如果没有安装 git lfs，可以用 <code>sudo apt-get install git-lfs</code></p></div><p>也可以用 ssh 链接，用 ssh 的话，需要更换连接地址为：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> lfs <span class="token function">install</span>
<span class="token function">git</span> clone ssh://git@hf.co/kevinng77/text_to_sql_t5_distill
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container warning"><p class="hint-container-title">注意</p><p>用 ssh 时，需要在 huggingface 上传你的 ssh 公钥。</p></div><h3 id="_3-commit-你的文件" tabindex="-1"><a class="header-anchor" href="#_3-commit-你的文件" aria-hidden="true">#</a> 3. commit 你的文件</h3><p>在 <code>git add</code> 你的模型权重之前，请先 track 你要上传的大文件（一般为模型权重）：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> lfs track *.bin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>完成后执行：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span>
<span class="token function">git</span> commit <span class="token parameter variable">-m</span> <span class="token string">&quot;your comments&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-推送到-huggingface-co" tabindex="-1"><a class="header-anchor" href="#_4-推送到-huggingface-co" aria-hidden="true">#</a> 4. 推送到 huggingface.co</h3><div class="hint-container tip"><p class="hint-container-title">提示</p><p>如果你选择通过 HTTP 连接到 huggignface，在 push 时候使用的密码，需要在 huggingface 上生成（settings-&gt;access token-&gt;generate access token），使用默认用户密码是登录不上去的。</p></div><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># git push origin 本机 branch:远端 branch</span>
<span class="token function">git</span> push origin main:main
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-添加-model-card-等信息" tabindex="-1"><a class="header-anchor" href="#_5-添加-model-card-等信息" aria-hidden="true">#</a> 5. 添加 model card 等信息</h3><p>model card 信息统一在 <code>READMD.md</code> 中配置，README 在 huggingface.co 网站上可以很方便地编辑。官方提供了 metadata UI 界面，可以轻松的配置模型的一些信息。</p><figure><img src="`+u+'" alt="metadata UI 示例" tabindex="0" loading="lazy"><figcaption>metadata UI 示例</figcaption></figure><p>以上配置的 metadata，会通过 <code>yaml</code> 的形式添加在 <code>README.md</code> 文件中。</p><p>如下图，如果我们想要配置 Hosted inference API 中的 examples，可以在 <code>README.md</code> 中手动添加一些 yaml 配置。</p><figure><img src="'+m+`" alt="Hosted inference API 示例" tabindex="0" loading="lazy"><figcaption>Hosted inference API 示例</figcaption></figure><p>添加的 yaml 配置示例：</p><div class="language-markdown line-numbers-mode" data-ext="md"><pre class="language-markdown"><code><span class="token front-matter-block"><span class="token punctuation">---</span>
<span class="token front-matter yaml language-yaml"><span class="token key atrule">license</span><span class="token punctuation">:</span> apache<span class="token punctuation">-</span><span class="token number">2.0</span>
<span class="token key atrule">language</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> en
<span class="token key atrule">pipeline_tag</span><span class="token punctuation">:</span> text2text<span class="token punctuation">-</span>generation
<span class="token key atrule">library_name</span><span class="token punctuation">:</span> transformers
<span class="token key atrule">tags</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> text<span class="token punctuation">-</span>generation<span class="token punctuation">-</span>inference
<span class="token key atrule">widget</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">text</span><span class="token punctuation">:</span> <span class="token punctuation">&gt;</span><span class="token scalar string">
    Given a SQL table named &#39;price_data&#39; with the following columns:</span>
    
    Transaction_ID<span class="token punctuation">,</span> Platform<span class="token punctuation">,</span> Product_ID<span class="token punctuation">,</span> User_ID<span class="token punctuation">,</span> Transaction_Amount
    
    <span class="token key atrule">Construct a SQL query to answer the following question</span><span class="token punctuation">:</span>
    
    <span class="token key atrule">Q</span><span class="token punctuation">:</span> How many rows are there

  <span class="token key atrule">example_title</span><span class="token punctuation">:</span> <span class="token string">&quot;How many rows are there?&quot;</span></span>
<span class="token punctuation">---</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="模型权重下载与使用" tabindex="-1"><a class="header-anchor" href="#模型权重下载与使用" aria-hidden="true">#</a> 模型权重下载与使用</h2><h3 id="_1-使用模型" tabindex="-1"><a class="header-anchor" href="#_1-使用模型" aria-hidden="true">#</a> 1. 使用模型</h3>`,37),h=s("code",null,".from_pretrained",-1),k=s("code",null,"git lfs",-1),b={href:"https://huggingface.co/docs/transformers/serialization",target:"_blank",rel:"noopener noreferrer"},f=a(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># transformers==4.29.1</span>

from transformers <span class="token function">import</span> AutoTokenizer, pipeline
from optimum.onnxruntime <span class="token function">import</span> ORTModelForSequenceClassification

onnx_model_path <span class="token operator">=</span> <span class="token string">&quot;kevinng77/unsup_bert_L3&quot;</span>
tokenizer <span class="token operator">=</span> AutoTokenizer.from_pretrained<span class="token punctuation">(</span>onnx_model_path<span class="token punctuation">)</span>

<span class="token comment"># 需要上传 .onnx 模型权重到 huggingface.co 上</span>
onnx_model <span class="token operator">=</span> ORTModelForSequenceClassification.from_pretrained<span class="token punctuation">(</span>onnx_model_path<span class="token punctuation">)</span>
onnx_pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&quot;text-classification&quot;</span>, <span class="token assign-left variable">model</span><span class="token operator">=</span>onnx_model, <span class="token assign-left variable">tokenizer</span><span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>
onnx_pipe<span class="token punctuation">(</span><span class="token string">&quot;How many rows are there in the table?&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-私有权重" tabindex="-1"><a class="header-anchor" href="#_2-私有权重" aria-hidden="true">#</a> 2. 私有权重</h3><p>我们可以将模型仓库设置为 <code>private</code>，这样子别人就不能用我们的模型了。设置成 private 之后，我们需要在本地登录 huggingface cli：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>huggingface-cli login
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>输入用户名以及 <code>Access Token</code>（注意，是 access token，不是登录密码）。登录成功后，在你的 python 文件中修改：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>private_model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> use_auth_token<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
private_tokenizer <span class="token operator">=</span> AutoTokenzier<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> use_auth_token<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-下载权重到本地" tabindex="-1"><a class="header-anchor" href="#_3-下载权重到本地" aria-hidden="true">#</a> 3. 下载权重到本地</h3><p>由于网络问题，我们通常会遇到使用 <code>.from_pretrained()</code> 无法正常加载模型的问题。这时候可以将模型先下载到本地：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> lfs <span class="token function">install</span>
<span class="token function">git</span> clone https://huggingface.co/your_model_id
<span class="token comment"># 如 git clone https://huggingface.co/kevinng77/chat-table-flan-t5</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而后通过 <code>.from_pretrained(模型绝对路径)</code> 的方式加载。</p><h2 id="一些坑" tabindex="-1"><a class="header-anchor" href="#一些坑" aria-hidden="true">#</a> 一些坑</h2><ol><li><p>使用 vscode 终端时，可能出现各种网络问题（如 connection error , SSH 验证错误等），可以尝试使用终端 ssh（不用 vscode 提供的终端）。</p></li><li><p>使用 ssh 时，可能出现 <code>GIT LFS Locking API Error</code>，可以使用通过暂时移除 lfs lock verify 来解决：</p></li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># Remote &quot;origin&quot; does not support the Git LFS locking API. Consider disabling it with:</span>
<span class="token function">git</span> config lfs.https://hf.co/kevinng77/text_to_sql_t5_distill.git/info/lfs.locksverify <span class="token boolean">false</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li><p>在通过 <code>git clone https://huggingface.co/xxx</code> 时，出现 <code>git-lfs filter-process failed</code> 错误。参考 https://github.com/git-lfs/git-lfs/issues/911：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># Skip smudge - We&#39;ll download binary files later in a faster batch</span>
<span class="token function">git</span> lfs <span class="token function">install</span> --skip-smudge

<span class="token comment"># Do git clone here</span>
<span class="token comment"># 这一步不会下载 lfs 文件</span>
<span class="token function">git</span> clone <span class="token punctuation">..</span>.

<span class="token comment"># Fetch all the binary files in the new clone</span>
<span class="token comment"># 单独下载 lfs 文件</span>
<span class="token function">git</span> lfs pull

<span class="token comment"># Reinstate smudge</span>
<span class="token function">git</span> lfs <span class="token function">install</span> <span class="token parameter variable">--force</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果在 <code>git lfs pull</code> 遇到了 <code>git config credential.helper manager</code> 等 credential 问题，可以使用：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> config credential.helper manager
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>或者</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> config <span class="token parameter variable">--global</span> credential.helper cache
<span class="token function">git</span> config <span class="token parameter variable">--global</span> crendential.helper wincred
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li></ol>`,14);function _(x,y){const e=c("ExternalLinkIcon");return t(),o("div",null,[v,s("p",null,[n("模型上传到 huggingface 之后，通过 transformers 的 "),h,n(" 可以直接拉取模型并使用。当然，huggingface.co 储存模型的本质是使用 "),k,n("，因此我们可以在 huggingface.co 上保存其他类型的模型，如 paddle, onnx, tensorflow 等等。至于加载非 huggingface 模型的方式，需要参考各个模型其对应的文档了。如使用 onnx 的话，参考 "),s("a",b,[n("HF: export to ONNX"),l(e)]),n(" 。以下为加载 Onnx 模型示例：")]),f])}const w=i(g,[["render",_],["__file","笔记hf_co_model_note.html.vue"]]);export{w as default};
