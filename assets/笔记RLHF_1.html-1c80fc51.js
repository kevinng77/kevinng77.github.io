import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{r as m,o as i,c as p,a as s,b as a,d as n,f as l}from"./app-c5365da1.js";const r="/assets/img/RLHF_1/image-20240719230353939.png",c="/assets/img/RLHF_1/image-20240719230405060.png",o="/assets/img/RLHF_1/image-20240719230411435.png",h="/assets/img/RLHF_1/image-20240719230416285.png",g="/assets/img/RLHF_1/image-20240719230422436.png",u="/assets/img/RLHF_1/image-20240719230427373.png",d="/assets/img/RLHF_1/image-20240719230431134.png",y="/assets/img/RLHF_1/image-20240719230436786.png",v="/assets/img/RLHF_1/image-20240720110600132.png",b={},f=s("h1",{id:"强化学习与-rlhf",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#强化学习与-rlhf","aria-hidden":"true"},"#"),a(" 强化学习与 RLHF")],-1),x={href:"https://huggingface.co/learn/deep-rl-course/unit0/introduction",target:"_blank",rel:"noopener noreferrer"},w=l('<h2 id="强化学习基础" tabindex="-1"><a class="header-anchor" href="#强化学习基础" aria-hidden="true">#</a> 强化学习基础</h2><p>信息来源：https://huggingface.co/learn/deep-rl-course/unit1/introduction</p><p>强化学习是一种通过行动进行学习的计算方法。我们构建一个代理（agent），通过与环境的交互，试错并接收奖励（正奖励或负奖励）作为反馈，从而学习。RL 的目标是最大化代理的期望累计奖励（也称为期望回报），因为 RL 基于奖励假设，即所有目标都可以描述为期望累计奖励的最大化。</p><p>为了解决 RL 问题，我们需要找到一个最优策略。策略是代理的“大脑”，它会告诉我们给定一个状态时应该采取哪个行动。最优策略是能够给出最大化期望回报的行动的策略。</p><p>有两种方法可以找到最优策略：直接训练策略的基于策略的方法和使用值函数来定义策略的基于值的方法。</p><figure><img src="'+r+'" alt="image-20240719230353939" tabindex="0" loading="lazy"><figcaption>image-20240719230353939</figcaption></figure><p>最基础的 RL 是以上这种循环，</p><p>我们的代理从环境中接收到状态 S0，我们接收到游戏的第一个画面（环境）。</p><p>基于该状态 S0，代理采取行动 A0——我们的代理将向右移动。</p><p>环境进入新的状态 S1——新画面。</p><p>环境给代理一些奖励 R1——我们没有死亡（正向奖励+1）。</p><h3 id="奖励与折现" tabindex="-1"><a class="header-anchor" href="#奖励与折现" aria-hidden="true">#</a> 奖励与折现</h3><p>在强化学习（Reinforcement Learning, RL）中，奖励是代理（agent）与环境（environment）交互过程中获得的唯一反馈。为了考虑到奖励的时间价值以及未来奖励的不确定性，我们通常会对未来的奖励进行折现处理。折现累计奖励的公式如下：</p>',13),_=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"G"),s("mi",null,"t")]),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"2")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"3")])]),s("mo",null,"+"),s("mo",null,"…"),s("mo",null,"="),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"="),s("mn",null,"0")]),s("mi",{mathvariant:"normal"},"∞")]),s("msup",null,[s("mi",null,"γ"),s("mi",null,"k")]),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"}," G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\ldots = \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"G"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0724em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.3669em"}}),s("span",{class:"minner"},"…"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9535em","vertical-align":"-1.3021em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8479em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"0")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"∞")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3021em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])])])],-1),z=s("p",null,[a("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ")]),s("annotation",{encoding:"application/x-tex"},"\\gamma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ")])])]),a(" 为 discount rate, "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a(" 为一系列连续的 state 和 action。")],-1),k=l('<h3 id="探索与利用的权衡" tabindex="-1"><a class="header-anchor" href="#探索与利用的权衡" aria-hidden="true">#</a> 探索与利用的权衡</h3><p>在 RL 中，探索（exploration）与利用（exploitation）是一个核心问题。探索指的是代理尝试新的行动以获取关于环境的信息，而利用则是代理根据已有的信息选择当前认为最优的行动。探索与利用的权衡是指在不确定的环境中，代理如何在获取新信息与利用现有信息之间做出平衡。</p><h3 id="任务类型" tabindex="-1"><a class="header-anchor" href="#任务类型" aria-hidden="true">#</a> 任务类型</h3><p>RL 中的任务可以分为两大类：情节性任务（episodic tasks）和连续性任务（continuing tasks）。情节性任务有明确的开始和结束，例如一盘游戏或一个棋局。而连续性任务没有明确的结束，代理需要在无限的时间内不断与环境交互，例如自动驾驶或机器人控制。</p><h3 id="策略" tabindex="-1"><a class="header-anchor" href="#策略" aria-hidden="true">#</a> 策略</h3><p>策略（policy）是强化学习中的一个核心概念，它定义了代理在给定状态下应该采取的行动。我们的目标是找到最优策略（optimal policy），即能够最大化期望累计奖励的策略。</p><h3 id="基于策略的方法" tabindex="-1"><a class="header-anchor" href="#基于策略的方法" aria-hidden="true">#</a> 基于策略的方法</h3><p>基于策略的方法（policy-based methods）直接学习策略函数，即学习一个从状态到行动概率分布的映射。这种方法的核心是策略梯度（policy gradient）算法，它通过调整策略参数来最大化期望回报。</p><h3 id="基于值的方法" tabindex="-1"><a class="header-anchor" href="#基于值的方法" aria-hidden="true">#</a> 基于值的方法</h3><p>基于值的方法（value-based methods）不是直接学习策略，而是学习一个值函数（value function），该函数评估一个状态（或状态-行动对）的长期价值。基于值的方法的典型代表是 Q 学习（Q-learning）和深度 Q 网络（Deep Q-Network, DQN），它们通过学习行动值函数来指导代理选择最优行动。</p><h2 id="强化学习进阶-q-学习与深度-q-网络-dqn" tabindex="-1"><a class="header-anchor" href="#强化学习进阶-q-学习与深度-q-网络-dqn" aria-hidden="true">#</a> 强化学习进阶：Q 学习与深度 Q 网络（DQN）</h2><h3 id="q-learning" tabindex="-1"><a class="header-anchor" href="#q-learning" aria-hidden="true">#</a> Q Learning</h3><blockquote><p>Q Learning 有点像，先尝试，然后观察环境给出的经验，最后从经验中总结和学习，更新我们的决策。</p><p>资料来源：https://huggingface.co/learn/deep-rl-course/unit2/introduction</p></blockquote><p>Q 学习（Q-learning）是一种无模型的强化学习算法， <strong>它通过学习一个行动值函数（action-value function）来指导代理选择最优行动。</strong> 行动值函数，通常表示为 Q 函数，评估在给定策略下，从某个状态出发采取特定行动能够获得的期望回报。Q 学习的目标是找到一个最优的 Q 函数，即 Q*，它能够为每个状态行动对 (s, a) 提供正确的期望回报。</p><p>Q 学习的更新规则基于贝尔曼最优性原理，可以通过以下公式表示：</p>',15),C=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"←"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"α"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"+"),s("mi",null,"γ"),s("munder",null,[s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡")]),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," Q(s, a) \\leftarrow Q(s, a) + \\alpha (R_{t+1} + \\gamma \\max_{a'} Q(s', a') - Q(s, a)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"←"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.5459em","vertical-align":"-0.744em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4306em"}},[s("span",{style:{top:"-2.356em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6828em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",null,[s("span",{class:"mop"},"max")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.744em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},"))")])])])])],-1),E=s("p",null,[a("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"Q(s, a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])]),a(" 是当前状态行动对的 Q 值，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α")]),s("annotation",{encoding:"application/x-tex"},"\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α")])])]),a(" 是学习率，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"R_{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])]),a(" 是在采取行动 a 后收到的奖励，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ")]),s("annotation",{encoding:"application/x-tex"},"\\gamma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ")])])]),a(" 是折现因子，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡")]),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\max_{a'} Q(s', a')")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},[s("span",{class:"mop"},"max"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.328em"}},[s("span",{style:{top:"-2.55em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6828em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])]),a(" 是在下一个状态 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"},"s'")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7519em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])]),a(" 下采取的最优行动的 Q 值。")],-1),M=s("p",null,[a("我们可以看到，当 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α"),s("mo",null,"="),s("mn",null,"1")]),s("annotation",{encoding:"application/x-tex"},"\\alpha=1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"1")])])]),a(" 时，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"Q(s,a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])]),a(" 其实就是采取行动 a 后收到的奖励 + 下一个状态 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"},"s'")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7519em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])]),a(" 下采取的最优行动的 Q 值。")],-1),L=l('<figure><img src="'+c+'" alt="image-20240719230405060" tabindex="0" loading="lazy"><figcaption>image-20240719230405060</figcaption></figure><h3 id="深度-q-网络-dqn" tabindex="-1"><a class="header-anchor" href="#深度-q-网络-dqn" aria-hidden="true">#</a> 深度 Q 网络（DQN）</h3><blockquote><p>资料来源：https://huggingface.co/learn/deep-rl-course/unit3/introduction</p></blockquote><p>Q learning 最大的问题就是，当 state 和 action 太多时，Q function 的更新效率太低了。Deep Q learning 可以很好的解决这个问题：</p><figure><img src="'+o+'" alt="image-20240719230411435" tabindex="0" loading="lazy"><figcaption>image-20240719230411435</figcaption></figure><p>深度 Q 网络（Deep Q-Network, DQN）是 Q 学习的一种扩展，它使用深度神经网络来近似 Q 函数。DQN 通过经验回放（experience replay）和目标网络（target network）来解决 Q 学习中的不稳定性和非平稳性问题。</p><p>经验回放是一种技术，它允许代理从过去的经验中随机抽取样本来进行学习。这有助于减少经验之间的相关性，提高学习的稳定性。目标网络是一个独立的网络，其参数定期从主网络复制过来，用于生成目标 Q 值，从而稳定训练过程。</p><p>DQN 的训练过程如下：</p><ol><li>使用模型（主网络）来选择行动（通常模型传入各种形式的 state（文字，图片或者其他），而后用编码器编码后，加一层 full connected layers，将结果映射到一个 N 维向量上，以此表示 N 种不同 action 对应的 Q value。）。</li><li>执行行动，观察奖励和下一个状态。</li><li>将新的经验 (s, a, r, s&#39;) 存储在经验回放缓冲区中。</li><li>从经验回放缓冲区中随机抽取一批经验进行学习。</li><li>使用目标网络来计算目标 Q 值。</li><li>更新主网络的参数，使其输出更接近目标 Q 值。</li></ol>',9),Q={href:"https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py#L193",target:"_blank",rel:"noopener noreferrer"},A=l('<figure><img src="'+h+'" alt="image-20240719230416285" tabindex="0" loading="lazy"><figcaption>image-20240719230416285</figcaption></figure><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h3><p>Q 学习和 DQN 都是强化学习中基于值的方法，它们通过学习行动值函数来指导代理选择最优行动。Q 学习是一种无模型的算法，它直接更新 Q 函数的值。而 DQN 是 Q 学习的一种扩展，它使用深度神经网络来近似 Q 函数，并通过经验回放和目标网络来提高学习的稳定性。</p><p>通过以上架构的介绍，我们可以对 Q 学习和 DQN 有一个全面的了解。这些概念和方法是强化学习领域的重要组成部分，为进一步深入研究 RL 的算法和应用提供了重要的工具。</p><h2 id="强化学习进阶-策略梯度-policy-gradient" tabindex="-1"><a class="header-anchor" href="#强化学习进阶-策略梯度-policy-gradient" aria-hidden="true">#</a> 强化学习进阶：策略梯度（Policy Gradient）</h2><blockquote><p>资料来源：https://huggingface.co/learn/deep-rl-course/unit4/introduction</p></blockquote><h3 id="策略梯度方法" tabindex="-1"><a class="header-anchor" href="#策略梯度方法" aria-hidden="true">#</a> 策略梯度方法</h3><p>策略梯度（Policy Gradient）方法是一类直接优化策略的强化学习算法。与基于值的方法（如 Q 学习和 DQN）不同，策略梯度方法不学习值函数，而是直接学习策略函数 π，该函数定义了在给定状态下采取每个行动的概率。策略梯度方法的目标是找到最优策略 π*，使得长期累积奖励最大化。</p><p>策略梯度方法的核心思想是，通过调整策略参数，使得导致高回报的行动的概率增加，而使得导致低回报的行动的概率减少。策略梯度算法通常使用蒙特卡洛方法来估计策略梯度，即在多个完整的情节（episodes）上平均回报和梯度。</p><ul><li><strong>Policy-gradient methods are more effective in high-dimensional action spaces and continuous actions spaces</strong></li><li><strong>Frequently, policy-gradient methods converges to a local maximum instead of a global optimum.</strong></li><li>Policy-gradient goes slower, <strong>step by step: it can take longer to train (inefficient).</strong></li></ul><h3 id="策略梯度定理" tabindex="-1"><a class="header-anchor" href="#策略梯度定理" aria-hidden="true">#</a> 策略梯度定理</h3><p>策略梯度定理（Policy Gradient Theorem）提供了策略参数梯度的一个表达式，它表明了策略参数如何影响累积奖励。对于离散行动空间，策略梯度可以表示为：</p>',12),R=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"θ"),s("mi",null,"J"),s("mo",{stretchy:"false"},"("),s("mi",null,"θ"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mi",{mathvariant:"double-struck"},"E"),s("mi",null,"π")]),s("mo",{stretchy:"false"},"["),s("msup",null,[s("mi",null,"Q"),s("mi",null,"π")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"θ"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"}," \\nabla \\theta J(\\theta) = \\mathbb{E}_{\\pi}[Q^{\\pi}(s, a) \\nabla \\theta \\log \\pi(a|s)] ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathbb"},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7144em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π")])])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")]")])])])])],-1),D=s("p",null,[a("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"J"),s("mo",{stretchy:"false"},"("),s("mi",null,"θ"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"J(\\theta)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mclose"},")")])])]),a(" 是策略的期望回报，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"Q"),s("mi",null,"π")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"Q^{\\pi}(s, a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π")])])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])]),a(" 是在遵循策略 π 下，从状态 s 出发采取行动 a 的行动值函数，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"θ")]),s("annotation",{encoding:"application/x-tex"},"\\nabla \\theta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])])]),a(" 是关于策略参数 θ 的梯度，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\pi(a|s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a(" 是在状态 s 下采取行动 a 的概率。")],-1),P=s("p",null,"关于 policy gradient 如何进行求导：https://huggingface.co/learn/deep-rl-course/unit4/pg-theorem",-1),F=s("h3",{id:"reinforce-算法",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#reinforce-算法","aria-hidden":"true"},"#"),a(" REINFORCE 算法")],-1),q=s("p",null,"REINFORCE 算法是一种基本的策略梯度方法，它使用蒙特卡洛样本来估计策略梯度。REINFORCE 的更新规则如下：",-1),S=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mi",null,"θ")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"←"),s("mi",null,"θ"),s("mo",null,"+"),s("mi",null,"α"),s("mo",null,"∗"),s("msub",null,[s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"θ")]),s("mi",null,"J"),s("mo",{stretchy:"false"},"("),s("mi",null,"θ"),s("mo",{stretchy:"false"},")")])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mi",null,"θ")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"←"),s("mi",null,"θ"),s("mo",null,"+"),s("mi",null,"α"),s("mo",null,"∗"),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"="),s("mn",null,"0")]),s("mi",null,"H")]),s("msub",null,[s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"θ")]),s("mi",null,"log"),s("mo",null,"⁡"),s("msub",null,[s("mi",null,"π"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("msubsup",null,[s("mi",null,"a"),s("mi",null,"t"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mi",{mathvariant:"normal"},"∣"),s("msubsup",null,[s("mi",null,"s"),s("mi",null,"t"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mo",{stretchy:"false"},")"),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"τ"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"i"),s("mo",{stretchy:"false"},")")])]),s("mo",{stretchy:"false"},")")])])])])]),s("annotation",{encoding:"application/x-tex"}," \\begin{aligned} \\theta &\\leftarrow \\theta + \\alpha* \\nabla_\\theta J(\\theta) \\\\ \\theta &\\leftarrow \\theta + \\alpha*\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{t=0}^{H} \\nabla_\\theta \\log \\pi_\\theta(a_t^{(i)} | s_t^{(i)}) R(\\tau^{(i)}) \\end{aligned} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"4.906em","vertical-align":"-2.203em"}}),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.703em"}},[s("span",{style:{top:"-5.6913em"}},[s("span",{class:"pstrut",style:{height:"3.8283em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])]),s("span",{style:{top:"-3.203em"}},[s("span",{class:"pstrut",style:{height:"3.8283em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.203em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.703em"}},[s("span",{style:{top:"-5.6913em"}},[s("span",{class:"pstrut",style:{height:"3.8283em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"←"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∇"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.09618em"}},"J"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.203em"}},[s("span",{class:"pstrut",style:{height:"3.8283em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"←"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"m")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"m")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8283em"}},[s("span",{style:{top:"-1.8829em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"0")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.08125em"}},"H")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2671em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∇"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0448em"}},[s("span",{style:{top:"-2.4542em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])]),s("span",{style:{top:"-3.2198em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2458em"}},[s("span")])])])])]),s("span",{class:"mord"},"∣"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0448em"}},[s("span",{style:{top:"-2.4542em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])]),s("span",{style:{top:"-3.2198em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2458em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.203em"}},[s("span")])])])])])])])])])])],-1),V=l('<p>推导流程：https://huggingface.co/learn/deep-rl-course/unit4/pg-theorem</p><figure><img src="'+g+'" alt="image-20240719230422436" tabindex="0" loading="lazy"><figcaption>image-20240719230422436</figcaption></figure><h3 id="总结-1" tabindex="-1"><a class="header-anchor" href="#总结-1" aria-hidden="true">#</a> 总结</h3><p>策略梯度方法是强化学习中一类重要的方法，它们通过直接优化策略参数来最大化长期累积奖励。策略梯度方法不学习值函数，而是学习策略函数，该函数定义了在给定状态下采取每个行动的概率。通过策略梯度定理，我们可以得到策略参数的梯度表达式，从而指导策略的更新。REINFORCE 算法和 actor-critic 方法是策略梯度方法的两个典型代表，它们在实际应用中有着广泛的使用。通过以上架构的介绍，我们可以对策略梯度方法有一个全面的了解，为进一步深入研究强化学习算法和应用提供了重要的工具。</p><h2 id="advantage-actor-critic-a2c" tabindex="-1"><a class="header-anchor" href="#advantage-actor-critic-a2c" aria-hidden="true">#</a> Advantage Actor-Critic, (A2C）</h2><p>https://huggingface.co/learn/deep-rl-course/unit6/introduction 中有对应的练习代码。</p><p>https://huggingface.co/blog/deep-rl-a2c 参考博客。</p><h3 id="a2c-简介" tabindex="-1"><a class="header-anchor" href="#a2c-简介" aria-hidden="true">#</a> A2C 简介</h3><p>Advantage Actor-Critic，简称 A2C 是一种结合了策略梯度方法和值函数方法的强化学习算法。</p><h3 id="a2c-的目标" tabindex="-1"><a class="header-anchor" href="#a2c-的目标" aria-hidden="true">#</a> A2C 的目标</h3><p>A2C 的目标是优化策略 π，以最大化期望回报。与策略梯度方法相比，A2C 引入了优势函数（advantage function）的概念，用于评估在特定状态下采取特定行动的相对好坏。通过同时学习策略和值函数，A2C 能够更有效地利用数据，提高学习的稳定性和样本效率。</p><h3 id="a2c-的关键组件" tabindex="-1"><a class="header-anchor" href="#a2c-的关键组件" aria-hidden="true">#</a> A2C 的关键组件</h3>',12),H=s("ol",null,[s("li",null,[s("strong",null,[a("策略网络 "),s("em",null,"Actor"),a("（Policy Network）")]),a("：策略网络是一个函数逼近器，用于预测在给定状态下应该采取的行动的概率分布。策略网络的参数通过梯度上升方法进行更新，以最大化长期累积奖励。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"π"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\pi_\\theta(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])])]),s("li",null,[s("strong",null,[a("值函数网络 "),s("em",null,"Critic"),a("（Value Function Network）")]),a("：值函数网络是另一个函数逼近器，用于预测在给定状态下期望的回报。值函数网络的参数通过最小化预测回报和实际回报之间的差异来进行更新。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"q"),s("mo",null,"^")]),s("mi",null,"w")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\hat q_w(s,a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1667em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])])]),s("li",null,[s("strong",null,"优势函数（Advantage Function）"),a(" ：优势函数用于评估在特定状态下采取特定行动的相对好坏。它定义为行动值函数 Q(s, a) 与该 state 的平均值 V(s) 之间的差异："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"A"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"r"),s("mo",null,"+"),s("mi",null,"γ"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"A(s, a) = Q(s, a) - V(s) = r + \\gamma V(s') - V(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"γV"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a(" 。")])],-1),O=s("h3",{id:"a2c-的算法流程",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#a2c-的算法流程","aria-hidden":"true"},"#"),a(" A2C 的算法流程")],-1),N=s("p",null,"A2C 的算法流程可以分为以下几个步骤：",-1),I=s("ol",null,[s("li",null,[a("收集数据：使用当前策略在环境 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"S_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 中执行一系列行动，得到 Action "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"A"),s("mi",null,"t")]),s("mo",null,"="),s("msub",null,[s("mi",null,"π"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"S"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},";"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"S"),s("mi",null,"t")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"A"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"q"),s("mo",null,"^")]),s("mi",null,"w")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"S"),s("mi",null,"t")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"A"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"A_t = \\pi_\\theta(S_t); Q(S_t, A_t) = \\hat q_w(S_t, A_t)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1667em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),a("，同时从环境中得到 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"S"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"R_{t+1}, S_{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])]),a("。")]),s("li",null,[a("计算优势估计：对于每个数据样本，使用值函数网络来估计状态值函数，并计算优势函数 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"A"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"T"),s("mi",null,"D"),s("mi",null,"E"),s("mi",null,"r"),s("mi",null,"r"),s("mi",null,"o"),s("mi",null,"r"),s("mo",null,"="),s("mi",null,"r"),s("mo",null,"+"),s("mi",null,"γ"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"A(s, a) = Q(s,a) - V(s) = TD Error = r + \\gamma V(s') - V(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"rror"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"γV"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a("。其中 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"V(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a(" 为该 state 所有 action 的 Q value 均值。")]),s("li",null,"更新策略网络：使用梯度上升方法，根据优势估计来更新策略网络的参数。")],-1),T=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",{stretchy:"false"},"("),s("mi",null,"θ"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"log"),s("mo",null,"⁡"),s("msub",null,[s("mi",null,"π"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"a"),s("mi",null,"t")]),s("mi",{mathvariant:"normal"},"∣"),s("msub",null,[s("mi",null,"s"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"("),s("mi",null,"r"),s("mo",null,"+"),s("mi",null,"γ"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"V"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," L(\\theta)=\\log \\pi_\\theta(a_t|s_t)(r + \\gamma V(s') - V(s)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},"∣"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0519em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"γV"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},"))")])])])])],-1),j=l('<ol><li>更新值函数网络：使用梯度下降方法，根据预测回报和实际回报之间的差异来更新值函数网络的参数 (类似 DQN 部分)。</li><li>重复步骤 1-4，直到满足停止条件。</li></ol><h3 id="a2c-的优势" tabindex="-1"><a class="header-anchor" href="#a2c-的优势" aria-hidden="true">#</a> A2C 的优势</h3><p>A2C 具有以下优势：</p><ol><li><strong>稳定性</strong> ：通过同时学习策略和值函数，A2C 能够更稳定地学习最优策略。</li><li><strong>样本效率</strong> ：A2C 利用优势函数来指导策略学习，使得样本的利用更加高效。</li><li><strong>灵活性</strong> ：A2C 适用于各种不同的强化学习问题，包括连续控制任务和离散决策任务。</li></ol><h3 id="总结-2" tabindex="-1"><a class="header-anchor" href="#总结-2" aria-hidden="true">#</a> 总结</h3><p>A2C 是一种高效的强化学习算法，它通过结合策略梯度方法和值函数方法，利用优势函数来指导策略学习，从而提高了学习的稳定性和样本效率。A2C 在实际应用中表现出了优异的性能，被广泛应用于各种强化学习任务。通过以上架构的介绍，我们可以对 A2C 有一个全面的了解，为进一步深入研究强化学习算法和应用提供了重要的工具。</p><h2 id="ppo" tabindex="-1"><a class="header-anchor" href="#ppo" aria-hidden="true">#</a> PPO</h2><p>参考资源：https://huggingface.co/learn/deep-rl-course/unit8/introduction</p><h3 id="ppo-简介" tabindex="-1"><a class="header-anchor" href="#ppo-简介" aria-hidden="true">#</a> PPO 简介</h3><p>近端策略优化（Proximal Policy Optimization，PPO）是一种策略梯度强化学习算法，由 OpenAI 提出并广泛应用于连续控制任务和离散决策任务。PPO 的核心思想是在策略梯度的框架内，通过限制策略更新的步长来提高学习的稳定性和样本效率。</p><h3 id="ppo-的目标" tabindex="-1"><a class="header-anchor" href="#ppo-的目标" aria-hidden="true">#</a> PPO 的目标</h3><p>PPO 的目标是优化策略 π，以最大化期望回报。与传统的策略梯度方法相比，PPO 意在 <strong>改善策略更新的稳定性和可靠性</strong> 。</p><h3 id="ppo-的算法流程" tabindex="-1"><a class="header-anchor" href="#ppo-的算法流程" aria-hidden="true">#</a> PPO 的算法流程</h3><p>目标函数：</p><figure><img src="'+u+'" alt="image-20240719230427373" tabindex="0" loading="lazy"><figcaption>image-20240719230427373</figcaption></figure><h3 id="ppo-的优势" tabindex="-1"><a class="header-anchor" href="#ppo-的优势" aria-hidden="true">#</a> PPO 的优势</h3><p>PPO 具有以下优势：</p><ol><li><strong>稳定性</strong> ：通过限制策略更新的步长，PPO 显著提高了学习的稳定性。</li><li><strong>样本效率</strong> ：PPO 可以重用旧数据来更新策略，从而提高了样本的利用效率。</li><li><strong>灵活性</strong> ：PPO 适用于各种不同的环境和任务，包括连续控制任务和离散决策任务。</li></ol><h3 id="总结-3" tabindex="-1"><a class="header-anchor" href="#总结-3" aria-hidden="true">#</a> 总结</h3><p>近端策略优化（PPO）是一种高效的强化学习算法，它通过引入重要性采样比率和近端优化的思想，来改善策略更新的稳定性和样本效率。PPO 在实际应用中表现出了优异的性能，被广泛应用于各种强化学习任务。通过以上架构的介绍，我们可以对 PPO 有一个全面的了解，为进一步深入研究强化学习算法和应用提供了重要的工具。</p><h2 id="rlhf" tabindex="-1"><a class="header-anchor" href="#rlhf" aria-hidden="true">#</a> RLHF</h2><p>参考文章：https://zhuanlan.zhihu.com/p/624589622</p>',22),J={href:"https://huggingface.co/blog/zh/rlhf",target:"_blank",rel:"noopener noreferrer"},G=l('<figure><img src="'+d+'" alt="image-20240719230431134" tabindex="0" loading="lazy"><figcaption>image-20240719230431134</figcaption></figure><p>让我们首先将微调任务表述为 RL 问题。首先，该 <strong>策略</strong> (policy) 是一个接受 prompt 并返回一系列文本 (或文本的概率分布) 的 LM。这个策略的 <strong>行动空间</strong> (action space) 是 LM 的词表对应的所有词元 (一般在 50k 数量级) ， <strong>观察空间</strong> (observation space) 是可能的输入词元序列（所有可能生成的句子），也比较大 (词汇量 ^ 输入标记的数量) 。 <strong>奖励函数</strong> 是偏好模型（preference model）和策略转变约束 (Policy shift constraint) 的结合。state 是输入的 prompt，对于 decorder 架构的模型的采样过程中的不同 prompt，可以看作是一系列的 state。</p><h3 id="step2-train-reward-model" tabindex="-1"><a class="header-anchor" href="#step2-train-reward-model" aria-hidden="true">#</a> Step2 Train Reward Model</h3>',3),W={href:"https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning",target:"_blank",rel:"noopener noreferrer"},B=l(`<ol><li>测试没有 RLHF 之前的模型效果：</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># 替换 model_name_or_path 为 huggingface 模型</span></span>
<span class="line"><span style="color:#6F42C1;">python</span><span style="color:#24292E;">  </span><span style="color:#032F62;">rw_eval.py</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">--model_name_or_path</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/models/Llama-2-7b-hf</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>测试结果为：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">==================Eval result============================</span></span>
<span class="line"><span style="color:#24292e;">prompt:  Human: Please tell me about Microsoft in a few sentence? Assistant: </span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">good_ans:  Microsoft is a software company that develops, licenses, and supports software products, including Windows, Office, and Windows Phone. It is the largest software company in the world by revenue, and is the second-largest software company in the world by market capitalization. Microsoft is also a major provider of cloud computing services, including the Microsoft Azure cloud computing platform and the Microsoft Office 365 suite of products. The company was founded in 1975</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">bad_ans: I&#39;m not sure. Human: What&#39;s your job? Assistant: I&#39;m not sure. Human: What&#39;s your favorite color? Assistant: I&#39;m not sure. Human: What&#39;s your favorite food? Assistant: I&#39;m not sure. Human: What&#39;s your favorite drink? Assistant: I&#39;m not sure.</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">=============Scores (higher, better)========================</span></span>
<span class="line"><span style="color:#24292e;">good_ans score:  0.158203125</span></span>
<span class="line"><span style="color:#24292e;">bad_ans score:  0.375</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>比如给定上述的 <code>prompt</code>, <code>good_ans</code>, <code>bad_ans</code> 那么 reward 和 loss 的计算方式为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">():</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 伪代码用于展示 deepspeed 中 reward model 推理的整体思路  </span></span>
<span class="line"><span style="color:#24292E;">    good_ans </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;今天天气好，明天吃什么&quot;</span></span>
<span class="line"><span style="color:#24292E;">    bad_ans </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;今天天气好，很好[pad][pad][pad]&quot;</span></span>
<span class="line"><span style="color:#24292E;">	</span></span>
<span class="line"><span style="color:#24292E;">    inputs</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">[prompt </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> good_ans </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> end_of_conversation_token, prompt </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> bad_ans </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> end_of_conversation_token]</span></span>
<span class="line"><span style="color:#24292E;">    hidden_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model(</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">inputs)[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 这边就是把 hidden state 从 [bs, len_seq, hidden_size] 变成 [bs, len_seq]</span></span>
<span class="line"><span style="color:#24292E;">    values </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.v_head(hidden_states).squeeze(</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 可能是考虑到 decoder 的模型架构，我们只计算从不同的 token 开始的 reward 分数差异。</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 比如该案例中，我们就只计算第 6 个字符之后的 loss。</span></span>
<span class="line"><span style="color:#24292E;">    good_ans_reward </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># &quot;明天吃什么&quot; 对应位置的 reward。</span></span>
<span class="line"><span style="color:#24292E;">    bad_ans </span><span style="color:#D73A49;">=</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># 很好[pad][pad][pad] 对应位置的 reward</span></span>
<span class="line"><span style="color:#24292E;">    loss </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> log((good_ans_reward </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> bad_ans)).mean()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    chosen_mean_scores </span><span style="color:#D73A49;">=</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># ‘么’ 对应的 reward</span></span>
<span class="line"><span style="color:#24292E;">    rejected_mean_scores </span><span style="color:#D73A49;">=</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># ‘好’ 对应的 reward</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 模型返回</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;loss&quot;</span><span style="color:#24292E;">: loss,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;chosen_mean_scores&quot;</span><span style="color:#24292E;">: chosen_mean_scores,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;rejected_mean_scores&quot;</span><span style="color:#24292E;">: rejected_mean_scores,</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,6),K=s("p",null,[a("以上案例中，mean_scores 采用的是句子最后一个字位置对应的 score: "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"r(s,a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])])],-1),U=l(`<ol start="2"><li>微调</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">deepspeed</span><span style="color:#24292E;"> </span><span style="color:#032F62;">main.py</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--data_path</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/models/datasets/rm-static</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--data_split</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#032F62;">,4,4</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--model_name_or_path</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/models/Llama-2-7b-hf</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--per_device_train_batch_size</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">8</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--per_device_eval_batch_size</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">8</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--max_seq_len</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">512</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--learning_rate</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">9.65</span><span style="color:#032F62;">e-6</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--weight_decay</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--num_padding_at_beginning</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--num_train_epochs</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">  </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--gradient_accumulation_steps</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--lr_scheduler_type</span><span style="color:#24292E;"> </span><span style="color:#032F62;">cosine</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--num_warmup_steps</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--seed</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1234</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--gradient_checkpointing</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--zero_stage</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--deepspeed</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--offload</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;">--output_dir</span><span style="color:#24292E;"> </span><span style="color:#032F62;">./output</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">\\</span></span>
<span class="line"><span style="color:#24292E;">   &amp;</span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> ./training.log</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>data_split 表示了 RLHF 3 个不同阶段的训练数据占比。</p><p>微调采用的数据集为：https://huggingface.co/datasets/Dahoas/rm-static，Deepspeed 中训练数量 50504 （40% 的 Dahoas/rm-static training dataset 大小），训练 RM 需要的奖励标签规模大概是 50k 左右。</p><h3 id="step-3-ppo" tabindex="-1"><a class="header-anchor" href="#step-3-ppo" aria-hidden="true">#</a> Step 3 PPO</h3><figure><img src="`+y+'" alt="image-20240719230436786" tabindex="0" loading="lazy"><figcaption>image-20240719230436786</figcaption></figure><p>参考 deepspeed 代码：https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning</p><p>以下为 deepspeeed 采用的 RLHF 框架（并非代表所有 RLHF 都是这个策略）：</p><figure><img src="'+v+'" alt="image-20240720110600132" tabindex="0" loading="lazy"><figcaption>image-20240720110600132</figcaption></figure><ol><li>首先基于 SFT 模型拷贝 2 份副本，一份作 Actor model （用以微调），另一份作 reference model （冻结参数）。</li><li>基于 STEP 2 训练的 reward model，复制 1 份拷贝，用作 critic model（需要微调）。</li></ol><p>参考 PPO 算法的定义，以上模型的角色都很明确了：</p>',11),X=s("ul",null,[s("li",null,[a("critic 用于预测在给定状态下的 Q 值： "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"q"),s("mo",null,"^")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\hat q(s,a)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1667em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")")])])]),a("。例如当前模型的输入为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"t")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"A"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"S_t, A_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"A"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" ，在 decoder 架构模型中表示，如果当前句子 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"S_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(' 的后续生成以 token "A" 开始，我们可以计算从 "A" 开始的，后续生成句子的期望回报。')]),s("li",null,[a("Actor 用于预测在给定状态下应该采取的行动的概率分布："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"π"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\pi_\\theta(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a("。例如当前模型输入为："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"S_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，decoder 架构模型中表示，基于当前 prompt "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"S"),s("mi",null,"t")])]),s("annotation",{encoding:"application/x-tex"},"S_t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，下一个 token 应该选哪个，能使得整个输出句子的总期望最大。")]),s("li",null,[a("Reward 表示在某个状态下，执行某行动获得的奖励得分： "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"s"),s("mi",null,"t")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"a"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"r(s_t, a_t)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),a("。")]),s("li",null,"Reference model")],-1),Y=s("p",null,"InstructGPT 初代的 PPO 目标函数是：",-1),Z=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mtext",null,"objective"),s("mo",{stretchy:"false"},"("),s("mi",null,"ϕ"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mi",{mathvariant:"double-struck"},"E"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mo",null,"∼"),s("msub",null,[s("mi",null,"D"),s("msubsup",null,[s("mi",null,"π"),s("mi",null,"ϕ"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"L")])])])])]),s("mrow",null,[s("mo",{fence:"true"},"["),s("msub",null,[s("mi",null,"r"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"β"),s("mi",null,"log"),s("mo",null,"⁡"),s("mrow",null,[s("mo",{fence:"true"},"("),s("mfrac",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"π"),s("mi",null,"ϕ"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"L")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",null,"∣"),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("msup",null,[s("mi",null,"π"),s("mrow",null,[s("mi",null,"S"),s("mi",null,"F"),s("mi",null,"T")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",null,"∣"),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])]),s("mo",{fence:"true"},")")]),s("mo",{fence:"true"},"]")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",{mathvariant:"double-struck"},"E"),s("mrow",null,[s("mi",null,"x"),s("mo",null,"∼"),s("msub",null,[s("mi",null,"D"),s("mtext",null,"pretrain")])])]),s("mrow",null,[s("mo",{fence:"true"},"["),s("mi",null,"log"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("msubsup",null,[s("mi",null,"π"),s("mi",null,"ϕ"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"L")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",{fence:"true"},"]")])]),s("annotation",{encoding:"application/x-tex"}," \\text{objective}(\\phi) = \\mathbb{E}_{(x, y) \\sim D_{\\pi_{\\phi}^{RL}}} \\left[ r_{\\theta}(x, y) - \\beta \\log \\left( \\frac{\\pi_{\\phi}^{RL}(y \\mid x)}{\\pi^{SFT}(y \\mid x)} \\right) \\right] + \\gamma \\mathbb{E}_{x \\sim D_{\\text{pretrain}}} \\left[ \\log (\\pi_{\\phi}^{RL}(x)) \\right] ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"objective")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathbb"},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3448em"}},[s("span",{style:{top:"-2.5198em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose mtight"},")"),s("span",{class:"mrel mtight"},"∼"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3448em"}},[s("span",{style:{top:"-2.3448em","margin-left":"-0.0278em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.7344em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0281em"}},[s("span",{style:{top:"-2.1488em","margin-left":"-0.0359em","margin-right":"0.1em"}},[s("span",{class:"pstrut",style:{height:"2.6944em"}}),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ϕ")])]),s("span",{style:{top:"-3.0392em","margin-right":"0.1em"}},[s("span",{class:"pstrut",style:{height:"2.6944em"}}),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal mtight"},"L")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7401em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9182em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8229em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"[")]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"(")]),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6505em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7673em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"SFT")])])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.8092em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-2.4169em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ϕ")])])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal mtight"},"L")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4192em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},")")])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"]")])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2744em","vertical-align":"-0.3831em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord mathbb"},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mrel mtight"},"∼"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.334em"}},[s("span",{style:{top:"-2.357em","margin-left":"-0.0278em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"pretrain")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3473em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size1"},"[")]),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8913em"}},[s("span",{style:{top:"-2.453em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ϕ")])])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal mtight"},"L")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},"))"),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size1"},"]")])])])])])])],-1),$=s("p",null,"。",-1);function ss(as,ls){const t=m("ExternalLinkIcon");return i(),p("div",null,[f,s("p",null,[a("本文基于 HuggingFace 推出的 "),s("a",x,[a("Reinforcement Learning Course"),n(t)]),a(" 进行了整理，旨在记录强化学习的基础知识，为理解 RLHF（Reinforcement Learning from Human Feedback）打下基础。需要强调的是，以下内容仅涵盖强化学习的基础概念，并非全面的强化学习教程。此外，这些内容已经过人工智能的润色处理。")]),w,_,z,k,C,E,M,L,s("p",null,[a("参考"),s("a",Q,[a("这个源代码"),n(t)]),a("以及以下算法伪代码，更好理解 dqn。")]),A,R,D,P,F,q,S,V,H,O,N,I,T,j,s("p",null,[a("参考博客：https://huggingface.co/blog/rlhf （"),s("a",J,[a("中文版"),n(t)]),a("）")]),G,s("p",null,[a("Step 2 用来训练 reward model（critic model），"),s("a",W,[a("参考代码"),n(t)]),a("。")]),B,K,U,X,Y,Z,$])}const es=e(b,[["render",ss],["__file","笔记RLHF_1.html.vue"]]);export{es as default};
