import{_ as p,Q as o,V as l,Z as n,ag as s,Y as e,aQ as t,H as i}from"./framework-bcd5cf65.js";const c={},d=n("p",null,"以 canine 复现为例，整理总结复现过程中重要的深度学习知识点。",-1),r=n("h2",{id:"简介",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#简介","aria-hidden":"true"},"#"),s(" 简介")],-1),u={href:"https://github.com/kevinng77/canine_paddle",target:"_blank",rel:"noopener noreferrer"},k=t('<h2 id="模型实现" tabindex="-1"><a class="header-anchor" href="#模型实现" aria-hidden="true">#</a> 模型实现</h2><h3 id="模型定位" tabindex="-1"><a class="header-anchor" href="#模型定位" aria-hidden="true">#</a> 模型定位</h3><p>在一切复现之前，最重要的事情就是判断这篇文章是否值得复现，内容包括：</p><ul><li><strong>复现难度：</strong> 你是否具备复现所需要的设备？训练模型所需要的时间是否充足？</li><li><strong>模型成就水平：</strong> 模型的指标是否可信，模型拿了哪些 SOTA？评测的数据库是否权威？算法是否优雅？</li><li><strong>论文合理性：</strong> 尽量避开有坑的论文。复现前检查论文是否具备完整的源码，浏览下论文仓库 issue 区。过一下论文大致框架。时间允许的话可以跑以下官方源码。</li></ul><p>不要迷恋大厂光环，如 google 的 CANINE 论文就充满了槽点，模型架构没什么创新，模型指标也一般般。CANINE 论文中声明该模型比 TydiQA 基线采用的 mBert 高了约 2%，看似不错，但同年发布的其他 TydiQA Top 5 模型比 CANINE 指标还要高出约 7% 到 13%。再者 TydiQA 数据集较为小众，排行榜发布两年到现在也就个位数的模型投榜。因此个人认为 CANINE 有点水论文的嫌疑了。</p>',5),h={href:"https://github.com/google-research-datasets/tydiqa",target:"_blank",rel:"noopener noreferrer"},m=t('<ul><li><code>run_tydi_lib.py</code> 中在 GPU 训练过程中插入了频繁的 CPU 计算，大大降低显卡使用率；</li><li><code>postproc.py</code> 中内存管理极不合理，实际运行官方源码，你需要 120G+ 的内存；然而经过笔者的优化测试，在程序效率不变的情况下，10G+的内存就可以搞定了。</li><li><code>postproc.py</code> 中计算效率极为缓慢，文件中存在诸多与 TydiQA 任务结果无关的计算，并且没有任何优化计算的方案，笔者通过加入多线程、清理无用中间变量，将数据处理时间从官方文件的 3 小时减少到了仅 20 分钟。</li></ul><h3 id="模型编写" tabindex="-1"><a class="header-anchor" href="#模型编写" aria-hidden="true">#</a> 模型编写</h3><p>复现一定不是从绝对的零开始，大部分复现都是基于已有的算子、模型框架进行编写。如 CANINE 采用了 Transformer Encoder 作为主编码器，因此若基于 Bert 模型进行修改，1 天便能完成模型架构的编写。若是从 0 开始自己拼算子，只怕需要花上个一周甚至更久。</p><p>算子也可能存在 bug，如 paddle 的 <code>repeat_interleave</code> 就存在反向传播时候的 <code>segmentation fault</code> 问题</p><h3 id="预训练权重转换" tabindex="-1"><a class="header-anchor" href="#预训练权重转换" aria-hidden="true">#</a> 预训练权重转换</h3><p>使用 paddle 或者其他框架时，可以考虑转换已有的 huggingface 预训练权重而非自己训练预训练权重。转换好的权重可以上传至 huggingface.co （记得使用 git lfs）</p><h3 id="静态图-动态图" tabindex="-1"><a class="header-anchor" href="#静态图-动态图" aria-hidden="true">#</a> 静态图，动态图</h3><p>个人喜欢使用动态图构建框架，在实现后转为静态图进行服务部署。</p>',8),_={href:"https://zhuanlan.zhihu.com/p/191648279",target:"_blank",rel:"noopener noreferrer"},b={href:"https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/jit/index_cn.html",target:"_blank",rel:"noopener noreferrer"},v={href:"https://www.paddlepaddle.org.cn/tutorials/projectdetail/1499114",target:"_blank",rel:"noopener noreferrer"},f=t("<p>根据 operator 算子解析执行方式不同，模型可以分为动态图和静态图。</p><table><thead><tr><th></th><th>动态图</th><th>静态图</th></tr></thead><tbody><tr><td>编程范式</td><td>命令式编程范式</td><td>声明式编程范式</td></tr><tr><td>执行方式</td><td>用户无需预先定义完整的网络结构，每写一行网络代码，即可同时获得计算结果。</td><td>先编译后执行，用户需预先定义完整的网络结构，再对网络结构进行编译优化后，才能执行获得计算结果。</td></tr><tr><td>编程体验</td><td>可以使用 python 原生的控制流，容易开发、调试</td><td>调试不方便，开发有一定门槛，过程中的算子需要有 action（如 .run()）才会执行。</td></tr><tr><td>性能</td><td>动态图需要在 python 与 C++计算库之间频繁切换，导致了更大的时间开销。</td><td>一般采用 C++ 性能更优。</td></tr><tr><td>模型架构</td><td>无需使用占位符</td><td>静态图组网阶段并没有实际运行网络，因此并不读入数据，所以需要使用“占位符”（如 paddle.data）指明输入数据的类型、shape 等信息，以完成组网。</td></tr></tbody></table><p><strong>动态图转静态</strong></p><p>除了手动编写静态图代码外，部分框架也提供了动转静的 API，如 paddle 只需要采用 <code>paddle.jit.to_static()</code> 。动态图转静态的一部分优化内容在于使用 python 定义的控制流，如 <code>for</code>, <code>while</code> 等。</p><p><strong>paddle 动态图转静态图注意点：</strong></p>",5),g={href:"https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/jit/grammar_list_cn.html#8",target:"_blank",rel:"noopener noreferrer"},w=t('<p>for range 中不支持参数传递 step 值，如 <code>for x in range(0,n, step):</code>，可改用 while 替代。</p><p><code>for a,b,c,d in xs:</code> 报错，采用 <code>for x in xs: a,b,c,d = x</code> 代替</p><ul><li><p>模型中比较常见的控制流转写大多数与 <code>batch_size</code> 或者 <code>x.shape</code> 相关。</p><p><code>x.shape[i]</code> 的返回值可能是固定的值，也可能是 <code>None</code> ，表示动态 shape（如 batch_size）。</p><p>如果比较明确 <code>x.shape[i]</code> 对应的是 <strong>动态 shape</strong> ，推荐使用 <code>paddle.shape(x)[i]</code>，特别是在生成 position_ids 的时候。</p></li><li><p>错误：Intel MKL function load error: cpu specific dynamic library is not loaded。环境问题，尝试 <code>conda install nomkl</code></p></li><li><p><code>paddle.jit.set_code_level()</code> 打印转换后的静态图模型代码。</p></li><li><p>若出现推理时候的维度错误，但模型动态转静态无报错，那么大概错误在于 reshape 或者 unsqeeze 时候维度出问题。1. 尽量少用 <code>axis=-1</code>；2. 检查所有的维度变换是否正确；3.检查是否使用 <code>paddle.shape(x)[i]</code>来获取动态维度，如 <code>batch_size</code>, <code>len_seq</code> 等。</p></li></ul><h2 id="数据处理" tabindex="-1"><a class="header-anchor" href="#数据处理" aria-hidden="true">#</a> 数据处理</h2><p>背景：训练数据集太大，一次性加载不进内存中。</p><h3 id="数据加载" tabindex="-1"><a class="header-anchor" href="#数据加载" aria-hidden="true">#</a> 数据加载</h3><p>场景：NLP 预训练任务，文本数据集大。</p>',7),y=n("thead",null,[n("tr",null,[n("th",null,"储存方式"),n("th",null,"文件格式"),n("th",null,"Dataset"),n("th",null,"备注"),n("th",null,"shuffle")])],-1),x=n("tr",null,[n("td",null,"单个大文件"),n("td",null,"pickle/jsonl/txt 等"),n("td",null,"map dataset/iterable dataset"),n("td",null,"使用更好的机器，将所有样本加载到内存中。"),n("td",null,"可以")],-1),D=n("td",null,"单个大文件",-1),A=n("td",null,"pickle/jsonl/txt 等",-1),E=n("td",null,"map dataset",-1),z={href:"https://zhuanlan.zhihu.com/p/460012052",target:"_blank",rel:"noopener noreferrer"},q=n("td",null,"可以",-1),B=n("tr",null,[n("td",null,"多个中文件"),n("td",null,"pickle/jsonl/txt 等"),n("td",null,"iterable dataset"),n("td",null,"每个文件储存一定数量的样本，内次加载部分样本到内存中，样本加载速度远大于楼下。"),n("td",null,"不能全局 shuffle")],-1),N=n("tr",null,[n("td",null,"超多个小文件"),n("td",null,"pickle/jsonl/txt 等"),n("td",null,"map dataset"),n("td",null,"将每个样本储存在一个文件中，通过索引 文件名获取样本。I/O 的开销非常大。"),n("td",null,"支持全局 shuffle")],-1),P=n("tr",null,[n("td",null,"数据库"),n("td",null,"h5df, tfrecord 等"),n("td",null,"map dataset"),n("td",null,"所有样本储存在同一数据库中，通过索引数据库获取样本。"),n("td",null,"支持全局 shuffle，但影响性能")],-1),T=t(`<h3 id="相关-api" tabindex="-1"><a class="header-anchor" href="#相关-api" aria-hidden="true">#</a> 相关 API</h3><p><code>Dataset</code></p><p>常用的 dataset 有 <code>MapDataset</code> 和 <code>IterableDataset</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TydiDataset</span><span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IterableDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Construct Dataset Class for Canine TydiQA task.
Args:
    file_names (List[int]): the names of input files.
    sample_dir (str): The directory of folder storing input sample files, which contains a single
        training sample respectively.
&quot;&quot;&quot;</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 file_names<span class="token punctuation">,</span>
                 sample_dir<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">&quot;/data/tydi/train_samples&quot;</span><span class="token punctuation">,</span>
                 <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TydiDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>all_file_path <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> file_name <span class="token keyword">in</span> file_names<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>all_file_path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> paddle<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            file_list <span class="token operator">=</span> self<span class="token punctuation">.</span>all_file_path
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            worker_info <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>get_worker_info<span class="token punctuation">(</span><span class="token punctuation">)</span>
            num_files <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>all_file_path<span class="token punctuation">)</span>
            files_per_worker <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>
                math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>num_files <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>
                    worker_info<span class="token punctuation">.</span>num_workers<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            worker_id <span class="token operator">=</span> worker_info<span class="token punctuation">.</span><span class="token builtin">id</span>
            iter_start <span class="token operator">=</span> worker_id <span class="token operator">*</span> files_per_worker
            iter_end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>iter_start <span class="token operator">+</span> files_per_worker<span class="token punctuation">,</span> num_files<span class="token punctuation">)</span>
            file_list <span class="token operator">=</span> self<span class="token punctuation">.</span>all_file_path<span class="token punctuation">[</span>iter_start<span class="token punctuation">:</span>iter_end<span class="token punctuation">]</span>

        <span class="token keyword">for</span> file_name <span class="token keyword">in</span> file_list<span class="token punctuation">:</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span><span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>
                <span class="token keyword">for</span> sample <span class="token keyword">in</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>fp<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">yield</span> sample
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>DataLoader </code></p>`,5),j={href:"https://www.zhihu.com/question/422160231/answer/1484767204",target:"_blank",rel:"noopener noreferrer"},C=n("code",null,"num_worker",-1),I=n("p",null,[n("code",null,"DistrubutedBatchSampler")],-1),L=n("p",null,[s("多卡训练下，数据的分配是个关键问题。采用 dataset 时可以手动设置每个卡读取的样本，如上述案例代码。若使用 "),n("code",null,"MapDataset"),s("，则可以考虑使用 "),n("code",null,"DistributedBatchSampler"),s(" 来自动分配每个卡的样本，以保证样本不重叠。")],-1),H=n("h3",{id:"h5df",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#h5df","aria-hidden":"true"},"#"),s(" H5DF")],-1),Q=n("p",null,"Canine 的指标是根据 TydiQA 数据集进行评测的，其中 TydiQA 数据集在数据处理过程中，使用了 tfrecord + tftensor 进行数据存储。为了适配 Paddle 的训练，笔者尝试了使用 H5DF 代替 tfrecord，在数据处理过程中，H5DF 的空间占用与 tfrecord 旗鼓相当，训练过程中，H5DF 也能提供足够的速度，以保证训练效率上与从内存加载数据集的效率相近。",-1),S={href:"http://wujiawen.xyz/archives/h5dfh5py%E6%96%87%E6%A1%A3%E5%B0%8F%E6%95%B4%E7%90%86",target:"_blank",rel:"noopener noreferrer"},F={href:"https://docs.h5py.org/en/stable/high/dataset.html#creating-datasets",target:"_blank",rel:"noopener noreferrer"},R=n("h2",{id:"训练",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#训练","aria-hidden":"true"},"#"),s(" 训练")],-1),G=n("h3",{id:"混合精度训练",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#混合精度训练","aria-hidden":"true"},"#"),s(" 混合精度训练")],-1),U={href:"http://wujiawen.xyz/archives/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83",target:"_blank",rel:"noopener noreferrer"},V=t(`<h3 id="梯度累加" tabindex="-1"><a class="header-anchor" href="#梯度累加" aria-hidden="true">#</a> 梯度累加</h3><p>可以近似地模拟大 batch：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>global_step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>training_set<span class="token punctuation">)</span><span class="token punctuation">:</span>
  loss <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>                    
  loss <span class="token operator">=</span> loss <span class="token operator">/</span> accumulation_steps                
  loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  
  global_step <span class="token operator">+=</span> <span class="token number">1</span>
  <span class="token keyword">if</span> global_step <span class="token operator">%</span> accumulation_steps <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>             
      optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                            
      model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                           
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="单机多卡训练" tabindex="-1"><a class="header-anchor" href="#单机多卡训练" aria-hidden="true">#</a> 单机多卡训练</h3>`,4),M={href:"https://zhuanlan.zhihu.com/p/56991108",target:"_blank",rel:"noopener noreferrer"},O=t(`<p>对于 torch，单机多卡可以使用 <code>DataParallel</code>（PS 架构，异步训练）。或者 <code>DistributedDataParallel</code> （Ring All-Reduce，同步训练）；对于 paddle，其中的 <code>DataParallel</code> 默认采用的已经是 Ring All-Reduce 了。使用单机多卡训练的操作也比较简介，通常只需要初始化多进程多卡，模型分配等环节即可，以下以 paddle 为例总结（torch 类似）。paddle 可以采用 paddle 的 spawn 或者通过 <code>paddle.distributed.launch</code> 开启多进程多卡训练。只要对单机单卡进行简单的修改即可：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 添加以下语句</span>
<span class="token keyword">from</span> paddle <span class="token keyword">import</span> distributed <span class="token keyword">as</span> dist
<span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    dist<span class="token punctuation">.</span>init_parallel_env<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> paddle<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通常多卡训练时的日志操作比较麻烦，常见的方法是使用 <code>get_rank()</code> 选择发布日志的进程，而后进行操作，如：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 只需要一个进程保存模型即可</span>
    
<span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_world_size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>  
    <span class="token comment"># 对所有进程的数据进行汇总，这边使用 ALL_GATHER,也可以用别的算子， 如 ALL_REDUCE</span>
    dist<span class="token punctuation">.</span>all_gather<span class="token punctuation">(</span>loss_list<span class="token punctuation">,</span> local_loss<span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>all_gather<span class="token punctuation">(</span>dev_loss_list<span class="token punctuation">,</span> dev_loss_tensor<span class="token punctuation">)</span>
    dist<span class="token punctuation">.</span>all_gather<span class="token punctuation">(</span>acc_list<span class="token punctuation">,</span> acc<span class="token punctuation">)</span>

    <span class="token keyword">if</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        logging_loss <span class="token operator">=</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>loss_list<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>
            loss_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        dev_loss <span class="token operator">=</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>dev_loss_list<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>
            dev_loss_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logging_acc <span class="token operator">=</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>acc_list<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>
            acc_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Step </span><span class="token interpolation"><span class="token punctuation">{</span>global_step<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_train_steps<span class="token punctuation">}</span></span><span class="token string"> train loss </span><span class="token interpolation"><span class="token punctuation">{</span>logging_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span>
                                            <span class="token string-interpolation"><span class="token string">f&quot; dev loss </span><span class="token interpolation"><span class="token punctuation">{</span>dev_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> acc </span><span class="token interpolation"><span class="token punctuation">{</span>logging_acc<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">% diff </span><span class="token interpolation"><span class="token punctuation">{</span>logging_diff<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span>
                                            <span class="token string-interpolation"><span class="token string">f&quot; time </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> time1<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">min&quot;</span></span>
                                            <span class="token punctuation">)</span>
        dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 阻塞其他进程，等待 0 号进程处理完毕。</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>多卡学习需要注意：</p><ul><li>batch size 与 学习率的调整</li><li>多卡下需要注意数据集的分配，可以使用 <code>DistributeBatchSampler</code> 来自动分配样本。</li><li>混合精度+多卡训练可能要预留一部分的显存出来，不然可能训练到一半发现 OOM 了</li></ul><h2 id="推理部署" tabindex="-1"><a class="header-anchor" href="#推理部署" aria-hidden="true">#</a> 推理部署</h2>`,7),W={href:"https://www.paddlepaddle.org.cn/tutorials/projectdetail/3952715",target:"_blank",rel:"noopener noreferrer"},K=t(`<h2 id="其他" tabindex="-1"><a class="header-anchor" href="#其他" aria-hidden="true">#</a> 其他</h2><h3 id="pdb-调试" tabindex="-1"><a class="header-anchor" href="#pdb-调试" aria-hidden="true">#</a> pdb 调试</h3><blockquote><p>pdb 调试更加灵活，可以使用条件判断语句，在代码中任意选择断点。这通常是 IDE 做不到的。</p></blockquote><p><strong>step1：</strong> 在想要进行调试的代码前插入<code>import pdb; pdb.set_trace()</code>开启 pdb 调试。</p><p><strong>step2：</strong> 正常运行.py 文件，在终端会出现下面类似结果，在<code>(Pdb)</code>位置后输入相应的 pdb 命令进行调试。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>&gt; /tmp/tmpm0iw5b5d.py(9)func()
-&gt; two = paddle.full(shape=[1], fill_value=2, dtype=&#39;int32&#39;)
(Pdb)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,6),X=n("strong",null,"step3：",-1),Y={href:"https://docs.python.org/zh-cn/3/library/pdb.html",target:"_blank",rel:"noopener noreferrer"},Z=t(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>l <span class="token comment"># 查看当前位置的源代码</span>
p expression <span class="token comment"># 查看上下文打印 expression 的值，如 p x</span>
s <span class="token comment"># 执行下一行，进入函数内部</span>
n <span class="token comment"># 执行下一行，不进入函数</span>
r <span class="token comment"># 执行代码到函数返回处</span>
b <span class="token number">30</span> <span class="token comment"># 在 30 行处设置断点</span>
c <span class="token comment"># 执行代码，直到下一个断点</span>
q <span class="token comment"># 退出调试</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="segmentation-fault-报错分析" tabindex="-1"><a class="header-anchor" href="#segmentation-fault-报错分析" aria-hidden="true">#</a> segmentation fault 报错分析</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-c</span>  <span class="token comment"># 查看 core 限制大小</span>
<span class="token comment"># 0</span>
<span class="token function">cat</span> /proc/sys/kernel/core_pattern <span class="token comment">#  查看 core 生成路径</span>
<span class="token comment"># core</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>现象：</p><p>我们执行生成 core 的文件并不是在 linux 的目录下，而是在 windows 和 linux 共享的 hgfs 下，导致生成的 core.xxx 都是 0 字节大小。</p>`,5),J={href:"https://so.csdn.net/so/search?q=%E6%A0%B9%E7%9B%AE%E5%BD%95&spm=1001.2101.3001.7020",target:"_blank",rel:"noopener noreferrer"},$={href:"https://zhuanlan.zhihu.com/p/201330829",target:"_blank",rel:"noopener noreferrer"},nn={href:"https://blog.csdn.net/dzhongjie/article/details/80280192",target:"_blank",rel:"noopener noreferrer"},sn=t(`<ul><li><p>修改 core 文件大小限制<code>ulimit -c unlimit</code></p></li><li><p>重新运行会 segmentation fault 的程序。</p></li><li><p>目录下生成 core 文件，检查 core 文件大小不为 0</p></li><li><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>gdb <span class="token variable"><span class="token variable">\`</span>whichi python<span class="token variable">\`</span></span> core 
<span class="token comment"># 用 python 解释器来进行 gdb core 分析</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><p>由于 docker 容器的权限问题，默认无法产生 core 文件，需要做一些配置修改。</p><p>在宿主机上修改 core 路径</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">echo</span> <span class="token string">&#39;/tmp/core.%t.%e.%p&#39;</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /proc/sys/kernel/core_pattern
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这是因为系统在产生 Core Dump 文件的时候是根据 /proc/sys/kernel/core_pattern 的设定。而默认的设定是 |/usr/share/apport/apport %p %s %c %P，也就是用管道传给 apport。然而 Docker 里面的系统不一定有装 apport，并且 /proc 又是直接挂到 Docker 里面的，所以我们就得改成放到固定的位置去，也就是 /tmp。</p><p>另外，在 docker run 的时候要加上以下参数</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token parameter variable">--ulimit</span> <span class="token assign-left variable">core</span><span class="token operator">=</span>-1 --security-opt <span class="token assign-left variable">seccomp</span><span class="token operator">=</span>unconfined
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="windows-环境还是很多坑" tabindex="-1"><a class="header-anchor" href="#windows-环境还是很多坑" aria-hidden="true">#</a> windows 环境还是很多坑</h3><p>尝试了 WSL2 下进行开发，还是感觉原先纯 LINUX 的环境更适应一点。Windows WSL 下存在 git 使用不方便，文件磁盘格式问题，文件权限有限等。</p><p>linux 和 windows 换行符：导致各种错误，如 pre-commit， sh 文件解析错误，markdown 文件解析错误等。解决方法： vim 中使用 <code>:set ff=unix</code> 或者 vscode 等编辑器中设置换行符为 lr</p>`,10);function an(en,tn){const a=i("ExternalLinkIcon");return o(),l("div",null,[d,r,n("p",null,[s("本文章对 NLP 论文复现的流程进行总结，包括模型编写、预训练权重转换；微调时候的大型数据处理、对卡训练、混合精度训练；模型推理部署。完整复现仓库："),n("a",u,[s("link"),e(a)])]),k,n("p",null,[s("此外从 TydiQA 源码中的算法来看，该团队的作风有些诡异。如"),n("a",h,[s("官方仓库"),e(a)]),s(" 中的：")]),m,n("p",null,[s("相关链接："),n("a",_,[s("动态图，静态图"),e(a)]),s("，"),n("a",b,[s("飞桨 动态图转静态图 "),e(a)]),s("，"),n("a",v,[s("飞桨产业级实践深度学习-"),e(a)])]),f,n("ul",null,[n("li",null,[s("需要注意控制流的使用方式，如 for range 等，详细可查看 "),n("a",g,[s("支持语法"),e(a)]),s("。")])]),w,n("table",null,[y,n("tbody",null,[x,n("tr",null,[D,A,E,n("td",null,[n("a",z,[s("知乎链接"),e(a)]),s(" ,计算每个样本的 offset，移动指针截取样本。")]),q]),B,N,P])]),T,n("ul",null,[n("li",null,[n("a",j,[s("num workers 和 dataloader"),e(a)]),s(" - 似乎不太起作用？个人测试对于小 batch size，提高 "),C,s(" 会有部分效果提升。")])]),I,L,H,Q,n("p",null,[s("相比于使用 pickle 或者 jsonl + 压缩的方式储存文件。H5DF 的数据处理方式更佳优雅，笔者个人也是推荐采用 h5df 的。关于 H5DF 的经验分享，欢迎参考我的博客 "),n("a",S,[s("H5DF | H5py 文档小整理"),e(a)]),s("。更多详细，请参考 "),n("a",F,[s("HDF5 官方文档链接"),e(a)])]),R,G,n("p",null,[s("混合精度训练，短短的几行代码，在节省显存占用 40%+，训练速度翻倍的前提下，能够做到模型准确率几乎不减少！该部分笔者也在个人博客 "),n("a",U,[s("混合精度训练"),e(a)]),s(" 中进行了整理。")]),V,n("p",null,[s("需要注意几个概念：模型并行与数据并行，Parameter Server 与 Ring All-Reduce，同步训练与异步训练。通常单机多卡采用数据并行，GPU 之间大多使用 Ring-All-reduce 进行同步。可以参考："),n("a",M,[s("一文说清楚 Tensorflow 分布式训练必备知识"),e(a)]),s(" 等。")]),O,n("p",null,[n("a",W,[s("paddle 产业级推理部署"),e(a)])]),K,n("p",null,[X,s(" 在 pdb 交互模式下输入 l、p 等命令可以查看相应的代码、变量，进而排查相关的问题。"),n("a",Y,[s("pdb 官方"),e(a)])]),Z,n("p",null,[s("解决： 把需要运行的程序拷贝到 linux 的"),n("a",J,[s("根目录"),e(a)]),s("下运行即可。"),n("a",$,[s("方案 1"),e(a)]),s(", "),n("a",nn,[s("方案 2"),e(a)])]),sn])}const on=p(c,[["render",an],["__file","笔记reproduction_summary.html.vue"]]);export{on as default};
