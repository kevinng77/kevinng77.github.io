const e=JSON.parse('{"key":"v-082c2445","path":"/posts/notes/articles/%E7%AC%94%E8%AE%B0hf_llm_board.html","title":"笔记 - Huggingface LLM 排行榜指标探索","lang":"zh-CN","frontmatter":{"title":"笔记 - Huggingface LLM 排行榜指标探索","date":"2023-07-01T00:00:00.000Z","author":"Kevin 吴嘉文","category":["知识笔记"],"tag":["NLP","AIGC"],"description":"Huggingface Open LLM Leaderboard 受到了大家的关注，该 LLM 排行榜使用了 ARC (25-s), HellaSwag (10-s), MMLU (5-s) 及 TruthfulQA (MC) 四个指标。但该排行榜也有不少的争议，如 falcon 和 LLaMa 的 MMLU 评分争议在前段时间就上了热门。本文主要对 Huggingface 排行榜上的四个指标进行介绍及尝试复现。 根据 Huggingface leaderboard 的说明，该排行榜使用了 lm-evaluation-harness 来进行指标计算。 lm-evaluation-harness 是一个专门为 LLM 进行 few shot 任务测评的工具，包括了 200 多种指标的测评。lm-evaluation-harness 输出的 LLM 评分文件，也可以直接用 Huggingface Leaderboard 官方提供的 load_results.py 来转换成 HF LLM 排行榜上的分数。","head":[["meta",{"property":"og:url","content":"http://wujiawen.xyz/posts/notes/articles/%E7%AC%94%E8%AE%B0hf_llm_board.html"}],["meta",{"property":"og:site_name","content":"记忆笔书"}],["meta",{"property":"og:title","content":"笔记 - Huggingface LLM 排行榜指标探索"}],["meta",{"property":"og:description","content":"Huggingface Open LLM Leaderboard 受到了大家的关注，该 LLM 排行榜使用了 ARC (25-s), HellaSwag (10-s), MMLU (5-s) 及 TruthfulQA (MC) 四个指标。但该排行榜也有不少的争议，如 falcon 和 LLaMa 的 MMLU 评分争议在前段时间就上了热门。本文主要对 Huggingface 排行榜上的四个指标进行介绍及尝试复现。 根据 Huggingface leaderboard 的说明，该排行榜使用了 lm-evaluation-harness 来进行指标计算。 lm-evaluation-harness 是一个专门为 LLM 进行 few shot 任务测评的工具，包括了 200 多种指标的测评。lm-evaluation-harness 输出的 LLM 评分文件，也可以直接用 Huggingface Leaderboard 官方提供的 load_results.py 来转换成 HF LLM 排行榜上的分数。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Kevin 吴嘉文"}],["meta",{"property":"article:tag","content":"NLP"}],["meta",{"property":"article:tag","content":"AIGC"}],["meta",{"property":"article:published_time","content":"2023-07-01T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"笔记 - Huggingface LLM 排行榜指标探索\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-07-01T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin 吴嘉文\\"}]}"]]},"headers":[{"level":2,"title":"环境准备","slug":"环境准备","link":"#环境准备","children":[]},{"level":2,"title":"MMLU   指标","slug":"mmlu-指标","link":"#mmlu-指标","children":[{"level":3,"title":"运行测评","slug":"运行测评","link":"#运行测评","children":[]},{"level":3,"title":"一些备注","slug":"一些备注","link":"#一些备注","children":[]}]},{"level":2,"title":"ARC 25-s","slug":"arc-25-s","link":"#arc-25-s","children":[{"level":3,"title":"运行测评","slug":"运行测评-1","link":"#运行测评-1","children":[]},{"level":3,"title":"其他备注","slug":"其他备注","link":"#其他备注","children":[]}]},{"level":2,"title":"TruthfulQA (MC) (0-s)","slug":"truthfulqa-mc-0-s","link":"#truthfulqa-mc-0-s","children":[{"level":3,"title":"运行测评","slug":"运行测评-2","link":"#运行测评-2","children":[]}]},{"level":2,"title":"HellaSwag (10-s)","slug":"hellaswag-10-s","link":"#hellaswag-10-s","children":[{"level":3,"title":"运行测评","slug":"运行测评-3","link":"#运行测评-3","children":[]}]},{"level":2,"title":"一点心得","slug":"一点心得","link":"#一点心得","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":7.34,"words":2202},"filePathRelative":"posts/notes/articles/笔记hf_llm_board.md","localizedDate":"2023年7月1日","excerpt":"<p>Huggingface Open LLM Leaderboard 受到了大家的关注，该 LLM 排行榜使用了 ARC (25-s), HellaSwag (10-s), MMLU (5-s) 及 TruthfulQA (MC) 四个指标。但该排行榜也有不少的争议，如 falcon 和 LLaMa 的 MMLU 评分争议在前段时间就上了热门。本文主要对 Huggingface 排行榜上的四个指标进行介绍及尝试复现。</p>\\n<p>根据 <a href=\\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Huggingface leaderboard</a>  的说明，该排行榜使用了 <a href=\\"https://github.com/EleutherAI/lm-evaluation-harness\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">lm-evaluation-harness</a> 来进行指标计算。 <a href=\\"https://github.com/EleutherAI/lm-evaluation-harness\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">lm-evaluation-harness</a> 是一个专门为 LLM 进行 few shot 任务测评的工具，包括了 200 多种指标的测评。lm-evaluation-harness 输出的 LLM 评分文件，也可以直接用 Huggingface Leaderboard 官方提供的 <a href=\\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/blob/main/src/auto_leaderboard/load_results.py\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">load_results.py</a> 来转换成 HF LLM 排行榜上的分数。</p>","autoDesc":true}');export{e as data};
