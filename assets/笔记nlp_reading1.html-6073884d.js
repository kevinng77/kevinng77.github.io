const s=JSON.parse('{"key":"v-50ab9a66","path":"/posts/notes/articles/%E7%AC%94%E8%AE%B0nlp_reading1.html","title":"NLP|阅读随笔","lang":"zh-CN","frontmatter":{"title":"NLP|阅读随笔","date":"2022-02-24T00:00:00.000Z","author":"Kevin 吴嘉文","category":["知识笔记"],"tag":["NLP"],"mathjax":true,"toc":true,"comments":"笔记","description":"内容覆盖深度学习初始化、标准化、正则等 关键词：BERT、Transformers、Xavier、LayerNorm、初始化 深度学习的初始化 从任意的均值为 0、方差为 1/m 的分布 p(x) 中独立重复采样，使得参数矩阵正交、以保持输入输出模不变 深度学习常采用的 Xavier 初始化 N(0,2din+dout)N(0, \\\\frac 2{d_{in}+d_{out}})N(0,din​+dout​2​) 。初始化方案为 bias 全 0，其他系数为 正交矩阵 。","head":[["meta",{"property":"og:url","content":"http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0nlp_reading1.html"}],["meta",{"property":"og:site_name","content":"记忆笔书"}],["meta",{"property":"og:title","content":"NLP|阅读随笔"}],["meta",{"property":"og:description","content":"内容覆盖深度学习初始化、标准化、正则等 关键词：BERT、Transformers、Xavier、LayerNorm、初始化 深度学习的初始化 从任意的均值为 0、方差为 1/m 的分布 p(x) 中独立重复采样，使得参数矩阵正交、以保持输入输出模不变 深度学习常采用的 Xavier 初始化 N(0,2din+dout)N(0, \\\\frac 2{d_{in}+d_{out}})N(0,din​+dout​2​) 。初始化方案为 bias 全 0，其他系数为 正交矩阵 。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-03-26T07:48:04.000Z"}],["meta",{"property":"article:author","content":"Kevin 吴嘉文"}],["meta",{"property":"article:tag","content":"NLP"}],["meta",{"property":"article:published_time","content":"2022-02-24T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-03-26T07:48:04.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"NLP|阅读随笔\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-02-24T00:00:00.000Z\\",\\"dateModified\\":\\"2023-03-26T07:48:04.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin 吴嘉文\\"}]}"]]},"headers":[{"level":2,"title":"深度学习的初始化","slug":"深度学习的初始化","link":"#深度学习的初始化","children":[]},{"level":2,"title":"Lipschitz 约束与 L2","slug":"lipschitz-约束与-l2","link":"#lipschitz-约束与-l2","children":[]},{"level":2,"title":"Transformer","slug":"transformer","link":"#transformer","children":[]},{"level":2,"title":"BERT 的一些细节","slug":"bert-的一些细节","link":"#bert-的一些细节","children":[]}],"git":{"createdTime":1679816884000,"updatedTime":1679816884000,"contributors":[{"name":"kevinng77","email":"417333277@qq.com","commits":1}]},"readingTime":{"minutes":11.08,"words":3323},"filePathRelative":"posts/notes/articles/笔记nlp_reading1.md","localizedDate":"2022年2月24日","excerpt":"<blockquote>\\n<p>内容覆盖深度学习初始化、标准化、正则等\\n关键词：BERT、Transformers、Xavier、LayerNorm、初始化</p>\\n</blockquote>\\n<!--more-->\\n<h2> 深度学习的初始化</h2>\\n<blockquote>\\n<p>从任意的均值为 0、方差为 1/m 的分布 p(x) 中独立重复采样，使得参数矩阵正交、以保持输入输出模不变</p>\\n</blockquote>\\n<p>深度学习常采用的 Xavier 初始化 <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>N</mi><mo stretchy=\\"false\\">(</mo><mn>0</mn><mo separator=\\"true\\">,</mo><mfrac><mn>2</mn><mrow><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></mfrac><mo stretchy=\\"false\\">)</mo></mrow><annotation encoding=\\"application/x-tex\\">N(0, \\\\frac 2{d_{in}+d_{out}})</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1.2902em;vertical-align:-0.4451em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.10903em;\\">N</span><span class=\\"mopen\\">(</span><span class=\\"mord\\">0</span><span class=\\"mpunct\\">,</span><span class=\\"mspace\\" style=\\"margin-right:0.1667em;\\"></span><span class=\\"mord\\"><span class=\\"mopen nulldelimiter\\"></span><span class=\\"mfrac\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8451em;\\"><span style=\\"top:-2.655em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">d</span><span class=\\"msupsub\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.3281em;\\"><span style=\\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\\"><span class=\\"pstrut\\" style=\\"height:2.5em;\\"></span><span class=\\"sizing reset-size3 size1 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">in</span></span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.143em;\\"><span></span></span></span></span></span></span><span class=\\"mbin mtight\\">+</span><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">d</span><span class=\\"msupsub\\"><span class=\\"vlist-t vlist-t2\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.2963em;\\"><span style=\\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\\"><span class=\\"pstrut\\" style=\\"height:2.5em;\\"></span><span class=\\"sizing reset-size3 size1 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mathnormal mtight\\">o</span><span class=\\"mord mathnormal mtight\\">u</span><span class=\\"mord mathnormal mtight\\">t</span></span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.143em;\\"><span></span></span></span></span></span></span></span></span></span><span style=\\"top:-3.23em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"frac-line\\" style=\\"border-bottom-width:0.04em;\\"></span></span><span style=\\"top:-3.394em;\\"><span class=\\"pstrut\\" style=\\"height:3em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mtight\\">2</span></span></span></span></span><span class=\\"vlist-s\\">​</span></span><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.4451em;\\"><span></span></span></span></span></span><span class=\\"mclose nulldelimiter\\"></span></span><span class=\\"mclose\\">)</span></span></span></span> 。初始化方案为 bias 全 0，其他系数为 <strong>正交矩阵</strong> 。</p>","autoDesc":true}');export{s as data};
