import{_ as o,E as p,S as i,W as c,$ as n,a3 as s,Z as e,aS as t}from"./framework-d5c0d2cb.js";const l={},u=t(`<p>RASA 感觉像是时代的眼泪了，自动 LLM 火了之后，类似 RASA 一类的传统 NLP 对话架构变得冷门，不少技术似乎也被摒弃。但如今不少厂家在实现对话机器人、智能服务等 AIGC 服务，却也会用到这类型的框架。市面上提供类似 RASA 服务的 low code 平台也不少，如 Nuance, Omilia, Kore.ai 等。</p><p>该系列文章主要围绕 RASA 源码，对落地部署传统 NLP 对话框架的相关话题展开。本文针对 RASA 自定义 NLU 功能展开。</p><p>RASA 默认的 NLU 策略不支持比如细腻度情感分析、指代消解等方案。通过自定义 NLU 模块，我们可以任意 NLU 方案，比如添加额外的实体链接、实体纠错、信息抽取模块。</p><h2 id="传统-nlp-对话框架" tabindex="-1"><a class="header-anchor" href="#传统-nlp-对话框架" aria-hidden="true">#</a> 传统 NLP 对话框架</h2><p>以下是一种传统的 NLP 对话框架，用户输入语句后，会经过 NLU 和 Dialog 两个模块，最后得到回复。</p><p>NLU 模块：</p><ol start="2"><li>使用各种算法对语句进行 Embedding，然后将各种 Embedding 拼接。（比如用 Conv 1D 抽取上下文意思，对语句中单词进行分词后进行额外 Embedding 等）</li><li>将拼接后的 Embedding 传入模型当中，如 LSTM，Transformer 等，得到 hidden state</li><li>将 hidden state 链接不同的 output layer 进行不同 NLU 任务的解析。比如链接 linear layer 做多分类或实体识别，链接 pointer Network 做关系抽取等等。</li><li>将所有意图整理在对话状态中，传入给 dialog 模块。</li></ol><p>对话模块（dialog 模块）</p><ol><li>采用 rule base：提前设计好用户故事线，以买咖啡为例；那么我们需要用条件语句，分别从用户那边问道咖啡的大小、甜度、加冰与否、打包还是堂食等信息（类似槽位填充）。在获得所有信息之后，对用户的咖啡进行下单。</li><li>采用其他方式：使用 rule base 的问题在于，我们需要多所有的场景进行规则构建，当用户问一点点规则以外的内容时，这个对话 session 可能会被影响，甚至打乱。因此有不少针对多轮对话的传统策略提出，比如将对话状态编码，与用户输入的 hidden state 一起生成回复等；或将用户输入与机器人的一些候选决策进行相关性匹配（RASA 的 Action 策略）。</li></ol><h2 id="rasa-架构" tabindex="-1"><a class="header-anchor" href="#rasa-架构" aria-hidden="true">#</a> RASA 架构</h2><p>RASA 的架构分成 nlu 模块和 core 模块。</p><p>Core 模块（即上文中的 dialog 模块）需要的操作有：</p><ol><li>写 Rule：定义如上文中提到的基于规则的对话逻辑</li><li>写故事： <ul><li>定义机器人的 Action，比如机器人可能会发送邮件，或者为客户下单一个咖啡，或者让客户付款。</li><li>准备一些多轮对话数据集作为训练集，用于训练模型的对话能力。比如训练集中会包含有用户提问以及机器人采取的对应 Action 信息。模型就会根据这部分信息，训练一个 Action 和 Query 匹配器。</li></ul></li></ol><p>NLU 需要的操作有：</p><ol><li>准备训练集：填写你要训练的 intent，entity 等信息。人工准备一些语料并针对不同任务进行打标签。</li><li>配置 NLU 流程：选择你要进行的 NLU 流程，比如你希望用哪些 Embedding 进行拼接。而后采用那个模型架构对拼接后的 Embedding 进行解析，得到 hidden state。最后用哪些解析器来讲 hidden state 转换为输出结果。</li><li>训练模型：RASA 提供了一键训练，训练速度和配置取决于你选择的 NLU 配置。</li></ol><p>当然如何配置 RASA NLU，可参考官方给出的详细文档。以下针对自定义 RASA NLU 模块做介绍。</p><h2 id="rasa-自定义-nlu" tabindex="-1"><a class="header-anchor" href="#rasa-自定义-nlu" aria-hidden="true">#</a> RASA 自定义 NLU</h2><h3 id="目录" tabindex="-1"><a class="header-anchor" href="#目录" aria-hidden="true">#</a> 目录</h3><p>该节展示了</p><ol><li>如何使用 Huggingface 上的模型，作为 RASA 的 embedding 工具。（默认 RASA 采用 TF 模型）</li><li>如何添加一个情感分析引擎（这在 RASA 中是没有的）。</li></ol><p>通过这个展示，我们能够延申到以下功能：</p><ol><li>参考这个代码，我们能够实现使用任何形式的模型作为我们的 Feature/Embedding 工具，比如 paddle, onnx 等。</li><li>当 RASA 默认的训练效果不好时，你应该意识到 RASA 的自带 Featurizer 存在很大问题：他不能够被训练。</li><li>RASA 默认使用 CLS 位置的 feature 作为 sentence embedding 进行分类，而其他位置的 feature 作为 sequence embedding 进行 NER 等任务。 <strong>大部分的 Transformer 使用了 SUB-TOKEN 的分词方式，而 RASA 默认的 NER 方式时将 subtoken 对应的 embedding 结合，作为完成 token 的 embedding。</strong></li><li>猜测：在 featurizer 中，没有输出任何完整 token 信息，估计在 NER 环节使用的 token 信息，是从 Tokenizer 传过去的，因此如果 Featurizer 输出 feature 维度和 Tokenizer 对应不上，就会报错。</li><li>RASA 训练策略比较单调，如果你享受调参等自定义模型训练方法。可以在自己机器上训练好权重，然后把他放在 RASA 中直接用，这将大大减少模型训练时间。最后通过自定义 Component 集成到 RASA 中。</li><li>我们能够在 RASA NLU 的基本功能（Intent，NER）上，添加上任意的 NLU 处理结果，比如添加额外的细腻度情感分析结果、添加额外的实体链接、实体纠错、信息抽取结果。</li></ol><h3 id="代码与实践" tabindex="-1"><a class="header-anchor" href="#代码与实践" aria-hidden="true">#</a> 代码与实践</h3><p>https://github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu</p><h4 id="rasa-配置文件-config-py-中的-pipeline" tabindex="-1"><a class="header-anchor" href="#rasa-配置文件-config-py-中的-pipeline" aria-hidden="true">#</a> RASA 配置文件 Config.py 中的 Pipeline</h4><p>Pipeline 由多个 RASA GraphComponent 组成，当用户发出消息后，消息会 <strong>依次</strong> 经过 Pipeline 的每一个 GraphComponent 处理，以完成 NLU。比如一下是一个经典的 Pipeline 写法：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pipeline:
  - name: &quot;WhitespaceTokenizer&quot;  
  - name: &quot;CountVectorsFeaturizer&quot;
  - name: &quot;DIETClassifier&quot;
    epochs: 100
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上面的 Pipeline 为例，rasa 进行 nlu 的时候，会从上到下进行每一个 GraphComponent。</p><p>如果用伪代码来表示这个流程，就是：</p><div class="language-PYTHON line-numbers-mode" data-ext="PYTHON"><pre class="language-PYTHON"><code># 毕竟是伪代码，因此逻辑不会很严谨
message = parse_user_input
# message 为数据结构，在 \`rasa.shared.nlu.training_data.message\` 可查看。
for GraphComponent in pipeline.name:
    message = GraphComponent.process(message)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每个 Component 可以在 <code>rasa.rasa.nlu</code> 文件夹下面找到，如 <code>WhitespaceTokenizer</code> 对应 <code>rasa.rasa.nlu.tokenizer.whitespace_tokenizer.WhitespaceTokenizer</code>。</p><h3 id="自定义-graphcomponent-for-nlu" tabindex="-1"><a class="header-anchor" href="#自定义-graphcomponent-for-nlu" aria-hidden="true">#</a> 自定义 GraphComponent (for NLU)</h3><p>使用自定义 NLU GraphComponent 需要以下几个步骤：</p><ol><li><p>写一个 <code>.py</code> 文件，里面定义好你要的 <code>GraphComponent</code>。本案例中的自定义 GraphComponent 都写在 Component 文件夹下面了。</p></li><li><p>在 Pipeline 中引用对应的 <code>GraphComponent</code></p></li></ol><h4 id="_1-定义-custom-graphcomponent" tabindex="-1"><a class="header-anchor" href="#_1-定义-custom-graphcomponent" aria-hidden="true">#</a> 1. 定义 Custom GraphComponent</h4><p>在 <code>rasa.data.test_classes</code> 中，我们能够看到一些官方提供的 <code>GraphComponent</code> 自定义方法和模板。如 <code>nlu_component_skeleton.py</code>。从下面的代码中可以看出，GraphComponent 主要的入口就是 <code>create</code>, <code>train</code>, <code>process</code>, <code>process_training_data</code> 四个方法。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@DefaultV1Recipe<span class="token punctuation">.</span>register</span><span class="token punctuation">(</span>
    <span class="token punctuation">[</span>DefaultV1Recipe<span class="token punctuation">.</span>ComponentType<span class="token punctuation">.</span>INTENT_CLASSIFIER<span class="token punctuation">]</span><span class="token punctuation">,</span> is_trainable<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">CustomNLUComponent</span><span class="token punctuation">(</span>GraphComponent<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">create</span><span class="token punctuation">(</span>
        cls<span class="token punctuation">,</span>
        config<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span>Text<span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">,</span>
        model_storage<span class="token punctuation">:</span> ModelStorage<span class="token punctuation">,</span>
        resource<span class="token punctuation">:</span> Resource<span class="token punctuation">,</span>
        execution_context<span class="token punctuation">:</span> ExecutionContext<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> GraphComponent<span class="token punctuation">:</span>
        <span class="token comment"># TODO: Implement this</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training_data<span class="token punctuation">:</span> TrainingData<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Resource<span class="token punctuation">:</span>
        <span class="token comment"># TODO: Implement this if your component requires training</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">process_training_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training_data<span class="token punctuation">:</span> TrainingData<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> TrainingData<span class="token punctuation">:</span>
        <span class="token comment"># TODO: Implement this if your component augments the training data with</span>
        <span class="token comment">#       tokens or message features which are used by other components</span>
        <span class="token comment">#       during training.</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

        <span class="token keyword">return</span> training_data

    <span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Message<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Message<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token comment"># TODO: This is the method which Rasa Open Source will call during inference.</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">return</span> messages
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>因此自定义的 <code>GraphComponent</code> 中，必须覆盖重写以上四个方法。我们根据 <code>rasa.rasa.nlu</code> 中的文件进行修改，尝试使用 pytorch 的模型来计算模型的 embedding。大致方法是继承 <code>rasa.nlu.featurizers.dense_featurizer.dense_featurizer</code> 中的 <code>DenseFeaturizer</code> 抽象类，</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@DefaultV1Recipe<span class="token punctuation">.</span>register</span><span class="token punctuation">(</span>
    DefaultV1Recipe<span class="token punctuation">.</span>ComponentType<span class="token punctuation">.</span>MESSAGE_FEATURIZER<span class="token punctuation">,</span> is_trainable<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">LanguageModelFeaturizer</span><span class="token punctuation">(</span>DenseFeaturizer<span class="token punctuation">,</span> GraphComponent<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment">#...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>具体查看该文件夹下的 <code>components/myintent.py</code>。比较值得注意的点是： <strong>默认情况下，所有的 Featurizer 都是不能被 train 的</strong> ，包括 RASA 自带的 TF transformers。而我们知道，Transformer 系列小模型在不微调的情况下，效果是不怎么好的。因此我们可以考虑，</p><ol><li>将 Featurizer 和 Intent Classifier 合并成一个 Compoent，而后统一在 RASA 中训练。</li><li>或者选个领域预训练+微调好的 embedding transformer</li><li>其他骚操作</li></ol><h4 id="_2-pipeline-中引用自定义模块" tabindex="-1"><a class="header-anchor" href="#_2-pipeline-中引用自定义模块" aria-hidden="true">#</a> 2. Pipeline 中引用自定义模块</h4><p>我们将原先的词袋模型替换为我们自定义的模型 <code>components.myintent.LanguageModelFeaturizer</code>， 并使用 huggingface 上的权重<code>kevinng77/TinyBERT_4L_312D_SIMCSE_finetune</code>，这便是自定义模型的好处之一：这是一个在个人 GPU 上蒸馏好的模型，速度比标准 bert 快 20+倍，且在 NLI 数据集上的精度（较 SIMCSE）保留了 98%。我们能够进一步对他进行量化、检索、推理部署等，以进一步提高预测速度。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>pipeline<span class="token punctuation">:</span>
  <span class="token operator">-</span> name<span class="token punctuation">:</span> <span class="token string">&quot;WhitespaceTokenizer&quot;</span>
  <span class="token operator">-</span> name<span class="token punctuation">:</span> components<span class="token punctuation">.</span>myintent<span class="token punctuation">.</span>LanguageModelFeaturizer
    model_name<span class="token punctuation">:</span> kevinng77<span class="token operator">/</span>TinyBERT_4L_312D_SIMCSE_finetune 
  <span class="token operator">-</span> name<span class="token punctuation">:</span> <span class="token string">&quot;DIETClassifier&quot;</span>
    epochs<span class="token punctuation">:</span> <span class="token number">100</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-我们添加额外的情感分析模块-从用户回答中提取更多信息" tabindex="-1"><a class="header-anchor" href="#_3-我们添加额外的情感分析模块-从用户回答中提取更多信息" aria-hidden="true">#</a> 3. 我们添加额外的情感分析模块，从用户回答中提取更多信息</h4><p>根据 <code>rasa.nlu</code> 下的代码，大致可以猜测到，整个 Pipeline 的 NLU 过程中，所有的结果都会被记录在 <code>Message</code> 上。</p><p>因此如果我们想要添加额外的 nlu 信息，如实体间关系、细腻度情感分析。那么，我们就可以自定义 <code>Component</code> 模块，而后通过 <code>process()</code> 函数，将 NLU 处理的结果添加到 <code>Message</code> 中就行。<code>Message</code> 中有 <code>data</code> 字典，可以用来储存其他特征信息。</p><p>比如说，我想要在 intent 分析和 NER 分析的基础上，加上一层情感分析：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">pipeline</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;WhitespaceTokenizer&quot;</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> components.myintent.LanguageModelFeaturizer
    <span class="token key atrule">model_name</span><span class="token punctuation">:</span> distilbert
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> components.sentiment_classifier.SentimentClassifier
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;DIETClassifier&quot;</span>
    <span class="token key atrule">epochs</span><span class="token punctuation">:</span> <span class="token number">50</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在 <code>components.sentiment_classifier.SentimentClassifier</code> 中，我们提供以下方法（具体可查看文件夹中代码）：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@DefaultV1Recipe<span class="token punctuation">.</span>register</span><span class="token punctuation">(</span>
    DefaultV1Recipe<span class="token punctuation">.</span>ComponentType<span class="token punctuation">.</span>INTENT_CLASSIFIER<span class="token punctuation">,</span> is_trainable<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">SentimentClassifier</span><span class="token punctuation">(</span>GraphComponent<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;Intent classifier using the Logistic Regression.&quot;&quot;&quot;</span>
    
    <span class="token comment"># ...</span>
    
	<span class="token keyword">def</span> <span class="token function">process</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Message<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Message<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;Return the most likely intent and its probability for a message.&quot;&quot;&quot;</span>

        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> message <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token punctuation">:</span>
            sentiment<span class="token punctuation">,</span> score <span class="token operator">=</span> <span class="token string">&quot;Positive&quot;</span><span class="token punctuation">,</span> <span class="token number">0.666</span>  <span class="token comment"># this should come from your model</span>
            message<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;sentiment&quot;</span><span class="token punctuation">,</span> sentiment<span class="token punctuation">,</span> add_to_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            message<span class="token punctuation">.</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">&quot;sentiment_confidence&quot;</span><span class="token punctuation">,</span> score<span class="token punctuation">,</span> add_to_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> messages
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么在输出结果中，我们就能看到 <code>Message.data</code> 中，多了情感分析的结果，执行以下语句进行测试 ：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>rasa train nlu
rasa shell
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>输入 <code>hello world</code>，系统回复内容中，就会多出来 <code>sentiment</code> 和 <code>sentiment_confidence</code> 两个字段了：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>NLU model loaded. Type a message and press enter to parse it.
Next message:
hello world
<span class="token punctuation">{</span>
  <span class="token string">&quot;text&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;hello world&quot;</span>,
  <span class="token string">&quot;intent&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;greet&quot;</span>,
    <span class="token string">&quot;confidence&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0.4089217782020569</span>
  <span class="token punctuation">}</span>,
  <span class="token string">&quot;entities&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>,
  <span class="token string">&quot;text_tokens&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span>
      <span class="token number">0</span>,
      <span class="token number">5</span>
    <span class="token punctuation">]</span>,
   <span class="token comment"># ...</span>
  <span class="token punctuation">]</span>,
  <span class="token string">&quot;sentiment&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Positive&quot;</span>,
  <span class="token string">&quot;sentiment_confidence&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0.666</span>,
  <span class="token string">&quot;intent_ranking&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;greet&quot;</span>,
      <span class="token string">&quot;confidence&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0.4089217782020569</span>
    <span class="token punctuation">}</span>,
	<span class="token comment">#...</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="rasa-nlu-部署" tabindex="-1"><a class="header-anchor" href="#rasa-nlu-部署" aria-hidden="true">#</a> RASA NLU 部署</h3><p>默认 RASA NLU 是单独部署成一个 API 的。因此我们可以讲实现好的自定义 NLU 模块部署成 API，而后进行测试。首先运行服务：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>rasa run --enable-api
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>发送 POST 请求到 <code>http://localhost:5005/model/parse</code>， body 中为：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token punctuation">{</span>
    <span class="token property">&quot;text&quot;</span><span class="token operator">:</span><span class="token string">&quot;what restaurants do you recomment?&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;sender&quot;</span><span class="token operator">:</span> <span class="token string">&quot;test_user&quot;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RASA 返回 Message 结果。而 Message 架构如下：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="language-json"><code><span class="token comment">// request 返回的结果</span>
<span class="token punctuation">{</span>
  <span class="token property">&quot;text&quot;</span><span class="token operator">:</span> <span class="token string">&quot;what restaurants do you recomment?&quot;</span><span class="token punctuation">,</span>  <span class="token comment">// 用户 query</span>
  <span class="token property">&quot;intent&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;query_knowledge_base&quot;</span><span class="token punctuation">,</span>
    <span class="token property">&quot;confidence&quot;</span><span class="token operator">:</span> <span class="token number">1.0</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token comment">// 最终判断意图</span>
  <span class="token property">&quot;entities&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span> <span class="token comment">// 所有实体抽取的结果</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;entity&quot;</span><span class="token operator">:</span> <span class="token string">&quot;object_type&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;start&quot;</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token property">&quot;end&quot;</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
      <span class="token property">&quot;value&quot;</span><span class="token operator">:</span> <span class="token string">&quot;restaurants&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;extractor&quot;</span><span class="token operator">:</span> <span class="token string">&quot;RegexEntityExtractor&quot;</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;entity&quot;</span><span class="token operator">:</span> <span class="token string">&quot;object_type&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;start&quot;</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token property">&quot;end&quot;</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
      <span class="token property">&quot;confidence_entity&quot;</span><span class="token operator">:</span> <span class="token number">0.9987316727638245</span><span class="token punctuation">,</span>
      <span class="token property">&quot;value&quot;</span><span class="token operator">:</span> <span class="token string">&quot;restaurants&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;extractor&quot;</span><span class="token operator">:</span> <span class="token string">&quot;DIETClassifier&quot;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">&quot;text_tokens&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token comment">// ... 所有 token 对应的 idx</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">&quot;intent_ranking&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;query_knowledge_base&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;confidence&quot;</span><span class="token operator">:</span> <span class="token number">1.0</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
      <span class="token property">&quot;name&quot;</span><span class="token operator">:</span> <span class="token string">&quot;greet&quot;</span><span class="token punctuation">,</span>
      <span class="token property">&quot;confidence&quot;</span><span class="token operator">:</span> <span class="token number">4.942866560497805e-9</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,62),r={href:"https://rasa.com/docs/rasa/pages/http-api",target:"_blank",rel:"noopener noreferrer"},d=t(`<h3 id="进一步解析结果来源" tabindex="-1"><a class="header-anchor" href="#进一步解析结果来源" aria-hidden="true">#</a> 进一步解析结果来源</h3><p>在 <code>rasa.server.create_app</code> 中，我们可以找到 NLU api 的入口：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>post</span><span class="token punctuation">(</span><span class="token string">&quot;/model/parse&quot;</span><span class="token punctuation">)</span>
<span class="token decorator annotation punctuation">@requires_auth</span><span class="token punctuation">(</span>app<span class="token punctuation">,</span> auth_token<span class="token punctuation">)</span>
<span class="token decorator annotation punctuation">@ensure_loaded_agent</span><span class="token punctuation">(</span>app<span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>request<span class="token punctuation">:</span> Request<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> HTTPResponse<span class="token punctuation">:</span>
    <span class="token comment"># NLU 处理</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span>response_data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中的 NLU 处理流程，我们可以在 <code>rasa.rasa.core.agent.Agent.parse_message</code> 查看到。</p><p>在上一个仓库<code>2-custom_nlu</code> 中，我们提到了 RASA nlu 的执行单元 <code>GraphComponent</code> 可以在 <code>rasa/rasa/nlu</code> ，如果你定义了这样一个 Pipeline：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">pipeline</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;WhitespaceTokenizer&quot;</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;CountVectorsFeaturizer&quot;</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;CountVectorsFeaturizer&quot;</span>
    <span class="token key atrule">analyzer</span><span class="token punctuation">:</span> <span class="token string">&quot;char_wb&quot;</span>
    <span class="token key atrule">min_ngram</span><span class="token punctuation">:</span> <span class="token number">1</span>
    <span class="token key atrule">max_ngram</span><span class="token punctuation">:</span> <span class="token number">4</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> RegexEntityExtractor
    <span class="token key atrule">use_regexes</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> components.diet_cls.DIETClassifier
    <span class="token key atrule">epochs</span><span class="token punctuation">:</span> <span class="token number">100</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么，NLU 处理的过程大概就是：</p><ol><li><p>通过<code>rasa/nlu/emulators</code> 预处理请求（可查看 <code>emulators.normalise_request_json</code>方法）。</p></li><li><p>在 <code>rasa/core/processor</code> 中将文本信息包装到 <code>Message</code> 中。此时的 <code>Message</code> 仅包括 <code>text</code> 等基础字段</p></li><li><p>通过 <code>rasa/nlu/tokneizers/whitespace_tokenizer</code> 中 <code>WhitespaceTokenizer.tokenize()</code> 往 <code>Message</code> 中添加 <code>text_tokens</code> 结果和字段。</p></li><li><p>通过 <code>rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py</code> 中 <code>CountVectorsFeaturizer.process()</code> ，往 <code>Message.features</code> 中添加 <code>features</code> 内容。（<code>Message.features</code> 中的所有内容仅被用于辅助 其他 NLU 环节处理，不会被当成最终结果返回）</p><blockquote><p>如果有多个 <code>featurizer</code>，那么他们的输出将会被统一储存在 <code>Message.features</code> 列表中。</p></blockquote></li><li><p>通过 <code>rasa/nlu/extractors/regex_entity_extractor.py</code> 中的 <code>RegexEntityExtractor.process()</code>，往 <code>Message</code> 中添加 <code>entities</code> 结果和字段。</p></li><li><p>通过 <code>rasa/nlu/classifier/diet_classifier.py</code> 中的 <code>DIETClassifier.process()</code>，往 <code>Message</code> 中添加 <code>intent</code>, <code>intent_ranking</code>, <code>entities</code> 结果和字段。</p></li><li><p>最终结果经过 <code>emulator.normalise_response_json</code> 后处理，被包装成 json 返回。</p></li></ol><h3 id="nlu-模块思考" tabindex="-1"><a class="header-anchor" href="#nlu-模块思考" aria-hidden="true">#</a> NLU 模块思考</h3><ol><li><p>整个 NLU 过程采用了几年前 NLU 领域特征工程大杂烩 + 基础模型训练的操作。你可以任意的添加 Features，但是 features 在最后进行意图识别，或者实体识别时候，将会以拼接的方式结合（如 <code>rasa.utils.tensorfloe.ConcatenateSparseDenseFeatures</code>），而后加上下游模型进行训练和预测。</p></li><li><p>如果要自定义 Intent 和 NER 模块，只需要重新包装好 <code>GraphComponent</code>，确保在 <code>process()</code> 方法中，将 <code>entities</code>， <code>intent</code>，<code>intent_ranking</code> 添加到 Message 中即可。</p></li><li><p>对于 RASA 中的 Transformer，意图识别默认使用 CLS 位置的 <code>hidden_state</code> 进行分类；实体抽取任务默认使用其他位置的 <code>hidden_state</code> 进行预测。预测的基础单位取决于 Pipeline 中的 <code>Tokenizer</code>。比如你使用了 <code>WhitespaceTokenizer</code>。假设用户输入 <code>say HelloWorld</code> ，那么大致的实体抽取流程会是：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokens <span class="token operator">=</span> <span class="token string">&quot;say HelloWorld&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
token_features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
    sub_token <span class="token operator">=</span> MybertTokenzier<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
    sub_token_feature <span class="token operator">=</span> MyBertModel<span class="token punctuation">(</span>sub_token<span class="token punctuation">)</span>
    token_feature <span class="token operator">=</span> combine<span class="token punctuation">(</span>sub_token_feature<span class="token punctuation">)</span> 
    token_features<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token_feature<span class="token punctuation">)</span>
NER_result <span class="token operator">=</span> my_ner_model<span class="token punctuation">(</span>token_features<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>部分 Transformer 模型在 tokenize 之前都会进行基础 tokenize（如 <code>.split()</code>）。但对那些不进行基础 tokenize 的 Transformer 模型，则会使 X 分布偏移，导致效果受影响。</p></li></ol><p>参考代码：</p>`,11),k={href:"https://link.zhihu.com/?target=https%3A//github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu",target:"_blank",rel:"noopener noreferrer"},m=n("h2",{id:"小结",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#小结","aria-hidden":"true"},"#"),s(" 小结")],-1),v=n("p",null,"不少 low code 对话系统开发平台的 NLU 模块与 RASA 几乎一致，后续的系列文章也会分析落地部署类似的 NLU 引擎，以及部署 huggingface NLU 模型实现高吞吐量方案。",-1),b=n("p",null,"印象中研究 RASA 也就一年前左右，而今 LLM 和 Agent 等 AIGC 话题的火热，使得 RASA 这样的对话框架受到的关注减少。不知多久后，RASA 会变成 NLP 的历史产物。",-1);function g(h,q){const a=p("ExternalLinkIcon");return i(),c("div",null,[u,n("p",null,[s("其他的 API 服务接口可以在 "),n("a",r,[s("RASA API"),e(a)]),s(" 查看。")]),d,n("p",null,[n("a",k,[s("https://github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clugithub.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu"),e(a)])]),m,v,b])}const y=o(l,[["render",g],["__file","笔记rasa1.html.vue"]]);export{y as default};
