import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{r as c,o as i,c as t,a as e,b as o,d as n,f as l}from"./app-4ea08187.js";const p={},r=l(`<h2 id="fooocus" tabindex="-1"><a class="header-anchor" href="#fooocus" aria-hidden="true">#</a> Fooocus</h2><p>https://github.com/lllyasviel/Fooocus</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">python entry_with_update.py --language zh --port 8000</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>主要启动函数在 <code>webui/generate_clicked(*args)</code></p><p>主要输入为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span></span>
<span class="line"><span style="color:#24292E;">    prompt, negative_prompt, style_selections,</span></span>
<span class="line"><span style="color:#24292E;">    performance_selection, aspect_ratios_selection, image_number, image_seed, sharpness, guidance_scale</span></span>
<span class="line"><span style="color:#24292E;">] </span><span style="color:#D73A49;">//</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> [base_model, refiner_model, refiner_switch] </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> lora_ctrls</span></span>
<span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> [input_image_checkbox, current_tab]</span></span>
<span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> [uov_method, uov_input_image]</span></span>
<span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> [outpaint_selections, inpaint_input_image, inpaint_additional_prompt]</span></span>
<span class="line"><span style="color:#24292E;">ctrls </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> ip_ctrls</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中</p><ul><li><code>prompt</code>：初始 prompt，并非模型推理时候的 prompt。</li><li><code>negative_prompt</code>：初始 negtive prompt。</li><li><code>style_selections</code>：style 以 prompt 的形式填充。</li><li><code>performance_selection</code>：fooocus 中提供了 <code>speed</code>, <code>quality</code>, <code>extreme speed</code> 三种方案分别采用 step 30, step 60 和 lcm 模式下（用的 lcm lora）的 step 8 进行推理。</li><li><code>aspect_ratios_selection</code>：图片大小</li><li><code>image_number</code>：fooocus 通过 for 循环生成图片，并非采用增大 batch size 实现。</li><li><code>image_seed</code>：关闭 random 之后就可以设置。</li><li><code>sharpness</code>：类似与锐化程度</li><li><code>guidance_scale</code>：有些地方叫做 <code>cfg scale</code>，可以根据模型训练时候的情况进行配置。</li></ul><ul><li><code>refiner_switch</code>：SDXL 中，从 base 切换到 <code>refine</code> 模型的时间点。通常取 0.8。</li><li><code>lora_ctrls</code>：要添加的 lora 模型以及对应的 weight。</li><li><code>input_image_checkbox</code> 和<code>current_tab</code>：fooocus 中提供了 <code>Upscale or Variantion</code>, <code>Image Prompt</code>, <code>Inpaint or Outpaint</code>, <code>Describe</code> 四种模式。</li><li><code>uov_method</code>：<code>Upscale or Variantion</code> 提供了 <code>Vary(Subtle)</code>, <code>Upscale(1.5x)</code> 等其他方案。</li><li><code>outpaint_selections</code>：支持 <code>[&#39;Left&#39;, &#39;Right&#39;, &#39;Top&#39;, &#39;Bottom&#39;]</code> 中的一项</li><li><code>ip_ctrls</code>: image prompt。支持输入几张图片，然后选择不同的图片参考模式。</li></ul><p>除了主要输出外，在 <code>modules.advanced_parameters</code> 中还有一些其他参数可以用来进一步配置推理，比如 <code>sampler</code>, <code>scheduler</code> 等</p><h3 id="推理分析" tabindex="-1"><a class="header-anchor" href="#推理分析" aria-hidden="true">#</a> 推理分析</h3><p>推理部分在 <code>modules.async_worker.py</code></p><h4 id="模型加载" tabindex="-1"><a class="header-anchor" href="#模型加载" aria-hidden="true">#</a> 模型加载</h4><p>fooocus 的模型加载有不同策略，个人喜欢采用</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">python</span><span style="color:#24292E;"> </span><span style="color:#032F62;">entry_with_update.py</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--language</span><span style="color:#24292E;"> </span><span style="color:#032F62;">zh</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--port</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">8000</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--always-gpu</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--disable-offload-from-vram</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>默认情况下，fooocus 会根据使用者的显卡，来选择不同的 VRAM offload 策略，感觉频繁的 offload 对显卡似乎不太好。</p><h4 id="prompt-处理" tabindex="-1"><a class="header-anchor" href="#prompt-处理" aria-hidden="true">#</a> prompt 处理</h4>`,17),d=l("<li><p>fooocus 会对文本进行简单的清洗：比如去除对于的空格或换行符等。</p></li><li><p><strong>wild card：</strong> 类似 auto 1111 的 wild card 插件，在 prompt 中如果出现 <code>__flower__</code> ，那么就会从 <code>wildcard/flower.txt</code> 中随机挑选 prompt 插入。</p></li><li><p><strong>添加 style：</strong> 根据选择的 <code>style</code>，在 prompt 中添加对应的内容。（参考 <code>sdxl_styles</code> 文件夹）。</p></li>",3),_=e("strong",null,"fooocus_expansion",-1),h=e("code",null,"Fooocus V2",-1),u={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},m=e("code",null,"fooocus_expansion.bin",-1),g=e("li",null,[e("p",null,[e("strong",null,"encoding："),o(" 采用 clip 模型（"),e("code",null,"ldm_patched/modules/sd/CLIP"),o("）进行 encoding，对每个 style 填充后的 prompt 和 neg prompt 分别进行编码。大概流程为：")])],-1),f=e("code",null,"tokenize_with_weights",-1),y=e("code",null,"(happy:1.5)",-1),v={href:"https://github.com/lllyasviel/Fooocus/blob/main/ldm_patched/modules/sd1_clip.py#L398",target:"_blank",rel:"noopener noreferrer"},b=e("code",null,'"This is a sample string with (parentheses) and (some other:1.5) special characters."',-1),k=e("code",null,"[('This is a sample string with ', 1.0), ('parentheses', 1.1), (' and ', 1.0), ('some other', 1.5), (' special characters.', 1.0)]",-1),x=e("code",null,"[(token, weight),] ",-1),w=l(`<li><p><code>encode_token_weights</code>：参考官方 <code>ClipTokenWeightEncoder</code> 的实现。假设 prompt 当中有存在 weight 的 token 那么对于这些有权重的 token，他们的 hidden state 会被进行调整，调整方式为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">z_empty </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> encode(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.special_tokens)</span></span>
<span class="line"><span style="color:#24292E;">z_token </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (z_token</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">z_empty)</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">weight </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> z_empty</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>总结来看，weight 是根据特殊 token 进行调整的。</p></li>`,1),E=l(`<ol start="6"><li>经过所有处理后，prompt 会被转化为</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">[[concat_hidden_state, {</span><span style="color:#032F62;">&quot;pooled_output&quot;</span><span style="color:#24292E;">: pool_hidden_state}]]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>的形式，其中 <code>concat_hidden_state</code> 为 torch tensor，shape 大致为 <code>[1, 77* num_style, 2048]</code> （具体 shape 根据模型而定，但 hidden state 均根据 <code>len_input</code> 这个维度拼接）</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>在推理过程中，可以缓存好出现频率高的 prompt 及其对应 hidden state。 对于部分 SD 落地应用，CLIP 的部分甚至可以变成离线任务，以此节省计算资源。</p></div><h4 id="图片-prompt" tabindex="-1"><a class="header-anchor" href="#图片-prompt" aria-hidden="true">#</a> 图片 prompt</h4><p>fooocus 支持使用 Ip-Adapter，controlnet canny， depth 等垫图操作。</p>`,6),A={href:"https://github.com/tencent-ailab/IP-Adapter",target:"_blank",rel:"noopener noreferrer"},C={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},D={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},I={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},F={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},P={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},z={href:"https://huggingface.co/lllyasviel/misc/tree/main",target:"_blank",rel:"noopener noreferrer"},V={href:"http://www.cse.cuhk.edu.hk/leojia/projects/color2gray/index.html",target:"_blank",rel:"noopener noreferrer"},L=l('<h4 id="扩散过程" tabindex="-1"><a class="header-anchor" href="#扩散过程" aria-hidden="true">#</a> 扩散过程</h4><p>sampler 的入口函数可以参考 fooocus 的 <code>ldm_patched.modules.samplers</code> 及 <code>ldm_patched.modules.sample</code>。</p><p>各个 sampler 的实现可以参考<code>k_diffusion.sampling</code> 。</p><h3 id="额外参数" tabindex="-1"><a class="header-anchor" href="#额外参数" aria-hidden="true">#</a> 额外参数</h3><ul><li><p><code>disable_preview</code>：可以关闭 UI 上的生成预览</p></li><li><p><code>sampler_name</code>：默认用的 <code>dpmpp_2m_sde_gpu</code>，可自定义采样方案。</p></li><li><p><code>scheduler_name</code>：默认用的 <code>karas</code>，可自定义扩散过程的迭代算法。</p></li><li><p><code>generate_image_grid</code>：在 UI 上，可以选择不以网格的形式展示生成的图片</p></li><li><p><code>overwrite_step</code>：自定义模型推理的总 step。</p></li><li><p><code>overwrite_switch</code>：自定义 base 切换到 refine 的时间点。</p></li><li><p><code>overwrite_width</code> 和 <code>overwrite_height</code>：自定义图片输出大小</p></li><li><p><code>overwrite_vary_strength</code> 和 <code>overwrite_upscale_strength</code>：进行图片 uov 模式时，自定义的 vary 或者 upscale 大小。</p></li><li><p><code>refiner_swap_method</code>：支持 <code>joint</code>, <code>separate</code> 和 <code>vae</code>。官方的描述是， Fooocus uses its own advanced k-diffusion sampling that ensures seamless, native, and continuous swap in a refiner setup，这样确保了扩散模型采样的一致性。</p></li><li><p><code>freeu_enabled</code></p></li><li><p><code>freeu_b1</code></p></li><li><p><code>freeu_b2</code></p></li><li><p><code>freeu_s1</code></p></li><li><p><code>freeu_s2</code></p></li><li><p><code>debugging_inpaint_preprocessor</code></p></li><li><p><code>inpaint_disable_initial_latent</code></p></li><li><p><code>inpaint_engine</code></p></li><li><p><code>inpaint_strength</code>：同 denoising_strength。越小，生成的图片越接近参考图。</p></li><li><p><code>inpaint_respective_field</code></p></li><li><p><code>mixing_image_prompt_and_vary_upscale</code></p></li><li><p><code>mixing_image_prompt_and_inpaint</code></p></li><li><p><code>controlnet_softness</code></p></li><li><p><code>canny_low_threshold</code></p></li><li><p><code>canny_high_threshold</code></p></li><li><p><code>adm_scaler_positive</code></p></li><li><p><code>adm_scaler_negative</code></p></li><li><p><code>adm_scaler_end</code></p></li><li><p><code>adaptive_cfg</code></p></li></ul>',5);function T(U,B){const s=c("ExternalLinkIcon");return i(),t("div",null,[r,e("ol",null,[d,e("li",null,[e("p",null,[_,o(" ：style 中使用 "),h,o(" 时，会对输入的 prompt 进行额外的填充，用微调后的 GPT 2 来对 prompt 进行扩展填充，此处使用的为 GPT 2 的架构，但词表改动较大。 (权重在该"),e("a",u,[o("连接"),n(s)]),o("下"),m,o(" 文件)")])]),g]),e("ul",null,[e("li",null,[e("p",null,[f,o(" ：如果 prompt 当中有如 "),y,o(" 类型的 prompt，那么这部分 prompt 回和 auto1111 进行类似的权重处理。源码在"),e("a",v,[o("这"),n(s)]),o("。比如输入为 "),b,o(" 的话，那么输入会先被处理成 "),k,o(" 而后进行 token，转化为 "),x,o(" 的形式")])]),w]),E,e("p",null,[o("image prompt 中主要采用 "),e("a",A,[o("IP-Adapter"),n(s)]),o(" 涉及到的模型有：")]),e("ul",null,[e("li",null,[e("p",null,[e("a",C,[o("clip_vision_vit_h.safetensors"),n(s)]),o("：")])]),e("li",null,[e("p",null,[e("a",D,[o("fooocus_ip_negative.safetensors"),n(s)]),o("：Fooocus 团队训练的 pre-computed negative embedding")])]),e("li",null,[e("p",null,[e("a",I,[o("ip-adapter-plus-face_sdxl_vit-h.bin"),n(s)]),o(" 或 "),e("a",F,[o("ip-adapter-plus_sdxl_vit-h.bin"),n(s)]),o("：IP-Adapter 的 sdxl 模型权重。Fooocus 使用的权重比 IP-Adapter 官方的要大一点。不确定是根据官方的权重进行微调还是有其他操作。")])]),e("li",null,[e("p",null,[e("a",P,[o("control-lora-canny-rank128.safetensors"),n(s)]),o("：canny 风格图片借鉴。")])]),e("li",null,[e("p",null,[e("a",z,[o("fooocus_xl_cpds_128.safetensors"),n(s)]),o("：fooocus 团队根据 "),e("a",V,[o("“Contrast Preserving Decolorization (CPD)”"),n(s)]),o(" 算法修改得到的模型，可以实现和 controlnet 中 depth 类似的功能。")])])]),L])}const j=a(p,[["render",T],["__file","笔记fooocus_note.html.vue"]]);export{j as default};
