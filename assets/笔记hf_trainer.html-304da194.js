const e=JSON.parse('{"key":"v-b32e9978","path":"/posts/notes/articles/%E7%AC%94%E8%AE%B0hf_trainer.html","title":"更方便的 Training","lang":"zh-CN","frontmatter":{"title":"更方便的 Training","date":"2023-05-15T00:00:00.000Z","author":"Kevin 吴嘉文","category":["知识笔记"],"tag":["NLP","AIGC"],"description":"Huggingface Training 本文参考 transformers 官方指南 link 经过几年的发展，transformers 的训练框架也变得成熟，在 bert 时代我们可能需要手写许多优化过程，当初 huggingface 快速上手中的示例代码，大部分还是类似以下的操作：","head":[["meta",{"property":"og:url","content":"http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0hf_trainer.html"}],["meta",{"property":"og:site_name","content":"记忆笔书"}],["meta",{"property":"og:title","content":"更方便的 Training"}],["meta",{"property":"og:description","content":"Huggingface Training 本文参考 transformers 官方指南 link 经过几年的发展，transformers 的训练框架也变得成熟，在 bert 时代我们可能需要手写许多优化过程，当初 huggingface 快速上手中的示例代码，大部分还是类似以下的操作："}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-07-27T15:28:00.000Z"}],["meta",{"property":"article:author","content":"Kevin 吴嘉文"}],["meta",{"property":"article:tag","content":"NLP"}],["meta",{"property":"article:tag","content":"AIGC"}],["meta",{"property":"article:published_time","content":"2023-05-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-07-27T15:28:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"更方便的 Training\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-05-15T00:00:00.000Z\\",\\"dateModified\\":\\"2023-07-27T15:28:00.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin 吴嘉文\\"}]}"]]},"headers":[{"level":3,"title":"训练超参梳理","slug":"训练超参梳理","link":"#训练超参梳理","children":[]},{"level":3,"title":"关键训练配置","slug":"关键训练配置","link":"#关键训练配置","children":[]},{"level":2,"title":"完成一次训练","slug":"完成一次训练","link":"#完成一次训练","children":[]}],"git":{"createdTime":1690471680000,"updatedTime":1690471680000,"contributors":[{"name":"kevinng77","email":"417333277@qq.com","commits":1}]},"readingTime":{"minutes":3.15,"words":945},"filePathRelative":"posts/notes/articles/笔记hf_trainer.md","localizedDate":"2023年5月15日","excerpt":"<h1> Huggingface Training</h1>\\n<blockquote>\\n<p>本文参考 transformers 官方指南 <a href=\\"https://huggingface.co/docs/transformers/perf_train_gpu_one\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">link</a></p>\\n</blockquote>\\n<p>经过几年的发展，transformers 的训练框架也变得成熟，在 bert 时代我们可能需要手写许多优化过程，当初 huggingface 快速上手中的示例代码，大部分还是类似以下的操作：</p>","autoDesc":true}');export{e as data};
