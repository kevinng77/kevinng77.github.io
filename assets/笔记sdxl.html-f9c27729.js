import{_ as o,E as p,S as i,W as l,$ as n,a3 as s,Z as e,aS as t}from"./framework-d5c0d2cb.js";const c={},r=n("h2",{id:"sdxl",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#sdxl","aria-hidden":"true"},"#"),s(" SDXL")],-1),u={href:"https://arxiv.org/abs/2307.01952",target:"_blank",rel:"noopener noreferrer"},d={href:"https://www.zhihu.com/people/bei-jing-de-wen-zhou-ren",target:"_blank",rel:"noopener noreferrer"},k=n("p",null,"https://zhuanlan.zhihu.com/p/643420260",-1),m=n("p",null,"总结来说，SDXL 相对于 SD 模型有以下改进：",-1),v={href:"https://github.com/mlfoundations/open_clip",target:"_blank",rel:"noopener noreferrer"},b={href:"https://github.com/openai/CLIP/tree/main",target:"_blank",rel:"noopener noreferrer"},_=n("li",null,"引入了尺寸和裁剪调节，以保留训练数据，防止其被丢弃，并更好地控制生成图像的裁剪方式。",-1),f=n("figure",null,[n("img",{src:"https://pic2.zhimg.com/80/v2-133be5225344e7881807328f6b7b4d05_1440w.webp",alt:"SDXL 论文截图",tabindex:"0",loading:"lazy"}),n("figcaption",null,"SDXL 论文截图")],-1),g=n("ol",{start:"3"},[n("li",null,[s("SD 对 LDM 的生成图流程做了改进，由 base, refiner, VAE 组成："),n("code",null,"base"),s(" 模型（也可以作为独立模型运行）生成图像作为输入，输入到 "),n("code",null,"refiner"),s(" 模型中，后者添加额外的高质量细节。")])],-1),h=n("figure",null,[n("img",{src:"https://pic3.zhimg.com/80/v2-28c9d29925f7e2e8b93ecd6b7b04b1c6_1440w.webp",alt:"SDXL 论文截图： SDXL 生成图片架构",tabindex:"0",loading:"lazy"}),n("figcaption",null,"SDXL 论文截图： SDXL 生成图片架构")],-1),y={href:"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",target:"_blank",rel:"noopener noreferrer"},w=t(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> diffusers <span class="token keyword">import</span> DiffusionPipeline
<span class="token keyword">import</span> torch

<span class="token comment"># load both base &amp; refiner</span>
base <span class="token operator">=</span> DiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span> variant<span class="token operator">=</span><span class="token string">&quot;fp16&quot;</span><span class="token punctuation">,</span> use_safetensors<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
base<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span>
refiner <span class="token operator">=</span> DiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span><span class="token punctuation">,</span>
    text_encoder_2<span class="token operator">=</span>base<span class="token punctuation">.</span>text_encoder_2<span class="token punctuation">,</span>
    vae<span class="token operator">=</span>base<span class="token punctuation">.</span>vae<span class="token punctuation">,</span>
    torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span>
    use_safetensors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    variant<span class="token operator">=</span><span class="token string">&quot;fp16&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
refiner<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Define how many steps and what % of steps to be run on each experts (80/20) here</span>
n_steps <span class="token operator">=</span> <span class="token number">40</span>
high_noise_frac <span class="token operator">=</span> <span class="token number">0.8</span>

prompt <span class="token operator">=</span> <span class="token string">&quot;A majestic lion jumping from a big stone at night&quot;</span>

<span class="token comment"># run both experts</span>
image <span class="token operator">=</span> base<span class="token punctuation">(</span>
    prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
    num_inference_steps<span class="token operator">=</span>n_steps<span class="token punctuation">,</span>
    denoising_end<span class="token operator">=</span>high_noise_frac<span class="token punctuation">,</span>
    output_type<span class="token operator">=</span><span class="token string">&quot;latent&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">.</span>images
image <span class="token operator">=</span> refiner<span class="token punctuation">(</span>
    prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
    num_inference_steps<span class="token operator">=</span>n_steps<span class="token punctuation">,</span>
    denoising_start<span class="token operator">=</span>high_noise_frac<span class="token punctuation">,</span>
    image<span class="token operator">=</span>image<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中，base 与 refiner 各自的推理步数由参数 <code>high_noise_frac</code> 决定。</p><p>假设总推理步数为 40，然后 <code>high_noise_frac=0.8</code>，那么 base 模型只进行 32 步推理：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># StableDiffusionXLPipeline 对 timesteps 的裁剪梳理</span>
<span class="token keyword">if</span> denoising_end <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>denoising_end<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token keyword">and</span> denoising_end <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> denoising_end <span class="token operator">&lt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    discrete_timestep_cutoff <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>
        <span class="token builtin">round</span><span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_train_timesteps
            <span class="token operator">-</span> <span class="token punctuation">(</span>denoising_end <span class="token operator">*</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_train_timesteps<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    num_inference_steps <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> ts<span class="token punctuation">:</span> ts <span class="token operator">&gt;=</span> discrete_timestep_cutoff<span class="token punctuation">,</span> timesteps<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    timesteps <span class="token operator">=</span> timesteps<span class="token punctuation">[</span><span class="token punctuation">:</span>num_inference_steps<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>refiner 大概只进行约 8 步:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># StableDiffusionXLImg2ImgPipeline 对 timesteps 的裁剪梳理</span>
<span class="token keyword">if</span> denoising_start <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    discrete_timestep_cutoff <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>
        <span class="token builtin">round</span><span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_train_timesteps
            <span class="token operator">-</span> <span class="token punctuation">(</span>denoising_start <span class="token operator">*</span> self<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>config<span class="token punctuation">.</span>num_train_timesteps<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    timesteps <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> ts<span class="token punctuation">:</span> ts <span class="token operator">&lt;</span> discrete_timestep_cutoff<span class="token punctuation">,</span> timesteps<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>timesteps<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="sdxl-lora" tabindex="-1"><a class="header-anchor" href="#sdxl-lora" aria-hidden="true">#</a> SDXL Lora</h3><p>参考 https://github.com/bmaltais/kohya_ss#tips-for-sdxl-training 的训练配置，参考以下 kohya 的训练代码：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">TF_ENABLE_ONEDNN_OPTS</span><span class="token operator">=</span><span class="token number">0</span>
accelerate launch <span class="token parameter variable">--num_cpu_threads_per_process</span><span class="token operator">=</span><span class="token number">2</span> <span class="token string">&quot;/workspace/kohya_ss/sdxl_train_network.py&quot;</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--enable_bucket</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--pretrained_model_name_or_path</span><span class="token operator">=</span><span class="token string">&quot;/workspace/models/stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors&quot;</span>  <span class="token punctuation">\\</span>
    <span class="token parameter variable">--train_data_dir</span><span class="token operator">=</span><span class="token string">&quot;/workspace/coffee_mini&quot;</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--resolution</span><span class="token operator">=</span><span class="token string">&quot;1024,1024&quot;</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--output_dir</span><span class="token operator">=</span><span class="token string">&quot;/workspace/stable-diffusion-webui/models/Lora&quot;</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--logging_dir</span><span class="token operator">=</span><span class="token string">&quot;/workspace/coffee_sdxl/logs&quot;</span> <span class="token parameter variable">--network_alpha</span><span class="token operator">=</span><span class="token string">&quot;8&quot;</span> <span class="token parameter variable">--network_dim</span><span class="token operator">=</span><span class="token number">8</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--save_model_as</span><span class="token operator">=</span>safetensors <span class="token parameter variable">--network_module</span><span class="token operator">=</span>networks.lora   <span class="token punctuation">\\</span>
    <span class="token parameter variable">--unet_lr</span><span class="token operator">=</span><span class="token number">0.0004</span> <span class="token parameter variable">--output_name</span><span class="token operator">=</span><span class="token string">&quot;sdxl_xiaokafei_mini_v1.0&quot;</span>             <span class="token punctuation">\\</span>
    <span class="token parameter variable">--lr_scheduler_num_cycles</span><span class="token operator">=</span><span class="token string">&quot;1&quot;</span> <span class="token parameter variable">--no_half_vae</span> <span class="token parameter variable">--learning_rate</span><span class="token operator">=</span><span class="token string">&quot;0.0004&quot;</span>        <span class="token punctuation">\\</span>
    <span class="token parameter variable">--lr_scheduler</span><span class="token operator">=</span><span class="token string">&quot;constant&quot;</span> <span class="token parameter variable">--train_batch_size</span><span class="token operator">=</span><span class="token string">&quot;2&quot;</span>        <span class="token punctuation">\\</span>
    <span class="token parameter variable">--max_train_steps</span><span class="token operator">=</span><span class="token string">&quot;400&quot;</span> <span class="token parameter variable">--save_every_n_epochs</span><span class="token operator">=</span><span class="token string">&quot;1&quot;</span> <span class="token parameter variable">--mixed_precision</span><span class="token operator">=</span><span class="token string">&quot;bf16&quot;</span>    <span class="token punctuation">\\</span>
    <span class="token parameter variable">--save_precision</span><span class="token operator">=</span><span class="token string">&quot;bf16&quot;</span> <span class="token parameter variable">--seed</span><span class="token operator">=</span><span class="token string">&quot;1234&quot;</span> <span class="token parameter variable">--caption_extension</span><span class="token operator">=</span><span class="token string">&quot;.txt&quot;</span> <span class="token parameter variable">--cache_latents</span>     <span class="token punctuation">\\</span>
    <span class="token parameter variable">--optimizer_type</span><span class="token operator">=</span><span class="token string">&quot;Adafactor&quot;</span> <span class="token parameter variable">--max_data_loader_n_workers</span><span class="token operator">=</span><span class="token string">&quot;2&quot;</span> <span class="token parameter variable">--clip_skip</span><span class="token operator">=</span><span class="token number">2</span>     <span class="token punctuation">\\</span>
    <span class="token parameter variable">--bucket_reso_steps</span><span class="token operator">=</span><span class="token number">64</span> <span class="token parameter variable">--xformers</span> <span class="token parameter variable">--bucket_no_upscale</span> <span class="token parameter variable">--noise_offset</span><span class="token operator">=</span><span class="token number">0.0</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--tokenizer_cache_dir</span><span class="token operator">=</span><span class="token string">&quot;/workspace/models/&quot;</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--optimizer_args</span> <span class="token assign-left variable">scale_parameter</span><span class="token operator">=</span>False <span class="token assign-left variable">relative_step</span><span class="token operator">=</span>False <span class="token assign-left variable">warmup_init</span><span class="token operator">=</span>False <span class="token punctuation">\\</span>
    <span class="token parameter variable">--gradient_checkpointing</span> <span class="token parameter variable">--cache_latents_to_disk</span> <span class="token parameter variable">--cache_text_encoder_outputs</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--network_train_unet_only</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在相同的训练素材下，即便近训练 <code>Unet</code>，也必须要开启 <code>gradient_checkpointing</code>。以上代码训练占用显存 10 GB，训练时长约 4 分钟。</p>`,10),q={href:"https://huggingface.co/docs/diffusers/training/lora",target:"_blank",rel:"noopener noreferrer"},x=n("h2",{id:"controlnet",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#controlnet","aria-hidden":"true"},"#"),s(" Controlnet")],-1),D={href:"https://arxiv.org/pdf/2302.05543.pdf",target:"_blank",rel:"noopener noreferrer"},S=t(`<figure><img src="https://pic4.zhimg.com/80/v2-59072b5b1fc68d75ac9c1121bb4c4a93_1440w.webp" alt="Controlnet 论文截图：Controlnet 模型架构，及推理示意图。" tabindex="0" loading="lazy"><figcaption>Controlnet 论文截图：Controlnet 模型架构，及推理示意图。</figcaption></figure><p>参考 huggingface diffusers 中 <code>StableDiffusionControlNetPipeline</code> 的实现，在每次进行 diffusion backward processing 时，controlnet text to image 大致可以表示为以下伪代码：</p><ol><li>首先计算出 SD Unet 所需的残差值 <code>down_block_res_samples</code> 及 <code>mid_block_res_sample</code>。（分别对应上图中 SD Middle Block 和 SD Decoder Block 对应的蓝色连线）</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 详细请参考 diffusers StableDiffusionControlNetPipeline __call__ 方法</span>

down_block_res_samples<span class="token punctuation">,</span> mid_block_res_sample <span class="token operator">=</span> self<span class="token punctuation">.</span>controlnet<span class="token punctuation">(</span>
                    control_model_input<span class="token punctuation">,</span>  <span class="token comment"># latent (input z)</span>
                    t<span class="token punctuation">,</span>  <span class="token comment"># Time T encoder hidden state</span>
                    encoder_hidden_states<span class="token operator">=</span>controlnet_prompt_embeds<span class="token punctuation">,</span>  <span class="token comment"># prompt encoder hidden state</span>
                    controlnet_cond<span class="token operator">=</span>image<span class="token punctuation">,</span>  <span class="token comment"># 如用 canny 图对应的 hidden state</span>
                    conditioning_scale<span class="token operator">=</span>cond_scale<span class="token punctuation">,</span>  <span class="token comment"># multi-controlnet 时用来控制权重的参数</span>
                    guess_mode<span class="token operator">=</span>guess_mode<span class="token punctuation">,</span>
                    return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>此外参考 <code>huggingface diffusers </code> <code>MultiControlNetModel</code> 的推理过程，在有多个 controlnet 情况下，<code>down_block_res_samples</code> 以及 <code> mid_block_res_sample</code> 则为所有风格的 controlnet 输出加和，如下伪代码，我们如果选择了对一张图片进行 reference only，而后对另一张进行 canny 控制，那么最后的<code>mid_block_res_sample</code> 即为两个不同 controlnet 输出 <code>mid_sample</code> 的总和:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code> <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>image<span class="token punctuation">,</span> scale<span class="token punctuation">,</span> controlnet<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>controlnet_cond<span class="token punctuation">,</span> conditioning_scale<span class="token punctuation">,</span> self<span class="token punctuation">.</span>nets<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            down_samples<span class="token punctuation">,</span> mid_sample <span class="token operator">=</span> controlnet<span class="token punctuation">(</span>
                sample<span class="token operator">=</span>sample<span class="token punctuation">,</span>
                <span class="token comment"># other params... )</span>

            <span class="token comment"># merge samples</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                down_block_res_samples<span class="token punctuation">,</span> mid_block_res_sample <span class="token operator">=</span> down_samples<span class="token punctuation">,</span> mid_sample
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                down_block_res_samples <span class="token operator">=</span> <span class="token punctuation">[</span>
                    samples_prev <span class="token operator">+</span> samples_curr
                    <span class="token keyword">for</span> samples_prev<span class="token punctuation">,</span> samples_curr <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>down_block_res_samples<span class="token punctuation">,</span> down_samples<span class="token punctuation">)</span>
                <span class="token punctuation">]</span>
                mid_block_res_sample <span class="token operator">+=</span> mid_sample
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>使用 Unet2DConditional 对噪声进行预测。</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 详细请参考 diffusers StableDiffusionControlNetPipeline __call__ 方法</span>
noise_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>unet<span class="token punctuation">(</span>
                    latent_model_input<span class="token punctuation">,</span>
                    t<span class="token punctuation">,</span>
                    encoder_hidden_states<span class="token operator">=</span>prompt_embeds<span class="token punctuation">,</span>
                    cross_attention_kwargs<span class="token operator">=</span>cross_attention_kwargs<span class="token punctuation">,</span>
                    down_block_additional_residuals<span class="token operator">=</span>down_block_res_samples<span class="token punctuation">,</span>
                    mid_block_additional_residual<span class="token operator">=</span>mid_block_res_sample<span class="token punctuation">,</span>
                    return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>参考 huggingface diffusers <code>unet_2d_blocks.py</code> 中 <code>CrossAttnDownBlock2D</code> 的实现，controlnet 对残差使用求和处理，而非张量拼接。</p><p>controlnet 原作者给出了一些 controlnet 模型权重： https://huggingface.co/lllyasviel/sd_control_collection/tree/main</p>`,10),L={href:"https://huggingface.co/docs/diffusers/using-diffusers/controlnet",target:"_blank",rel:"noopener noreferrer"},z=n("p",null,"在 stablediffusoin webui 中，可以使用 https://github.com/Mikubill/sd-webui-controlnet 插件。",-1),C=n("h2",{id:"参考",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#参考","aria-hidden":"true"},"#"),s(" 参考")],-1),X=n("p",null,"https://huggingface.co/docs/diffusers/using-diffusers/sdxl",-1),N={href:"https://huggingface.co/papers/2307.01952",target:"_blank",rel:"noopener noreferrer"},I={href:"https://arxiv.org/abs/2307.01952",target:"_blank",rel:"noopener noreferrer"};function P(T,E){const a=p("ExternalLinkIcon");return i(),l("div",null,[r,n("p",null,[s("来自论文："),n("a",u,[s("SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"),e(a)])]),n("p",null,[s("SDXL 不论在模型架构还是 diffusion pipeline 上都与 SD 不同。十分推荐 "),n("a",d,[s("Rocky Ding"),e(a)]),s(" 的 SDXL 分享：")]),k,m,n("ol",null,[n("li",null,[s("模型更大：UNet 是原先的 3 倍大（从参数量来看）。Text Encoder 部分，采用了 "),n("a",v,[s("OpenCLIP-ViT/G"),e(a)]),s(" and "),n("a",b,[s("CLIP-ViT/L"),e(a)]),s(" 作为 text encoding。")]),_]),f,g,h,n("p",null,[s("参考 "),n("a",y,[s("HF diffusers"),e(a)]),s(" 的代码实现：")]),w,n("p",null,[s("除了 kohya 外，SDXL LORA 训练也可以参考："),n("a",q,[s("huggingface train lora guide"),e(a)])]),x,n("p",null,[n("a",D,[s("Adding Conditional Control to Text-to-Image Diffusion Models"),e(a)])]),S,n("p",null,[s("在 huggingface diffuser 中，调用 controlnet 可以参考"),n("a",L,[s("该连接"),e(a)]),s("。")]),z,C,X,n("p",null,[n("a",N,[s("SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"),e(a)])]),n("p",null,[n("a",I,[s("SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"),e(a)])])])}const B=o(c,[["render",P],["__file","笔记sdxl.html.vue"]]);export{B as default};
