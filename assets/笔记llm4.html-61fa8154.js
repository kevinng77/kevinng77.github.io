const t=JSON.parse('{"key":"v-4e7e2df1","path":"/posts/notes/articles/%E7%AC%94%E8%AE%B0llm4.html","title":"Instruction Tuning 后时代的模型笔记（三）","lang":"zh-CN","frontmatter":{"title":"Instruction Tuning 后时代的模型笔记（三）","date":"2023-07-16T00:00:00.000Z","author":"Kevin 吴嘉文","category":["知识笔记"],"tag":["NLP","AIGC"],"description":"在前两篇笔记中，笔者记录了早些年的部分指令微调模型，他们大多数使用大规模的，多种类的公开数据集进行训练。在接下来的笔记中，我们会对 LLaMa 系列的一些指令微调模型进行整理，包括 Alpaca, Vicuna, WizardLM, WizardVicunaLM 等。 笔记 - Instruction Tuning 时代的模型 83 赞同 · 6 评论文章 笔记 - Instruction Tuning 时代的模型 (二)44 赞同 · 1 评论文章","head":[["meta",{"property":"og:url","content":"http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0llm4.html"}],["meta",{"property":"og:site_name","content":"记忆笔书"}],["meta",{"property":"og:title","content":"Instruction Tuning 后时代的模型笔记（三）"}],["meta",{"property":"og:description","content":"在前两篇笔记中，笔者记录了早些年的部分指令微调模型，他们大多数使用大规模的，多种类的公开数据集进行训练。在接下来的笔记中，我们会对 LLaMa 系列的一些指令微调模型进行整理，包括 Alpaca, Vicuna, WizardLM, WizardVicunaLM 等。 笔记 - Instruction Tuning 时代的模型 83 赞同 · 6 评论文章 笔记 - Instruction Tuning 时代的模型 (二)44 赞同 · 1 评论文章"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-16T10:19:36.000Z"}],["meta",{"property":"article:author","content":"Kevin 吴嘉文"}],["meta",{"property":"article:tag","content":"NLP"}],["meta",{"property":"article:tag","content":"AIGC"}],["meta",{"property":"article:published_time","content":"2023-07-16T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-07-16T10:19:36.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Instruction Tuning 后时代的模型笔记（三）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-07-16T00:00:00.000Z\\",\\"dateModified\\":\\"2025-07-16T10:19:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Kevin 吴嘉文\\"}]}"]]},"headers":[{"level":2,"title":"InstructGPT","slug":"instructgpt","link":"#instructgpt","children":[]},{"level":2,"title":"Alpaca","slug":"alpaca","link":"#alpaca","children":[]},{"level":2,"title":"Vicuna","slug":"vicuna","link":"#vicuna","children":[]},{"level":2,"title":"WizardLM","slug":"wizardlm","link":"#wizardlm","children":[]},{"level":2,"title":"WizardVicunaLM","slug":"wizardvicunalm","link":"#wizardvicunalm","children":[]},{"level":2,"title":"Guanaco","slug":"guanaco","link":"#guanaco","children":[]},{"level":2,"title":"小结","slug":"小结","link":"#小结","children":[]}],"git":{"createdTime":1752661176000,"updatedTime":1752661176000,"contributors":[{"name":"kevinng77","email":"417333277@qq.com","commits":1}]},"readingTime":{"minutes":9.87,"words":2962},"filePathRelative":"posts/notes/articles/笔记llm4.md","localizedDate":"2023年7月16日","excerpt":"<p>在前两篇笔记中，笔者记录了早些年的部分指令微调模型，他们大多数使用大规模的，多种类的公开数据集进行训练。在接下来的笔记中，我们会对 LLaMa 系列的一些指令微调模型进行整理，包括 Alpaca, Vicuna, WizardLM, WizardVicunaLM 等。</p>\\n<p><a href=\\"https://zhuanlan.zhihu.com/p/616830127\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">笔记 - Instruction Tuning 时代的模型 83 赞同 · 6 评论文章</a></p>\\n<p><a href=\\"https://zhuanlan.zhihu.com/p/617302168\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">笔记 - Instruction Tuning 时代的模型 (二)44 赞同 · 1 评论文章</a></p>","autoDesc":true}');export{t as data};
