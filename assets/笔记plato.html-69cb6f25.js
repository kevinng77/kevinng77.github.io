import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as m,c as p,a as s,b as a,d as n,f as t}from"./app-80ce1db6.js";const r="/assets/img/plato/image-20220925175603731.png",c="/assets/img/plato/image-20220925180010559.png",o="/assets/img/plato/image-20221002115449356.png",h="/assets/img/plato/image-20220928103258849.png",g="/assets/img/plato/image-20220928103320587.png",d="/assets/img/plato/image-20220928103339039.png",u="/assets/img/plato/image-20220928214127388.png",y="/assets/img/plato/image-20220929105506250.png",v="/assets/img/plato/image-20221005143858830.png",b={},_=t('<h1 id="对话模型-plato-系列论文笔记" tabindex="-1"><a class="header-anchor" href="#对话模型-plato-系列论文笔记" aria-hidden="true">#</a> 对话模型 PLATO 系列论文笔记</h1><p>最近又开始着迷对话系统了，于是花时间看了以下几个中文比较有意思的模型。本文对 PLATO，PLATO=2， PLATO-XL，PLATO-KAG 四篇论文进行笔记梳理与总结。</p><h2 id="plato" tabindex="-1"><a class="header-anchor" href="#plato" aria-hidden="true">#</a> PLATO</h2><p>论文：PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</p><h3 id="概述" tabindex="-1"><a class="header-anchor" href="#概述" aria-hidden="true">#</a> 概述</h3><p>比较早的论文了，论文一上来提出，如果直接使用 Bert 在小规模的对话数据集上微调对话任务，其效果是很差的，基于这些问题，论文给出了几点原因猜测：</p><ul><li>现实对话的分布与训练文本分布的差异是非常大的。</li><li>one-to-many relationship：对于一个问题，在不同场景下，可能可以有多种不同的、正确的回答。而常规的训练过程是一个 one-to-one 对话模式的训练。</li><li>Bert 模型本身对生成任务有局限性。</li></ul><p>针对以上问题，论文提出了以下解决方案：</p>',8),x=s("ul",null,[s("li",null,"在 Reddit 和 Twitter 数据上进行进一步预训练。"),s("li",null,[a("对话过程中，对于同一个问题，在不同场景下可以有不同的回答。因此 PLATO 用一个隐变量 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"z"),s("mo",null,"∈"),s("mo",{stretchy:"false"},"["),s("mn",null,"1"),s("mo",{separator:"true"},","),s("mi",null,"K"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"},"z\\in[1,K]")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∈"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mclose"},"]")])])]),a("，来建模 one-to-many 对话中的信息。隐变量的每个值，都会对应一种特定的对话意图。")]),s("li",null,"训练时用了 UniLM 的方案，模型采用与 BERT 相似的 Transformer Encoder 模型，训练时用不同掩码来实现不同的优化目标。")],-1),f=t('<h3 id="预训练方法" tabindex="-1"><a class="header-anchor" href="#预训练方法" aria-hidden="true">#</a> 预训练方法</h3><p>预训练方法如下，采用 bert-case 作为初始权重。</p><figure><img src="'+r+'" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>如上图，每一步训练都要进行两次前向传播。第一步负责进行 response generation 任务。</p><h4 id="response-generation" tabindex="-1"><a class="header-anchor" href="#response-generation" aria-hidden="true">#</a> response generation</h4><p><strong>输入：</strong> 隐变量 latent，历史对话内容 Context，回复 Response 三者的拼接，如下图。</p><figure><img src="'+c+'" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure>',7),w=s("p",null,[a("其中 Role Embeddings 用于标记说话的角色。(对于包含了外部知识背景的对话内容，如 Duconv 任务，额外知识对应位置的 Role Embedding 为 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"E"),s("mi",null,"c")])]),s("annotation",{encoding:"application/x-tex"},"E_c")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"c")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(")。Turn Embedding 用于标记当前对话轮数。")],-1),z=t('<p><strong>隐变量的计算</strong></p><p>大致的隐变量计算过程为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.embedding([context,response])  </span><span style="color:#6A737D;"># 通过 `context, response` 拼接后的 `embedding`</span></span>\n<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> gumbel_softmax(dense(X))  </span><span style="color:#6A737D;"># 形状 `[batch_size, num_latent]` </span></span>\n<span class="line"><span style="color:#24292E;">latent_embedding </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X.matmul(embedding_params)</span></span>\n<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>',3),L=s("code",null,"argmax",-1),k=s("code",null,"gumbel_softmax",-1),E={href:"https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L420",target:"_blank",rel:"noopener noreferrer"},A=s("p",null,[s("strong",null,"优化目标：")],-1),M=s("p",null,[a("采用 UniLM 的训练方式，对 Response 位置对应的输出 hidden state 计算经典的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"L"),s("mi",null,"L")])])]),s("annotation",{encoding:"application/x-tex"},"L_{NLL}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal mtight"},"LL")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("。")],-1),T=s("p",null,[a("同时对 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"B"),s("mi",null,"O"),s("mi",null,"W")])])]),s("annotation",{encoding:"application/x-tex"},"L_{BOW}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"BO"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"W")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 进行优化。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"B"),s("mi",null,"O"),s("mi",null,"W")])])]),s("annotation",{encoding:"application/x-tex"},"L_{BOW}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"BO"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"W")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 主要思想是，我们希望隐变量位置对应的 hidden state "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mi",null,"z")])]),s("annotation",{encoding:"application/x-tex"},"H_z")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，能够预测答案中包含了哪些 "),s("code",null,"token"),a("。大致代码思路如下，比较特别的是 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mi",null,"z")])]),s("annotation",{encoding:"application/x-tex"},"H_z")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 通过一次线性变换后，在计算交叉熵之前被拓展到了 "),s("code",null,"[batch_size, len_pred, num_tokens]"),a(" 维度，因为最后交叉熵的输入是通过 "),s("code",null,"expand"),a(" 得来的，因此计算出的 loss 与答案的顺序没有关系。")],-1),P=t(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">label </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> inputs[</span><span style="color:#032F62;">&quot;tgt_token&quot;</span><span style="color:#24292E;">][:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">:]  </span><span style="color:#6A737D;"># [batch size, len_pred]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bow_predictor </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> FC(</span><span style="color:#E36209;">name_scope</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.full_name() </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;.bow_predictor&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                                    </span><span style="color:#E36209;">size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.num_token_embeddings,  </span></span>
<span class="line"><span style="color:#24292E;">                        </span><span style="color:#6A737D;"># &quot;The number of tokens in vocabulary. &quot;</span></span>
<span class="line"><span style="color:#24292E;">                                    </span><span style="color:#E36209;">bias_attr</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">bow_logits </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bow_predictor(latent_embed)  </span><span style="color:#6A737D;"># [batch size, 1, num_tokens]</span></span>
<span class="line"><span style="color:#24292E;">outputs[</span><span style="color:#032F62;">&quot;bow_probs&quot;</span><span style="color:#24292E;">] </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.softmax(bow_logits)  </span><span style="color:#6A737D;"># [batch size, 1, num_tokens]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">bow_probs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> F.unsqueeze(outputs[</span><span style="color:#032F62;">&quot;bow_probs&quot;</span><span style="color:#24292E;">], [</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])  </span><span style="color:#6A737D;"># [batch size, len_pred, num_tokens]</span></span>
<span class="line"><span style="color:#24292E;">bow_probs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.expand(bow_probs, [</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, label.shape[</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">], </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])  </span></span>
<span class="line"><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.label_smooth </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    bow </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.cross_entropy(bow_probs, smooth_label, </span><span style="color:#E36209;">soft_label</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">ignore_index</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.padding_idx)</span></span>
<span class="line"><span style="color:#D73A49;">else</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    bow </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.cross_entropy(bow_probs, label, </span><span style="color:#E36209;">ignore_index</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.padding_idx)</span></span>
<span class="line"><span style="color:#24292E;">            bow </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.reduce_sum(bow, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            token_bow </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.reduce_sum(bow) </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> tgt_len</span></span>
<span class="line"><span style="color:#24292E;">            bow </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> layers.reduce_mean(bow)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),O={href:"https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L482",target:"_blank",rel:"noopener noreferrer"},D=s("h4",{id:"response-selection",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#response-selection","aria-hidden":"true"},"#"),a(),s("strong",null,"Response Selection")],-1),C=s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"S")])])]),s("annotation",{encoding:"application/x-tex"},"L_{RS}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"RS")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])],-1),S={href:"https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L338",target:"_blank",rel:"noopener noreferrer"},R=s("p",null,[a("而后通过隐变量 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Z")]),s("annotation",{encoding:"application/x-tex"},"Z")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z")])])]),a(" 对应位置的 hidden state（正样本和负样本各自有一个 hidden state）计算"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"S")])])]),s("annotation",{encoding:"application/x-tex"},"L_{RS}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"RS")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 损失为：")],-1),N=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",{mathvariant:"script"},"L"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"S")])]),s("mo",null,"="),s("mo",null,"−"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"p"),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mi",null,"l"),s("mi",null,"r")]),s("mo",null,"="),s("mn",null,"1"),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"r"),s("mo",{fence:"true"},")")]),s("mo",null,"−"),s("mi",null,"log"),s("mo",null,"⁡"),s("mi",null,"p"),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mi",null,"l"),s("msup",null,[s("mi",null,"r"),s("mo",{lspace:"0em",rspace:"0em"},"−")])]),s("mo",null,"="),s("mn",null,"0"),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"r"),s("mo",{lspace:"0em",rspace:"0em"},"−")]),s("mo",{fence:"true"},")")])]),s("annotation",{encoding:"application/x-tex"}," \\mathcal{L}_{R S}=-\\log p\\left(l_r=1 \\mid c, r\\right)-\\log p\\left(l_{r^{-}}=0 \\mid c, r^{-}\\right) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathcal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"RS")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0197em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mclose delimcenter",style:{top:"0em"}},")")]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2em","vertical-align":"-0.35em"}}),s("span",{class:"mop"},[a("lo"),s("span",{style:{"margin-right":"0.01389em"}},"g")]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size1"},"(")]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3419em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0197em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7027em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−")])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8213em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−")])])])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size1"},")")])])])])])])],-1),K=s("p",null,[s("strong",null,"总体优化目标")],-1),B=s("p",null,"总体的优化目标为以上介绍的三个损失的加权平均：",-1),W=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mo",null,"="),s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"L"),s("mi",null,"L")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"B"),s("mi",null,"O"),s("mi",null,"W")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"S")])])]),s("annotation",{encoding:"application/x-tex"}," L = L_{NLL} + L_{BOW} + L_{RS} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal mtight"},"LL")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"BO"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"W")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"RS")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),G=t(`<p>论文中没有提三个损失的权重，源码中有用于调整各个 loss 的超参，不过这些超参默认值都是 1。整个预训练用了 8 张 V100(32G) 训练了 2 周 。具体参数可以参考原论文。</p><h3 id="推理过程" tabindex="-1"><a class="header-anchor" href="#推理过程" aria-hidden="true">#</a> 推理过程</h3><p>对于一个历史对话 <code>context</code>：</p><ul><li>首先给 <code>context</code> 添加上不同类型的 <code>latent_embed</code>。原本输入为 <code>batch size</code> 条，变换后，变成了 <code>batch size * num_latent</code> 条。</li><li>对 <code>batch_size * num_latent</code> 条输入分别进行预测，得到所有 latent 对应的回复 。</li><li>通过 Response selection 阶段训练的判别器，对所有生成进行打分，选取分数高的作为最终回复。</li></ul><h3 id="模型使用" tabindex="-1"><a class="header-anchor" href="#模型使用" aria-hidden="true">#</a> 模型使用</h3><p>PLATO 采用 <code>UnifiedTransformerModel</code>。对应的使用方法在 PaddleNLP 中可查看到。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> paddlenlp.transformers </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> UnifiedTransformerModel</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> paddlenlp.transformers </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> UnifiedTransformerTokenizer</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> UnifiedTransformerModel.from_pretrained(</span><span style="color:#032F62;">&#39;plato-mini&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">tokenizer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> UnifiedTransformerTokenizer.from_pretrained(</span><span style="color:#032F62;">&#39;plato-mini&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">history </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;我爱祖国&#39;</span></span>
<span class="line"><span style="color:#24292E;">inputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> tokenizer.dialogue_encode(</span></span>
<span class="line"><span style="color:#24292E;">    history,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">return_tensors</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">is_split_into_words</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">outputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model(</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">inputs)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="plato-2" tabindex="-1"><a class="header-anchor" href="#plato-2" aria-hidden="true">#</a> PLATO-2</h2><p>来自论文 PLATO-2: Towards Building an OpeDomain Chatbot via Curriculum Learning</p><p>PLATO-2 为 PLATO 升级版，除了模型规模不同外，其与 PLATO 的主要差别在于预训练的方式。此外 PLATO-2 用的是依旧是 Transformer encoder 架构，但是采用了 <code>pre-normalization</code>。</p><p>PLATO-2 效果如下：</p><figure><img src="`+o+'" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><h3 id="预训练过程" tabindex="-1"><a class="header-anchor" href="#预训练过程" aria-hidden="true">#</a> 预训练过程</h3><p>文中提出了 curriculum learning 的预训练方案。</p><h4 id="step-1" tabindex="-1"><a class="header-anchor" href="#step-1" aria-hidden="true">#</a> Step 1</h4><figure><img src="'+h+'" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>不采用 latent embedding， 直接利用 UniLM 的方式，在正常的生成任务上优化传统的 NLL loss。</p><h4 id="step-2-1" tabindex="-1"><a class="header-anchor" href="#step-2-1" aria-hidden="true">#</a> Step 2.1</h4><figure><img src="'+g+`" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>首先计算 <code>latent_embed</code>，该操作于 PLATO 不同。PLATO 中计算 <code>latent_embed</code> 的方式大致为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.embedding([context, response])</span></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> gumbel_softmax(dense(x))</span></span>
<span class="line"><span style="color:#24292E;">latent_embed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x.matmul(latent_embed_params)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而 PLATO-2 则采用了</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model([context, response])</span></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> gumbel_softmax(dense(x))</span></span>
<span class="line"><span style="color:#24292E;">latent_embed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x.matmul(latent_embed_params)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>差别就在于计算 <code>x</code> 过程中，PLATO-2 用的是整个 encoder 进行编码，这也会更耗时。</p>`,24),q=s("code",null,"latent_embed",-1),X=s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"L"),s("mi",null,"L")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"B"),s("mi",null,"O"),s("mi",null,"W")])])]),s("annotation",{encoding:"application/x-tex"},"L_{NLL} + L_{BOW}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal mtight"},"LL")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"BO"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"W")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])],-1),F=s("strong",null,"优化方法与 PLATO 相同。",-1),U={href:"https://github.com/PaddlePaddle/Knover/blob/ab547f0ba03c9142183d97c2ee6ed7a1c3750125/knover/models/plato.py#L151",target:"_blank",rel:"noopener noreferrer"},V=s("h4",{id:"step-2-2",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#step-2-2","aria-hidden":"true"},"#"),a(" Step 2.2")],-1),H=s("figure",null,[s("img",{src:d,alt:"相关图片",tabindex:"0",loading:"lazy"}),s("figcaption",null,"相关图片")],-1),I=s("p",null,[a("额外训练一个打分器，如图所示，优化的目标和 BERT 预训练时相同，为 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"M"),s("mi",null,"L"),s("mi",null,"M")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"S"),s("mi",null,"P")])])]),s("annotation",{encoding:"application/x-tex"},"L_{MLM} + L_{NSP}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"M"),s("span",{class:"mord mathnormal mtight"},"L"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"M")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"NSP")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 。其中 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"S"),s("mi",null,"P")])])]),s("annotation",{encoding:"application/x-tex"},"L_{NSP}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"NSP")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 与图中的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"R"),s("mi",null,"C"),s("mi",null,"E")])])]),s("annotation",{encoding:"application/x-tex"},"L_{RCE}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"RCE")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 大同小异，原理都是预测 "),s("code",null,"Response"),a(" 是否为 "),s("code",null,"Context"),a(" 的下一句话。")],-1),J=s("p",null,[a("该步骤与 PLATO 中的 Response Selection 对应，只是在 PLATO-2 中，优化目标多了一个 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"M"),s("mi",null,"L"),s("mi",null,"M")])])]),s("annotation",{encoding:"application/x-tex"},"L_{MLM}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"M"),s("span",{class:"mord mathnormal mtight"},"L"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"M")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])],-1),Z=s("h3",{id:"推理",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#推理","aria-hidden":"true"},"#"),a(" 推理")],-1),j=s("p",null,"推理过程同 PLATO，先生成所有 latent 对应的回复，然后在用 step 2.2 训练来的打分器打分。",-1),Q=s("h3",{id:"任务式对话",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#任务式对话","aria-hidden":"true"},"#"),a(" 任务式对话")],-1),Y={href:"https://arxiv.org/abs/2102.02096",target:"_blank",rel:"noopener noreferrer"},$={href:"https://zhuanlan.zhihu.com/p/423748187",target:"_blank",rel:"noopener noreferrer"},ss=t('<h3 id="其他" tabindex="-1"><a class="header-anchor" href="#其他" aria-hidden="true">#</a> 其他</h3><p>有网友提到第一阶段的预训练花了 1.8M 个 STEP，LOSS 仅下降到 2.66。作者建议 24L 模型的学习率可以用 5e-4 或者更大，Knover 中 24L PLATO 默认的学习率是 <code>1e-3</code>。</p><p>论文 STEP 2 采用了多种学习方案，但是并没有消融实验。此外作者并没有公布中文数据集的具体来源。隐约感觉，PLATO-2 的好效果绝大部分来源于语料？</p><p>PLATO-2 的 ISSUE 中提到，论文中 table 6 的 batch size 是根据 token 数量来计算的。源码中给到的 batch size 是 8169，通过语料的平均 token 长度换算过来的话，源码中的 batch size 会稍微大一些。</p><p>PLATO-2 的预训练权重目前只开源了英文版的，想要中文版的话只能自己收集中文数据集训练了。</p><h2 id="plato-xl" tabindex="-1"><a class="header-anchor" href="#plato-xl" aria-hidden="true">#</a> PLATO-XL</h2><p>来自论文 PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation</p><p>PLATO-XL 仍然采用于 PLATO-2 相同的架构，只是规模变大了，训练方法和预料也有所不同。 PLATO-XL 的训练代码似乎并没有开源，仅英文预训练权重有开源。论文中大致介绍了大模型效果更好，以及一些大模型训练及推理的解决方案。相比于 PLATO-2，PLATO-XL 似乎想说明：花里胡哨的训练，不如大模型，好语料来的管用。</p><h3 id="模型训练" tabindex="-1"><a class="header-anchor" href="#模型训练" aria-hidden="true">#</a> 模型训练</h3>',9),as=s("p",null,[a("模型的优化目标只剩下一个 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"L"),s("mrow",null,[s("mi",null,"N"),s("mi",null,"L"),s("mi",null,"L")])])]),s("annotation",{encoding:"application/x-tex"},"L_{NLL}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"L"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal mtight"},"LL")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 了。")],-1),ls=s("p",null,[a("相比于 PLATO-2，PLATO-XL 的训练预料中，考虑到了多人对话的场景。因此文章提出了 Multi-Party Aware Pre-training，即在 "),s("code",null,"role_embedding"),a(" 中区分 2 个以上的角色（在 PLATO-2 中，只有机器和用户两个角色，因此只用 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"E"),s("mi",null,"a")])]),s("annotation",{encoding:"application/x-tex"},"E_a")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"a")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 和 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"E"),s("mi",null,"b")])]),s("annotation",{encoding:"application/x-tex"},"E_b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"b")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 进行区分）。")],-1),ns=s("p",null,[a("由于模型规模大，因此 "),s("code",null,"pre-normalization"),a(" 和 "),s("code",null,"scaled_initialization"),a(" 都被采用了，以此提高训练效果。整个训练用了 256 张 V100 32G，训练周期未知。效果如下图：")],-1),ts=s("figure",null,[s("img",{src:u,alt:"相关图片",tabindex:"0",loading:"lazy"}),s("figcaption",null,"相关图片")],-1),es={href:"https://github.com/PaddlePaddle/PaddleNLP/blob/develop/model_zoo/plato-xl/infer.py",target:"_blank",rel:"noopener noreferrer"},is=s("h2",{id:"plato-kag",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#plato-kag","aria-hidden":"true"},"#"),a(" PLATO-KAG")],-1),ms=s("p",null,"来自论文 PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling。",-1),ps={href:"https://github.com/PaddlePaddle/Knover/blob/develop/knover/models/plato_kag.py",target:"_blank",rel:"noopener noreferrer"},rs=s("h3",{id:"模型训练-1",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#模型训练-1","aria-hidden":"true"},"#"),a(" 模型训练")],-1),cs=s("p",null,"模型训练流程如下，整个模型采用 PLATO-2 的权重进行初始化。",-1),os=s("figure",null,[s("img",{src:y,alt:"相关图片",tabindex:"0",loading:"lazy"}),s("figcaption",null,"相关图片")],-1),hs=s("p",null,[s("strong",null,"Knowledge Selection")],-1),gs=s("p",null,[a("用同一个编码器编码 "),s("code",null,"Context"),a(" 以及 "),s("code",null,"Knowledge"),a(" 片段，得到隐状态 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"E")]),s("annotation",{encoding:"application/x-tex"},"E")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E")])])]),a("。而后通过 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"z"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"W"),s("mi",null,"c")]),s("mi",null,"E"),s("mo",{stretchy:"false"},"("),s("mi",null,"c"),s("mo",{stretchy:"false"},")"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mi",null,"T")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"W"),s("mi",null,"z")]),s("mi",null,"E"),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"f(c,z) = (W_cE(c))^T(W_zE(z))")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0913em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"c")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},"))")])])]),a(" 计算 "),s("code",null,"context"),a(" 和 "),s("code",null,"knowledge"),a(" 片段的相似度。")],-1),ds=s("p",null,[a("在计算损失时，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"z"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"f(c,z)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},")")])])]),a(" 计算 "),s("code",null,"softmax"),a("，而后只对 Top K 个 "),s("code",null,"knowledge"),a(" 对应的 "),s("code",null,"softmax"),a(" 进行优化。")],-1),us=t('<p>论文中对 不同的 K 值进行了测试，结果展示了，在训练时选择 Top 8 个相关知识片段进行训练，模型最终的 PPL 和 Recall 都会更好。</p><figure><img src="'+v+'" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>但是 K 越大，对应的训练资源要求就越大，实验中 <code>k=2</code> 时，其效果也不比 <code>k=8</code> 小多少。</p><p><strong>Response Generation</strong></p><p>由于上一个任务中，选出了 Top K 个可能合适的知识片段，因此在生成任务中，我们需要对这些片段逐一进行拼接、预测和优化。</p><p>如原输入形状为 <code>[batch_size, len_seq]</code>， 那么训练过程中预测结果的形状就会是 <code>[batch_size * K, len_seq]</code></p><p><strong>Balanced Joint Training</strong></p>',7),ys={href:"https://github.com/PaddlePaddle/Knover/blob/develop/knover/models/plato_kag.py#L343",target:"_blank",rel:"noopener noreferrer"},vs=s("p",null,[a("文中提到了使用超参 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α")]),s("annotation",{encoding:"application/x-tex"},"\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α")])])]),a(" 来调整两个损失之间的权重，即整个优化目标为：")],-1),bs=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("mi",null,"r"),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{stretchy:"false"},")"),s("mo",null,"∝"),s("munder",null,[s("mo",null,"∑"),s("mi",null,"z")]),s("msub",null,[s("mi",null,"p"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{stretchy:"false"},")"),s("msup",null,[s("mrow",null,[s("mo",{fence:"true"},"("),s("munderover",null,[s("mo",null,"∏"),s("mi",null,"t"),s("mi",null,"T")]),s("msub",null,[s("mi",null,"p"),s("mi",null,"ϕ")]),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mi",null,"r"),s("mi",null,"t")]),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"z"),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mo",null,"<"),s("mi",null,"t")])]),s("mo",{fence:"true"},")")]),s("mo",{fence:"true"},")")]),s("mi",null,"α")])]),s("annotation",{encoding:"application/x-tex"}," p(r \\mid c) \\propto \\sum_z p_\\theta(z \\mid c)\\left(\\prod_t^T p_\\phi\\left(r_t \\mid c, z, r_{<t}\\right)\\right)^\\alpha ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∝"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3em","vertical-align":"-1.25em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.1327em","vertical-align":"-1.25em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"(")]),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8283em"}},[s("span",{style:{top:"-1.9em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∏")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.25em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"ϕ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mrel mtight"},"<"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1774em"}},[s("span")])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},")")]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},")")])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8826em"}},[s("span",{style:{top:"-4.2812em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.0037em"}},"α")])])])])])])])])])])])],-1),_s=s("p",null,[a("其中 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"p"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"c"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"p_{\\theta}(z|c)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mclose"},")")])])]),a(" 为 Knowledge Selection 对应的概率。生成任务的概率 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mo",null,"∏"),s("mi",null,"t"),s("mi",null,"T")]),s("msub",null,[s("mi",null,"p"),s("mi",null,"ϕ")]),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mi",null,"r"),s("mi",null,"t")]),s("mo",null,"∣"),s("mi",null,"c"),s("mo",{separator:"true"},","),s("mi",null,"z"),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mo",null,"<"),s("mi",null,"t")])]),s("mo",{fence:"true"},")")])]),s("annotation",{encoding:"application/x-tex"},"\\prod_t^T p_\\phi\\left(r_t \\mid c, z, r_{<t}\\right)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2809em","vertical-align":"-0.2997em"}}),s("span",{class:"mop"},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∏"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9812em"}},[s("span",{style:{top:"-2.4003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])]),s("span",{style:{top:"-3.2029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2997em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"ϕ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∣"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mrel mtight"},"<"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1774em"}},[s("span")])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},")")])])])]),a(" 用 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"α")]),s("annotation",{encoding:"application/x-tex"},"\\alpha")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α")])])]),a(" 参数来调整。")],-1),xs=s("p",null,"但是在 Knover 的源代码中，笔者并没有找到这个设置，整个 PLATO-KAG 训练过程仅是简单地将 Knowledge Selection 任务和 Response Generation 任务权重简单地做了相加。",-1),fs=s("p",null,"此外，模型采用 PLATO-2 的预训练权重初始化。",-1),ws=s("p",null,[a("在推理过程中，仅仅选择相似度最高的 "),s("code",null,"knowledge"),a(" 片段进行推理。")],-1),zs=s("h2",{id:"参考",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#参考","aria-hidden":"true"},"#"),a(" 参考")],-1),Ls={href:"http://arxiv.org/abs/2112.12441",target:"_blank",rel:"noopener noreferrer"},ks={href:"http://arxiv.org/abs/2102.02096",target:"_blank",rel:"noopener noreferrer"},Es={href:"https://aclanthology.org/2021.nlp4convai-1.14",target:"_blank",rel:"noopener noreferrer"},As={href:"http://arxiv.org/abs/2109.09519",target:"_blank",rel:"noopener noreferrer"},Ms={href:"https://www.aclweb.org/anthology/2020.acl-main.9",target:"_blank",rel:"noopener noreferrer"},Ts={href:"http://arxiv.org/abs/2006.16779",target:"_blank",rel:"noopener noreferrer"};function Ps(Os,Ds){const l=i("ExternalLinkIcon");return m(),p("div",null,[_,x,f,w,z,s("p",null,[a("比较特别的是，在推理阶段，我们采用 "),L,a(" 来取代 "),k,a("。详细的隐变量计算 "),s("a",E,[a("参考代码"),n(l)]),a("。")]),A,M,T,P,s("p",null,[a("详细代码可以参考 "),s("a",O,[a("PLATO 源码"),n(l)])]),D,s("p",null,[a("二分类任务，通过输入隐变量位置对应的 logits,计算交叉熵，文中对这个优化目标记为 "),C,a("。对于一个问答对，其正例就是本身，而负例侧是在无关的语料库中，随机的一个答案。在 "),s("a",S,[a("plato"),n(l)]),a(" 源码中可以发现，负例是在训练过程中创建的，即简单的采用同一个 batch 下除自身以外的其他样本作为负例。")]),R,N,K,B,W,G,s("p",null,[a("得到 "),q,a(" 之后，我们对 "),X,a(" 进行优化， "),F,a(),s("a",U,[a("参考代码"),n(l)])]),V,H,I,J,Z,j,Q,s("p",null,[a("PLATO-2 在 DSTC9 的部分任务上表现出色，百度也对 PLATO-2 在该任务上的操作提供了论文。相关论文：Learning to Select External Knowledge with Multi-Scale Negative Sampling. "),s("a",Y,[a("Paper link"),n(l)])]),s("p",null,[a("网友的笔记"),s("a",$,[a("参考链接"),n(l)])]),ss,as,ls,ns,ts,s("p",null,[a("由于 PLATO-XL 模型较大，paddle 官方采用了 PaddleNLP FasterGeneration 进行高性能预测。"),s("a",es,[a("参考代码"),n(l)])]),is,ms,s("p",null,[a("相比于之前 PLATO 系列论文，该文主要介绍如何使用 PLATO 架构来进行具备额外知识信息的问答。"),s("a",ps,[a("代码链接"),n(l)])]),rs,cs,os,hs,gs,ds,us,s("p",null,[a("训练过程中，同时对 Knowledge Selection 和 Response Generation 进行优化。"),s("a",ys,[a("参考代码"),n(l)])]),vs,bs,_s,xs,fs,ws,zs,s("p",null,[a("[1] "),s("a",Ls,[a("TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue Modeling on Spoken Conversations"),n(l)])]),s("p",null,[a("[2] "),s("a",ks,[a("Learning to Select External Knowledge with Multi-Scale Negative Sampling"),n(l)])]),s("p",null,[a("[3] "),s("a",Es,[a("PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling"),n(l)])]),s("p",null,[a("[4] "),s("a",As,[a("PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation"),n(l)])]),s("p",null,[a("[5] "),s("a",Ms,[a("PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable"),n(l)])]),s("p",null,[a("[6] "),s("a",Ts,[a("PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning"),n(l)])])])}const Rs=e(b,[["render",Ps],["__file","笔记plato.html.vue"]]);export{Rs as default};
