import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as e,o as p,c as o,a as s,b as a,d as t,f as r}from"./app-a26e9423.js";const c={},i=r(`<h2 id="llama-note" tabindex="-1"><a class="header-anchor" href="#llama-note" aria-hidden="true">#</a> llama note</h2><h3 id="llama-系列模型" tabindex="-1"><a class="header-anchor" href="#llama-系列模型" aria-hidden="true">#</a> LLaMa 系列模型</h3><p>baichuan，qwen 等与 llama 架构类似。不同点在于中文的这几个模型对此表进行了扩充，预训练方式不同，instruction tuning prompt template 不同，baichuan，qwen 分别采用 <code>w_proj</code> 和 <code>c_proj</code> 来代替 hf llama 官方的 <code>k,q,v_proj</code>。因此除了 lora 训练时需要映射一下位置，GPTQ 也需要做一下调整。</p><p>lora 有些人直接给设置成对 <code>q_proj, k_proj, v_proj, W_proj</code> 等等一系列不同模型采用的权重名称，似乎也不是不行。</p><h3 id="swiglu" tabindex="-1"><a class="header-anchor" href="#swiglu" aria-hidden="true">#</a> SwiGLU</h3><p>官方实现方式为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">LlamaMLP</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, config):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">().</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> config</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.hidden_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> config.hidden_size</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.intermediate_size </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> config.intermediate_size</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gate_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.hidden_size, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.intermediate_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.up_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.hidden_size, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.intermediate_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.down_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.intermediate_size, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.hidden_size, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.act_fn </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">ACT2FN</span><span style="color:#24292E;">[config.hidden_act] </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config.pretraining_tp </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">slice</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.intermediate_size </span><span style="color:#D73A49;">//</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config.pretraining_tp</span></span>
<span class="line"><span style="color:#24292E;">            gate_proj_slices </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gate_proj.weight.split(</span><span style="color:#005CC5;">slice</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            up_proj_slices </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.up_proj.weight.split(</span><span style="color:#005CC5;">slice</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            down_proj_slices </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.down_proj.weight.split(</span><span style="color:#005CC5;">slice</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">            gate_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.cat(</span></span>
<span class="line"><span style="color:#24292E;">                [F.linear(x, gate_proj_slices[i]) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config.pretraining_tp)], </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=-</span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">            )</span></span>
<span class="line"><span style="color:#24292E;">            up_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.cat([F.linear(x, up_proj_slices[i]) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config.pretraining_tp)], </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">            intermediate_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.act_fn(gate_proj) </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> up_proj).split(</span><span style="color:#005CC5;">slice</span><span style="color:#24292E;">, </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            down_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span></span>
<span class="line"><span style="color:#24292E;">                F.linear(intermediate_states[i], down_proj_slices[i]) </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.config.pretraining_tp)</span></span>
<span class="line"><span style="color:#24292E;">            ]</span></span>
<span class="line"><span style="color:#24292E;">            down_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">sum</span><span style="color:#24292E;">(down_proj)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">else</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            down_proj </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.down_proj(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.act_fn(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gate_proj(x)) </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.up_proj(x))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> down_proj</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>因此，尽管 llama 的 config 文件中，写了 hidden_act 为 silu，但是实际上用的的确时 SwiGLU。</p>`,8),m=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"S"),s("mi",null,"i"),s("mi",null,"l"),s("mi",null,"u"),s("mo",null,"="),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"∗"),s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"}," Silu = \\sigma (x) * x ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])])])],-1),y=s("p",null,"SwiGLU 融合了 GLU 的思想，结合 LLaMa 中 FFN 没有 bias，因此可以写成：",-1),d=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"S"),s("mi",null,"w"),s("mi",null,"i"),s("mi",null,"G"),s("mi",null,"L"),s("mi",null,"U"),s("mo",null,"="),s("mi",null,"S"),s("mi",null,"i"),s("mi",null,"l"),s("mi",null,"u"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mi",null,"W"),s("mo",{stretchy:"false"},")"),s("mo",null,"×"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mi",null,"V"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," SwiGLU = Silu(xW)\\times (xV) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"Sw"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"G"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"LU"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"×"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mclose"},")")])])])])],-1),h=s("p",null,[a("其中 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"W"),s("mo",{separator:"true"},","),s("mi",null,"V")]),s("annotation",{encoding:"application/x-tex"},"W,V")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V")])])]),a(" 分别表示 "),s("code",null,"gate_proj"),a(" 和 "),s("code",null,"up_proj")],-1),u=s("h3",{id:"训练",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#训练","aria-hidden":"true"},"#"),a(" 训练")],-1),E=s("p",null,"LLaMa 出了名的，很多仓库做好了适配，没必要去自己根据 huggingface 写一个（当然，除非有很好的改进想法，如优化 loss 计算方式等）。现阶段完全采用 CasualLM 的训练优化方案了。",-1),_=s("div",{class:"hint-container warning"},[s("p",{class:"hint-container-title"},"注意"),s("p",null,"很重要的一点，HF 的模型在计算 loss 时候，会自动对 label 进行 shift，以此计算 next token prediction 的 loss。因此我们输入中的 label 不需要进行提前的 shift。"),s("p",null,"此外 可以通过 ignore token 来进行多轮对话训练（参考 fschat 的代码）")],-1),g=s("p",null,"单卡 7B-lora 训练可以用：",-1),C={href:"https://github.com/hiyouga/LLaMA-Efficient-Tuning",target:"_blank",rel:"noopener noreferrer"},f=s("p",null,"多卡多轮对话训练：",-1),v=s("ul",null,[s("li",null,"FastChat")],-1);function b(x,A){const n=e("ExternalLinkIcon");return p(),o("div",null,[i,m,y,d,h,u,E,_,g,s("ul",null,[s("li",null,[s("a",C,[a("llama-efficient-tuning"),t(n)])])]),f,v])}const j=l(c,[["render",b],["__file","笔记llama_note.html.vue"]]);export{j as default};
