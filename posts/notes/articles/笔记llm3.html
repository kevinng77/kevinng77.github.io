<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0llm3.html"><meta property="og:site_name" content="记忆笔书"><meta property="og:title" content="Instruction Tuning 后时代的模型笔记（二）"><meta property="og:description" content="Alpaca，ChatGLM 6B 等模型的效果可以接受，下文总结部分笔记，为训练自定义小型化（7B）模型提供点知识储备。包括模型论文 LLAMA, PaLM, BLOOM, BLOOMZ-mT LLAMA LLaMA: Open and Efficient Foundation Language Models 论文的重点在于预训练，虽然也尝试了使用 instruction tuning 进行模型测试，但介绍部分并不多。 数据： 约 1.4 T token 预训练，多语言但就是没有中文；"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-07-27T15:28:00.000Z"><meta property="article:author" content="Kevin 吴嘉文"><meta property="article:tag" content="NLP"><meta property="article:tag" content="AIGC"><meta property="article:published_time" content="2023-03-25T00:00:00.000Z"><meta property="article:modified_time" content="2023-07-27T15:28:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Instruction Tuning 后时代的模型笔记（二）","image":[""],"datePublished":"2023-03-25T00:00:00.000Z","dateModified":"2023-07-27T15:28:00.000Z","author":[{"@type":"Person","name":"Kevin 吴嘉文"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&display=swap" rel="stylesheet"><link rel="icon" href="/logo.svg"><title>Instruction Tuning 后时代的模型笔记（二） | 记忆笔书</title><meta name="description" content="Alpaca，ChatGLM 6B 等模型的效果可以接受，下文总结部分笔记，为训练自定义小型化（7B）模型提供点知识储备。包括模型论文 LLAMA, PaLM, BLOOM, BLOOMZ-mT LLAMA LLaMA: Open and Efficient Foundation Language Models 论文的重点在于预训练，虽然也尝试了使用 instruction tuning 进行模型测试，但介绍部分并不多。 数据： 约 1.4 T token 预训练，多语言但就是没有中文；">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-99575b2e.css" as="style"><link rel="stylesheet" href="/assets/style-99575b2e.css">
    <link rel="modulepreload" href="/assets/app-b56fd88a.js"><link rel="modulepreload" href="/assets/笔记llm3.html-ebbb7e8d.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/笔记llm3.html-9d0b6941.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><!----><!----><span class="vp-site-name">记忆笔书</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="主页" class="vp-link nav-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="归档" class="vp-link nav-link nav-link" href="/timeline/"><span class="font-icon icon iconfont icon-categoryselected" style=""></span>归档<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/kevinng77" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" role="search" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Instruction Tuning 后时代的模型笔记（二）</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Kevin 吴嘉文</span></span><span property="author" content="Kevin 吴嘉文"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-03-25T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 4 分钟</span><meta property="timeRequired" content="PT4M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category7 clickable" role="navigation">知识笔记</span><!--]--><meta property="articleSection" content="知识笔记"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag8 clickable" role="navigation">NLP</span><span class="page-tag-item tag4 clickable" role="navigation">AIGC</span><!--]--><meta property="keywords" content="NLP,AIGC"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#llama">LLAMA</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#palm">PaLM</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#bloom">Bloom</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#bloomz-mt0">Bloomz/mT0</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#self-instruct">SELF-INSTRUCT</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><p>Alpaca，ChatGLM 6B 等模型的效果可以接受，下文总结部分笔记，为训练自定义小型化（7B）模型提供点知识储备。包括模型论文 LLAMA, PaLM, BLOOM, BLOOMZ-mT</p><!--more--><h3 id="llama" tabindex="-1"><a class="header-anchor" href="#llama" aria-hidden="true">#</a> <strong>LLAMA</strong></h3><p>LLaMA: Open and Efficient Foundation Language Models</p><p>论文的重点在于预训练，虽然也尝试了使用 instruction tuning 进行模型测试，但介绍部分并不多。</p><p><strong>数据：</strong> 约 1.4 T token 预训练，多语言但就是没有中文；</p><p><strong>模型：</strong></p><ul><li>经典的大模型 Pre-normalization，采用 RMSNorm normalizing。使用 SwiGLU 激活函数，使用 ROPE。</li><li>模型规模有：7B, 13B, 33B, 65B</li></ul><p><strong>训练：</strong></p><ul><li>预训练：2048 A100 GPU 21 天</li></ul><figure><img src="https://picx.zhimg.com/80/v2-7817c721628b82eeaf46f2cd3436362e_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>结果：</strong></p><p>LLAMA 对标 GPT-3, PALM, OPT 等预训练模型。根据论文中各种指标表格，直观上来看，在 0-shot 以及 few-shot 效果上， <strong>13B 的 LLAMA 与 GPT-3 可比，7B 的 LLAMA 不会落后 GPT-3 太多。</strong></p><h3 id="palm" tabindex="-1"><a class="header-anchor" href="#palm" aria-hidden="true">#</a> <strong>PaLM</strong></h3><p>论文： <strong>Scaling Language Modeling with Pathways</strong></p><p>论文主要以研究预训练模型为主，但部分 instruction tuning 模型会与 PaLM 作比较，因此记录一些关注点：</p><p><strong>模型架构上：</strong></p><ul><li>SwiGLU 激活函数，采用 RoPE，共享 input, output embedding，所有 layer 不用 biases，更改 Transformer Block 中 Layernorm 的并行方式，使用 multi-query attention 取代 multi_head attention（仅将 Q 映射到 [k, h]，K,V 保持 [1, h]）</li></ul><p><strong>训练</strong> ：</p><ul><li>预训练 780 billion tokens</li><li>针对训练过程中，loss 爆炸的情况，采用回滚的方式：在 loss 爆炸点前 100 steps 开始，跳过 200 到 500 个 data batches，这样使得训练更加稳定</li></ul><p>结果：总体看来 540 B 的 PaLM 在大部分任务上式新 SOTA</p><figure><img src="https://pic1.zhimg.com/80/v2-7eaf758246c61d6efbba74c7ddb5a1ee_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>同时 PaLM 62B 的效果与 GPT-3 相近。</p><figure><img src="https://pic1.zhimg.com/80/v2-2b63c2e776d91396cfe5ed040ba9c471_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="bloom" tabindex="-1"><a class="header-anchor" href="#bloom" aria-hidden="true">#</a> <strong>Bloom</strong></h3><p>论文：BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</p><p>Bloom 偏向于研究预训练的文章，文章将较大比重放在了多语言能力的实验上，文中的 Bloom 和 BLOOMz 两个模型也都开源。</p><p><strong>模型：</strong> Vocab size 比 LLAMA 等其他模型大很多。位置编码采用了 ALiBi Positional Embeddings。</p><figure><img src="https://picx.zhimg.com/80/v2-02d9ad6320c588eb1bb2c6eeb1bb2f61_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>数据：</strong> 预训练：498 个 huggingface 数据集，1.6 TB 文本(涵盖 46 种语言和 13 中编程语言)；BLOOMz 在多语言多任务数据集上额外进行了训练。</p><p><strong>效果：</strong></p><p>superGLUE 的评分图：</p><figure><img src="https://picx.zhimg.com/80/v2-e70699a70a2063ccec31478a310aa25d_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>文中还有其他评分任务，总体看来， BLOOM 效果好于 OPT。 <strong>不同规格的 BLOOM 效果差距还是很大的。</strong></p><figure><img src="https://picx.zhimg.com/80/v2-df64ca91877f42fba19ecf421eb33f6c_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="bloomz-mt0" tabindex="-1"><a class="header-anchor" href="#bloomz-mt0" aria-hidden="true">#</a> <strong>Bloomz/mT0</strong></h3><p>论文：Crosslingual Generalization through Multitask Finetuning</p><p>在 BLOOM 和 mT5 上实验了 Multitask prompted finetuning 的效果。</p><p>模型：实验的都是多语言模型，文中使用了 BLOOM 和 mT5</p><p>数据：仍然采用公开数据集</p><figure><img src="https://picx.zhimg.com/80/v2-18f861ab27ba5a008df73f73a274cba6_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>prompt finetuning 采用的 prompt 也被分成三种形式进行测试：</p><figure><img src="https://picx.zhimg.com/80/v2-9b8c14eaf80df62241e92632b1c3d476_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>结果：</strong></p><p>对照上图文中对比了三种模型的结果：BLOOMZ-P3 （prompt 数据为 P3 数据），BLOOMZ（prompt 数据为 xP3 数据），BLOOMZ-MT（prompt 数据为 xP3mt 数据）。</p><figure><img src="https://pic1.zhimg.com/80/v2-ac598e6954b3b62f293ff7c75b962ba1_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>论文中没有找到直接与 GPT 对比的实验，但根据下面的 code 续写成绩来看，BLOOM 系列和 GPT 差距应该不小。</p><figure><img src="https://picx.zhimg.com/80/v2-343aa555e421ffcdee3dd85541095a06_1440w.png?source=d16d100b" alt="img" height="500" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="self-instruct" tabindex="-1"><a class="header-anchor" href="#self-instruct" aria-hidden="true">#</a> <strong>SELF-INSTRUCT</strong></h3><p>论文：Aligning Language Model with Self Generated Instructions</p><figure><img src="https://pic1.zhimg.com/80/v2-712c8d81e1e26485936877bfa520bb24_1440w.png?source=d16d100b" alt="self-instrcut 生成数据流程图" tabindex="0" loading="lazy"><figcaption>self-instrcut 生成数据流程图</figcaption></figure><p><strong>大致数据生成流程：</strong></p><ol><li>首先人工提供好 175 个 [instruct, input, output] 或 [instruct, null, output] 形式的数据。</li><li>通过 LLM 的 ICL 能力，随机提取 6 个人工数据和 2 个，自动生成 2 个 instruction。</li><li>通过 few shot （19 个负样本+12 个正样本）的方式，使用 GPT-3 来判断生成的 instruction 是否属于分类任务。</li><li>通过 instruct 生成 input 以及 output，可以分为两个类别：</li><li>对于非 classification 类型 instruction，先生成 input，而后生成 output。</li><li>对于 classification 类型 instruction 生成 output，而后再试 input。</li><li>通过 few-shot 的样本来控制 output 或者 input 的生成顺序，如要先生成 input，那么 prompt 可能如： Come up with examples for the following tasks. Try to generate multiple examples when possible. If the task doesn’t require additional input, you can generate the output directly. Task: Which exercises are best for reducing belly fat at home? Output: - Lying Leg Raises - Leg In And Out - Plank - Side Plank - Sit-ups</li><li>筛选：</li><li>当生成的 instruction 与已有的任意 instruction 的 ROUGE-L 小于 0.7。</li><li>句子中不包含 image， picture 等非语言内容的信息。</li><li>过滤掉相同 input，但是不同 output 的案例。</li><li>数据分布可视化：通过 Berkeley Neural Parser 查看数据类型分布。</li></ol><p><strong>数据：</strong> 82k sample，52k instruction</p><p>论文中基于 ROUGE-L 进行的结果对比不太公平，毕竟数据集是冲着低 ROUGE-L 去做的。还是参考下图的人工评测结果好点。 self-instruct 后 GPT-3 效果能够接近 InstructGPT-001，同时在 self-instruct 数据集上训练的效果会好于在公开数据集上训练的效果：</p><figure><img src="https://pic1.zhimg.com/80/v2-a682858cf0c48988729cdb77129e08ae_1440w.png?source=d16d100b" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" target="_blank" rel="noopener noreferrer">Alpaca<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 中稍微修改了 self-instruct 生成数据的方式。一共使用 52K instruction 即 sample 对 LLAMA 进行训练，花费 3 hours on 8 80GB A100s。</p><p><a href="https://github.com/LianjiaTech/BELLE" target="_blank" rel="noopener noreferrer">BELLE<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 基于 BLOOMz-mt 进行了中文微调，根据论文实验的结果看来，想要达到 ALPACA 类似的成绩，可能有点悬。</p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 417333277@qq.com">kevinng77</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer"><a href="https://beian.miit.gov.cn/" target="_blank">沪ICP备2023027904号-1</a>&nbsp;<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" target="_blank"><img src="/assets/gongan.png">公安备案号 </a></div><div class="vp-copyright">Copyright © 2023 Kevin 吴嘉文</div></footer></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-b56fd88a.js" defer></script>
  </body>
</html>
