<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0rasa1.html"><meta property="og:site_name" content="记忆笔书"><meta property="og:title" content="RASA 回忆录（一） - 自定义 RASA NLU 模块"><meta property="og:description" content="RASA 感觉像是时代的眼泪了，自动 LLM 火了之后，类似 RASA 一类的传统 NLP 对话架构变得冷门，不少技术似乎也被摒弃。但如今不少厂家在实现对话机器人、智能服务等 AIGC 服务，却也会用到这类型的框架。市面上提供类似 RASA 服务的 low code 平台也不少，如 Nuance, Omilia, Kore.ai 等。 该系列文章主要围绕 RASA 源码，对落地部署传统 NLP 对话框架的相关话题展开。本文针对 RASA 自定义 NLU 功能展开。 RASA 默认的 NLU 策略不支持比如细腻度情感分析、指代消解等方案。通过自定义 NLU 模块，我们可以任意 NLU 方案，比如添加额外的实体链接、实体纠错、信息抽取模块。"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-12-26T15:42:10.000Z"><meta property="article:author" content="Kevin 吴嘉文"><meta property="article:tag" content="NLP"><meta property="article:published_time" content="2022-09-25T00:00:00.000Z"><meta property="article:modified_time" content="2023-12-26T15:42:10.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"RASA 回忆录（一） - 自定义 RASA NLU 模块","image":[""],"datePublished":"2022-09-25T00:00:00.000Z","dateModified":"2023-12-26T15:42:10.000Z","author":[{"@type":"Person","name":"Kevin 吴嘉文"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&display=swap" rel="stylesheet"><link rel="icon" href="/logo.svg"><title>RASA 回忆录（一） - 自定义 RASA NLU 模块 | 记忆笔书</title><meta name="description" content="RASA 感觉像是时代的眼泪了，自动 LLM 火了之后，类似 RASA 一类的传统 NLP 对话架构变得冷门，不少技术似乎也被摒弃。但如今不少厂家在实现对话机器人、智能服务等 AIGC 服务，却也会用到这类型的框架。市面上提供类似 RASA 服务的 low code 平台也不少，如 Nuance, Omilia, Kore.ai 等。 该系列文章主要围绕 RASA 源码，对落地部署传统 NLP 对话框架的相关话题展开。本文针对 RASA 自定义 NLU 功能展开。 RASA 默认的 NLU 策略不支持比如细腻度情感分析、指代消解等方案。通过自定义 NLU 模块，我们可以任意 NLU 方案，比如添加额外的实体链接、实体纠错、信息抽取模块。">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-99575b2e.css" as="style"><link rel="stylesheet" href="/assets/style-99575b2e.css">
    <link rel="modulepreload" href="/assets/app-8f289594.js"><link rel="modulepreload" href="/assets/笔记rasa1.html-9cf194b3.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/笔记rasa1.html-69acbefe.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><!----><!----><span class="vp-site-name">记忆笔书</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="主页" class="vp-link nav-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="归档" class="vp-link nav-link nav-link" href="/timeline/"><span class="font-icon icon iconfont icon-categoryselected" style=""></span>归档<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/kevinng77" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" role="search" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->RASA 回忆录（一） - 自定义 RASA NLU 模块</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Kevin 吴嘉文</span></span><span property="author" content="Kevin 吴嘉文"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-09-25T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 11 分钟</span><meta property="timeRequired" content="PT11M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category7 clickable" role="navigation">知识笔记</span><!--]--><meta property="articleSection" content="知识笔记"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag8 clickable" role="navigation">NLP</span><!--]--><meta property="keywords" content="NLP"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#传统-nlp-对话框架">传统 NLP 对话框架</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#rasa-架构">RASA 架构</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#rasa-自定义-nlu">RASA 自定义 NLU</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#目录">目录</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#代码与实践">代码与实践</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#自定义-graphcomponent-for-nlu">自定义  GraphComponent (for NLU)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#rasa-nlu-部署">RASA NLU 部署</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#进一步解析结果来源">进一步解析结果来源</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#nlu-模块思考">NLU 模块思考</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#小结">小结</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><p>RASA 感觉像是时代的眼泪了，自动 LLM 火了之后，类似 RASA 一类的传统 NLP 对话架构变得冷门，不少技术似乎也被摒弃。但如今不少厂家在实现对话机器人、智能服务等 AIGC 服务，却也会用到这类型的框架。市面上提供类似 RASA 服务的 low code 平台也不少，如 Nuance, Omilia, Kore.ai 等。</p><p>该系列文章主要围绕 RASA 源码，对落地部署传统 NLP 对话框架的相关话题展开。本文针对 RASA 自定义 NLU 功能展开。</p><p>RASA 默认的 NLU 策略不支持比如细腻度情感分析、指代消解等方案。通过自定义 NLU 模块，我们可以任意 NLU 方案，比如添加额外的实体链接、实体纠错、信息抽取模块。</p><h2 id="传统-nlp-对话框架" tabindex="-1"><a class="header-anchor" href="#传统-nlp-对话框架" aria-hidden="true">#</a> 传统 NLP 对话框架</h2><p>以下是一种传统的 NLP 对话框架，用户输入语句后，会经过 NLU 和 Dialog 两个模块，最后得到回复。</p><p>NLU 模块：</p><ol start="2"><li>使用各种算法对语句进行 Embedding，然后将各种 Embedding 拼接。（比如用 Conv 1D 抽取上下文意思，对语句中单词进行分词后进行额外 Embedding 等）</li><li>将拼接后的 Embedding 传入模型当中，如 LSTM，Transformer 等，得到 hidden state</li><li>将 hidden state 链接不同的 output layer 进行不同 NLU 任务的解析。比如链接 linear layer 做多分类或实体识别，链接 pointer Network 做关系抽取等等。</li><li>将所有意图整理在对话状态中，传入给 dialog 模块。</li></ol><p>对话模块（dialog 模块）</p><ol><li>采用 rule base：提前设计好用户故事线，以买咖啡为例；那么我们需要用条件语句，分别从用户那边问道咖啡的大小、甜度、加冰与否、打包还是堂食等信息（类似槽位填充）。在获得所有信息之后，对用户的咖啡进行下单。</li><li>采用其他方式：使用 rule base 的问题在于，我们需要多所有的场景进行规则构建，当用户问一点点规则以外的内容时，这个对话 session 可能会被影响，甚至打乱。因此有不少针对多轮对话的传统策略提出，比如将对话状态编码，与用户输入的 hidden state 一起生成回复等；或将用户输入与机器人的一些候选决策进行相关性匹配（RASA 的 Action 策略）。</li></ol><h2 id="rasa-架构" tabindex="-1"><a class="header-anchor" href="#rasa-架构" aria-hidden="true">#</a> RASA 架构</h2><p>RASA 的架构分成 nlu 模块和 core 模块。</p><p>Core 模块（即上文中的 dialog 模块）需要的操作有：</p><ol><li>写 Rule：定义如上文中提到的基于规则的对话逻辑</li><li>写故事： <ul><li>定义机器人的 Action，比如机器人可能会发送邮件，或者为客户下单一个咖啡，或者让客户付款。</li><li>准备一些多轮对话数据集作为训练集，用于训练模型的对话能力。比如训练集中会包含有用户提问以及机器人采取的对应 Action 信息。模型就会根据这部分信息，训练一个 Action 和 Query 匹配器。</li></ul></li></ol><p>NLU 需要的操作有：</p><ol><li>准备训练集：填写你要训练的 intent，entity 等信息。人工准备一些语料并针对不同任务进行打标签。</li><li>配置 NLU 流程：选择你要进行的 NLU 流程，比如你希望用哪些 Embedding 进行拼接。而后采用那个模型架构对拼接后的 Embedding 进行解析，得到 hidden state。最后用哪些解析器来讲 hidden state 转换为输出结果。</li><li>训练模型：RASA 提供了一键训练，训练速度和配置取决于你选择的 NLU 配置。</li></ol><p>当然如何配置 RASA NLU，可参考官方给出的详细文档。以下针对自定义 RASA NLU 模块做介绍。</p><h2 id="rasa-自定义-nlu" tabindex="-1"><a class="header-anchor" href="#rasa-自定义-nlu" aria-hidden="true">#</a> RASA 自定义 NLU</h2><h3 id="目录" tabindex="-1"><a class="header-anchor" href="#目录" aria-hidden="true">#</a> 目录</h3><p>该节展示了</p><ol><li>如何使用 Huggingface 上的模型，作为 RASA 的 embedding 工具。（默认 RASA 采用 TF 模型）</li><li>如何添加一个情感分析引擎（这在 RASA 中是没有的）。</li></ol><p>通过这个展示，我们能够延申到以下功能：</p><ol><li>参考这个代码，我们能够实现使用任何形式的模型作为我们的 Feature/Embedding 工具，比如 paddle, onnx 等。</li><li>当 RASA 默认的训练效果不好时，你应该意识到 RASA 的自带 Featurizer 存在很大问题：他不能够被训练。</li><li>RASA 默认使用 CLS 位置的 feature 作为 sentence embedding 进行分类，而其他位置的 feature 作为 sequence embedding 进行 NER 等任务。 <strong>大部分的 Transformer 使用了 SUB-TOKEN 的分词方式，而 RASA 默认的 NER 方式时将 subtoken 对应的 embedding 结合，作为完成 token 的 embedding。</strong></li><li>猜测：在 featurizer 中，没有输出任何完整 token 信息，估计在 NER 环节使用的 token 信息，是从 Tokenizer 传过去的，因此如果 Featurizer 输出 feature 维度和 Tokenizer 对应不上，就会报错。</li><li>RASA 训练策略比较单调，如果你享受调参等自定义模型训练方法。可以在自己机器上训练好权重，然后把他放在 RASA 中直接用，这将大大减少模型训练时间。最后通过自定义 Component 集成到 RASA 中。</li><li>我们能够在 RASA NLU 的基本功能（Intent，NER）上，添加上任意的 NLU 处理结果，比如添加额外的细腻度情感分析结果、添加额外的实体链接、实体纠错、信息抽取结果。</li></ol><h3 id="代码与实践" tabindex="-1"><a class="header-anchor" href="#代码与实践" aria-hidden="true">#</a> 代码与实践</h3><p>https://github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu</p><h4 id="rasa-配置文件-config-py-中的-pipeline" tabindex="-1"><a class="header-anchor" href="#rasa-配置文件-config-py-中的-pipeline" aria-hidden="true">#</a> RASA 配置文件 Config.py 中的 Pipeline</h4><p>Pipeline 由多个 RASA GraphComponent 组成，当用户发出消息后，消息会 <strong>依次</strong> 经过 Pipeline 的每一个 GraphComponent 处理，以完成 NLU。比如一下是一个经典的 Pipeline 写法：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">pipeline:</span></span>
<span class="line"><span style="color:#24292e;">  - name: &quot;WhitespaceTokenizer&quot;  </span></span>
<span class="line"><span style="color:#24292e;">  - name: &quot;CountVectorsFeaturizer&quot;</span></span>
<span class="line"><span style="color:#24292e;">  - name: &quot;DIETClassifier&quot;</span></span>
<span class="line"><span style="color:#24292e;">    epochs: 100</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上面的 Pipeline 为例，rasa 进行 nlu 的时候，会从上到下进行每一个 GraphComponent。</p><p>如果用伪代码来表示这个流程，就是：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># 毕竟是伪代码，因此逻辑不会很严谨</span></span>
<span class="line"><span style="color:#24292E;">message </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> parse_user_input</span></span>
<span class="line"><span style="color:#6A737D;"># message 为数据结构，在 `rasa.shared.nlu.training_data.message` 可查看。</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> GraphComponent </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> pipeline.name:</span></span>
<span class="line"><span style="color:#24292E;">    message </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> GraphComponent.process(message)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每个 Component 可以在 <code>rasa.rasa.nlu</code> 文件夹下面找到，如 <code>WhitespaceTokenizer</code> 对应 <code>rasa.rasa.nlu.tokenizer.whitespace_tokenizer.WhitespaceTokenizer</code>。</p><h3 id="自定义-graphcomponent-for-nlu" tabindex="-1"><a class="header-anchor" href="#自定义-graphcomponent-for-nlu" aria-hidden="true">#</a> 自定义 GraphComponent (for NLU)</h3><p>使用自定义 NLU GraphComponent 需要以下几个步骤：</p><ol><li><p>写一个 <code>.py</code> 文件，里面定义好你要的 <code>GraphComponent</code>。本案例中的自定义 GraphComponent 都写在 Component 文件夹下面了。</p></li><li><p>在 Pipeline 中引用对应的 <code>GraphComponent</code></p></li></ol><h4 id="_1-定义-custom-graphcomponent" tabindex="-1"><a class="header-anchor" href="#_1-定义-custom-graphcomponent" aria-hidden="true">#</a> 1. 定义 Custom GraphComponent</h4><p>在 <code>rasa.data.test_classes</code> 中，我们能够看到一些官方提供的 <code>GraphComponent</code> 自定义方法和模板。如 <code>nlu_component_skeleton.py</code>。从下面的代码中可以看出，GraphComponent 主要的入口就是 <code>create</code>, <code>train</code>, <code>process</code>, <code>process_training_data</code> 四个方法。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">@DefaultV1Recipe.register</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">    [DefaultV1Recipe.ComponentType.</span><span style="color:#005CC5;">INTENT_CLASSIFIER</span><span style="color:#24292E;">], </span><span style="color:#E36209;">is_trainable</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">CustomNLUComponent</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">GraphComponent</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6F42C1;">@</span><span style="color:#005CC5;">classmethod</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">create</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">        cls,</span></span>
<span class="line"><span style="color:#24292E;">        config: Dict[Text, Any],</span></span>
<span class="line"><span style="color:#24292E;">        model_storage: ModelStorage,</span></span>
<span class="line"><span style="color:#24292E;">        resource: Resource,</span></span>
<span class="line"><span style="color:#24292E;">        execution_context: ExecutionContext,</span></span>
<span class="line"><span style="color:#24292E;">    ) -&gt; GraphComponent:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># </span><span style="color:#D73A49;">TODO</span><span style="color:#6A737D;">: Implement this</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">...</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">train</span><span style="color:#24292E;">(self, training_data: TrainingData) -&gt; Resource:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># </span><span style="color:#D73A49;">TODO</span><span style="color:#6A737D;">: Implement this if your component requires training</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">...</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">process_training_data</span><span style="color:#24292E;">(self, training_data: TrainingData) -&gt; TrainingData:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># </span><span style="color:#D73A49;">TODO</span><span style="color:#6A737D;">: Implement this if your component augments the training data with</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">#       tokens or message features which are used by other components</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;">#       during training.</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">...</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> training_data</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">process</span><span style="color:#24292E;">(self, messages: List[Message]) -&gt; List[Message]:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># </span><span style="color:#D73A49;">TODO</span><span style="color:#6A737D;">: This is the method which Rasa Open Source will call during inference.</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">...</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> messages</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>因此自定义的 <code>GraphComponent</code> 中，必须覆盖重写以上四个方法。我们根据 <code>rasa.rasa.nlu</code> 中的文件进行修改，尝试使用 pytorch 的模型来计算模型的 embedding。大致方法是继承 <code>rasa.nlu.featurizers.dense_featurizer.dense_featurizer</code> 中的 <code>DenseFeaturizer</code> 抽象类，</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">@DefaultV1Recipe.register</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">    DefaultV1Recipe.ComponentType.</span><span style="color:#005CC5;">MESSAGE_FEATURIZER</span><span style="color:#24292E;">, </span><span style="color:#E36209;">is_trainable</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">LanguageModelFeaturizer</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">DenseFeaturizer</span><span style="color:#24292E;">, </span><span style="color:#6F42C1;">GraphComponent</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">	</span><span style="color:#6A737D;">#...</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>具体查看该文件夹下的 <code>components/myintent.py</code>。比较值得注意的点是： <strong>默认情况下，所有的 Featurizer 都是不能被 train 的</strong> ，包括 RASA 自带的 TF transformers。而我们知道，Transformer 系列小模型在不微调的情况下，效果是不怎么好的。因此我们可以考虑，</p><ol><li>将 Featurizer 和 Intent Classifier 合并成一个 Compoent，而后统一在 RASA 中训练。</li><li>或者选个领域预训练+微调好的 embedding transformer</li><li>其他骚操作</li></ol><h4 id="_2-pipeline-中引用自定义模块" tabindex="-1"><a class="header-anchor" href="#_2-pipeline-中引用自定义模块" aria-hidden="true">#</a> 2. Pipeline 中引用自定义模块</h4><p>我们将原先的词袋模型替换为我们自定义的模型 <code>components.myintent.LanguageModelFeaturizer</code>， 并使用 huggingface 上的权重<code>kevinng77/TinyBERT_4L_312D_SIMCSE_finetune</code>，这便是自定义模型的好处之一：这是一个在个人 GPU 上蒸馏好的模型，速度比标准 bert 快 20+倍，且在 NLI 数据集上的精度（较 SIMCSE）保留了 98%。我们能够进一步对他进行量化、检索、推理部署等，以进一步提高预测速度。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">pipeline:</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> name: </span><span style="color:#032F62;">&quot;WhitespaceTokenizer&quot;</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> name: components.myintent.LanguageModelFeaturizer</span></span>
<span class="line"><span style="color:#24292E;">    model_name: kevinng77</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">TinyBERT_4L_312D_SIMCSE_finetune </span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> name: </span><span style="color:#032F62;">&quot;DIETClassifier&quot;</span></span>
<span class="line"><span style="color:#24292E;">    epochs: </span><span style="color:#005CC5;">100</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_3-我们添加额外的情感分析模块-从用户回答中提取更多信息" tabindex="-1"><a class="header-anchor" href="#_3-我们添加额外的情感分析模块-从用户回答中提取更多信息" aria-hidden="true">#</a> 3. 我们添加额外的情感分析模块，从用户回答中提取更多信息</h4><p>根据 <code>rasa.nlu</code> 下的代码，大致可以猜测到，整个 Pipeline 的 NLU 过程中，所有的结果都会被记录在 <code>Message</code> 上。</p><p>因此如果我们想要添加额外的 nlu 信息，如实体间关系、细腻度情感分析。那么，我们就可以自定义 <code>Component</code> 模块，而后通过 <code>process()</code> 函数，将 NLU 处理的结果添加到 <code>Message</code> 中就行。<code>Message</code> 中有 <code>data</code> 字典，可以用来储存其他特征信息。</p><p>比如说，我想要在 intent 分析和 NER 分析的基础上，加上一层情感分析：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#22863A;">pipeline</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;WhitespaceTokenizer&quot;</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">components.myintent.LanguageModelFeaturizer</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">model_name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">distilbert</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">components.sentiment_classifier.SentimentClassifier</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;DIETClassifier&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">epochs</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">50</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在 <code>components.sentiment_classifier.SentimentClassifier</code> 中，我们提供以下方法（具体可查看文件夹中代码）：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">@DefaultV1Recipe.register</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">    DefaultV1Recipe.ComponentType.</span><span style="color:#005CC5;">INTENT_CLASSIFIER</span><span style="color:#24292E;">, </span><span style="color:#E36209;">is_trainable</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">SentimentClassifier</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">GraphComponent</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;Intent classifier using the Logistic Regression.&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># ...</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#24292E;">	</span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">process</span><span style="color:#24292E;">(self, messages: List[Message]) -&gt; List[Message]:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;Return the most likely intent and its probability for a message.&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> idx, message </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(messages):</span></span>
<span class="line"><span style="color:#24292E;">            sentiment, score </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;Positive&quot;</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">0.666</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># this should come from your model</span></span>
<span class="line"><span style="color:#24292E;">            message.set(</span><span style="color:#032F62;">&quot;sentiment&quot;</span><span style="color:#24292E;">, sentiment, </span><span style="color:#E36209;">add_to_output</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            message.set(</span><span style="color:#032F62;">&quot;sentiment_confidence&quot;</span><span style="color:#24292E;">, score, </span><span style="color:#E36209;">add_to_output</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> messages</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么在输出结果中，我们就能看到 <code>Message.data</code> 中，多了情感分析的结果，执行以下语句进行测试 ：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">rasa train nlu</span></span>
<span class="line"><span style="color:#24292e;">rasa shell</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>输入 <code>hello world</code>，系统回复内容中，就会多出来 <code>sentiment</code> 和 <code>sentiment_confidence</code> 两个字段了：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">NLU</span><span style="color:#24292E;"> </span><span style="color:#032F62;">model</span><span style="color:#24292E;"> </span><span style="color:#032F62;">loaded.</span><span style="color:#24292E;"> </span><span style="color:#032F62;">Type</span><span style="color:#24292E;"> </span><span style="color:#032F62;">a</span><span style="color:#24292E;"> </span><span style="color:#032F62;">message</span><span style="color:#24292E;"> </span><span style="color:#032F62;">and</span><span style="color:#24292E;"> </span><span style="color:#032F62;">press</span><span style="color:#24292E;"> </span><span style="color:#032F62;">enter</span><span style="color:#24292E;"> </span><span style="color:#032F62;">to</span><span style="color:#24292E;"> </span><span style="color:#032F62;">parse</span><span style="color:#24292E;"> </span><span style="color:#032F62;">it.</span></span>
<span class="line"><span style="color:#6F42C1;">Next</span><span style="color:#24292E;"> </span><span style="color:#032F62;">message:</span></span>
<span class="line"><span style="color:#6F42C1;">hello</span><span style="color:#24292E;"> </span><span style="color:#032F62;">world</span></span>
<span class="line"><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;text&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;hello world&quot;,</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;intent&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">{</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6F42C1;">&quot;name&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;greet&quot;,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6F42C1;">&quot;confidence&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.4089217782020569</span></span>
<span class="line"><span style="color:#24292E;">  },</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;entities&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> [],</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;text_tokens&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> [</span></span>
<span class="line"><span style="color:#24292E;">    [</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">5</span></span>
<span class="line"><span style="color:#24292E;">    ]</span><span style="color:#6F42C1;">,</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#6A737D;"># ...</span></span>
<span class="line"><span style="color:#24292E;">  ],</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;sentiment&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;Positive&quot;,</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;sentiment_confidence&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.666</span><span style="color:#032F62;">,</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#6F42C1;">&quot;intent_ranking&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> [</span></span>
<span class="line"><span style="color:#24292E;">    {</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#6F42C1;">&quot;name&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;greet&quot;,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#6F42C1;">&quot;confidence&quot;</span><span style="color:#005CC5;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.4089217782020569</span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">	</span><span style="color:#6A737D;">#...</span></span>
<span class="line"><span style="color:#24292E;">  ]</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="rasa-nlu-部署" tabindex="-1"><a class="header-anchor" href="#rasa-nlu-部署" aria-hidden="true">#</a> RASA NLU 部署</h3><p>默认 RASA NLU 是单独部署成一个 API 的。因此我们可以讲实现好的自定义 NLU 模块部署成 API，而后进行测试。首先运行服务：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">rasa</span><span style="color:#24292E;"> </span><span style="color:#032F62;">run</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--enable-api</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>发送 POST 请求到 <code>http://localhost:5005/model/parse</code>， body 中为：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">&quot;text&quot;</span><span style="color:#24292E;">:</span><span style="color:#032F62;">&quot;what restaurants do you recomment?&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">&quot;sender&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;test_user&quot;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RASA 返回 Message 结果。而 Message 架构如下：</p><div class="language-json line-numbers-mode" data-ext="json"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;">// request 返回的结果</span></span>
<span class="line"><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#005CC5;">&quot;text&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;what restaurants do you recomment?&quot;</span><span style="color:#24292E;">,  </span><span style="color:#6A737D;">// 用户 query</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#005CC5;">&quot;intent&quot;</span><span style="color:#24292E;">: {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">&quot;name&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;query_knowledge_base&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">&quot;confidence&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1.0</span></span>
<span class="line"><span style="color:#24292E;">  },  </span><span style="color:#6A737D;">// 最终判断意图</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#005CC5;">&quot;entities&quot;</span><span style="color:#24292E;">: [ </span><span style="color:#6A737D;">// 所有实体抽取的结果</span></span>
<span class="line"><span style="color:#24292E;">    {</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;entity&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;object_type&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;start&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;end&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">16</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;value&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;restaurants&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;extractor&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;RegexEntityExtractor&quot;</span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    {</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;entity&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;object_type&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;start&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;end&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">16</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;confidence_entity&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0.9987316727638245</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;value&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;restaurants&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;extractor&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;DIETClassifier&quot;</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">  ],</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#005CC5;">&quot;text_tokens&quot;</span><span style="color:#24292E;">: [</span></span>
<span class="line"><span style="color:#24292E;">    [</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">    [</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">16</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;">// ... 所有 token 对应的 idx</span></span>
<span class="line"><span style="color:#24292E;">  ],</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#005CC5;">&quot;intent_ranking&quot;</span><span style="color:#24292E;">: [</span></span>
<span class="line"><span style="color:#24292E;">    {</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;name&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;query_knowledge_base&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;confidence&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1.0</span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    {</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;name&quot;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;greet&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">      </span><span style="color:#005CC5;">&quot;confidence&quot;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">4.942866560497805e-9</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">  ]</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其他的 API 服务接口可以在 <a href="https://rasa.com/docs/rasa/pages/http-api" target="_blank" rel="noopener noreferrer">RASA API<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 查看。</p><h3 id="进一步解析结果来源" tabindex="-1"><a class="header-anchor" href="#进一步解析结果来源" aria-hidden="true">#</a> 进一步解析结果来源</h3><p>在 <code>rasa.server.create_app</code> 中，我们可以找到 NLU api 的入口：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">@app.post</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;/model/parse&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#6F42C1;">@requires_auth</span><span style="color:#24292E;">(app, auth_token)</span></span>
<span class="line"><span style="color:#6F42C1;">@ensure_loaded_agent</span><span style="color:#24292E;">(app)</span></span>
<span class="line"><span style="color:#D73A49;">async</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">parse</span><span style="color:#24292E;">(request: Request) -&gt; HTTPResponse:</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># NLU 处理</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> response.json(response_data)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中的 NLU 处理流程，我们可以在 <code>rasa.rasa.core.agent.Agent.parse_message</code> 查看到。</p><p>在上一个仓库<code>2-custom_nlu</code> 中，我们提到了 RASA nlu 的执行单元 <code>GraphComponent</code> 可以在 <code>rasa/rasa/nlu</code> ，如果你定义了这样一个 Pipeline：</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#22863A;">pipeline</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;WhitespaceTokenizer&quot;</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;CountVectorsFeaturizer&quot;</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;CountVectorsFeaturizer&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">analyzer</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&quot;char_wb&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">min_ngram</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">max_ngram</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">4</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">RegexEntityExtractor</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">use_regexes</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">True</span></span>
<span class="line"><span style="color:#24292E;">  - </span><span style="color:#22863A;">name</span><span style="color:#24292E;">: </span><span style="color:#032F62;">components.diet_cls.DIETClassifier</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#22863A;">epochs</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">100</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>那么，NLU 处理的过程大概就是：</p><ol><li><p>通过<code>rasa/nlu/emulators</code> 预处理请求（可查看 <code>emulators.normalise_request_json</code>方法）。</p></li><li><p>在 <code>rasa/core/processor</code> 中将文本信息包装到 <code>Message</code> 中。此时的 <code>Message</code> 仅包括 <code>text</code> 等基础字段</p></li><li><p>通过 <code>rasa/nlu/tokneizers/whitespace_tokenizer</code> 中 <code>WhitespaceTokenizer.tokenize()</code> 往 <code>Message</code> 中添加 <code>text_tokens</code> 结果和字段。</p></li><li><p>通过 <code>rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py</code> 中 <code>CountVectorsFeaturizer.process()</code> ，往 <code>Message.features</code> 中添加 <code>features</code> 内容。（<code>Message.features</code> 中的所有内容仅被用于辅助 其他 NLU 环节处理，不会被当成最终结果返回）</p><blockquote><p>如果有多个 <code>featurizer</code>，那么他们的输出将会被统一储存在 <code>Message.features</code> 列表中。</p></blockquote></li><li><p>通过 <code>rasa/nlu/extractors/regex_entity_extractor.py</code> 中的 <code>RegexEntityExtractor.process()</code>，往 <code>Message</code> 中添加 <code>entities</code> 结果和字段。</p></li><li><p>通过 <code>rasa/nlu/classifier/diet_classifier.py</code> 中的 <code>DIETClassifier.process()</code>，往 <code>Message</code> 中添加 <code>intent</code>, <code>intent_ranking</code>, <code>entities</code> 结果和字段。</p></li><li><p>最终结果经过 <code>emulator.normalise_response_json</code> 后处理，被包装成 json 返回。</p></li></ol><h3 id="nlu-模块思考" tabindex="-1"><a class="header-anchor" href="#nlu-模块思考" aria-hidden="true">#</a> NLU 模块思考</h3><ol><li><p>整个 NLU 过程采用了几年前 NLU 领域特征工程大杂烩 + 基础模型训练的操作。你可以任意的添加 Features，但是 features 在最后进行意图识别，或者实体识别时候，将会以拼接的方式结合（如 <code>rasa.utils.tensorfloe.ConcatenateSparseDenseFeatures</code>），而后加上下游模型进行训练和预测。</p></li><li><p>如果要自定义 Intent 和 NER 模块，只需要重新包装好 <code>GraphComponent</code>，确保在 <code>process()</code> 方法中，将 <code>entities</code>， <code>intent</code>，<code>intent_ranking</code> 添加到 Message 中即可。</p></li><li><p>对于 RASA 中的 Transformer，意图识别默认使用 CLS 位置的 <code>hidden_state</code> 进行分类；实体抽取任务默认使用其他位置的 <code>hidden_state</code> 进行预测。预测的基础单位取决于 Pipeline 中的 <code>Tokenizer</code>。比如你使用了 <code>WhitespaceTokenizer</code>。假设用户输入 <code>say HelloWorld</code> ，那么大致的实体抽取流程会是：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">tokens </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;say HelloWorld&quot;</span><span style="color:#24292E;">.split()</span></span>
<span class="line"><span style="color:#24292E;">token_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> token </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> tokens:</span></span>
<span class="line"><span style="color:#24292E;">    sub_token </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> MybertTokenzier(token)</span></span>
<span class="line"><span style="color:#24292E;">    sub_token_feature </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> MyBertModel(sub_token)</span></span>
<span class="line"><span style="color:#24292E;">    token_feature </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> combine(sub_token_feature) </span></span>
<span class="line"><span style="color:#24292E;">    token_features.append(token_feature)</span></span>
<span class="line"><span style="color:#005CC5;">NER_result</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> my_ner_model(token_features)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>部分 Transformer 模型在 tokenize 之前都会进行基础 tokenize（如 <code>.split()</code>）。但对那些不进行基础 tokenize 的 Transformer 模型，则会使 X 分布偏移，导致效果受影响。</p></li></ol><p>参考代码：</p><p><a href="https://link.zhihu.com/?target=https%3A//github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu" target="_blank" rel="noopener noreferrer">https://github.com/kevinng77/rasa_example/tree/master/examples/2_custom_clugithub.com/kevinng77/rasa_example/tree/master/examples/2_custom_clu<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="小结" tabindex="-1"><a class="header-anchor" href="#小结" aria-hidden="true">#</a> 小结</h2><p>不少 low code 对话系统开发平台的 NLU 模块与 RASA 几乎一致，后续的系列文章也会分析落地部署类似的 NLU 引擎，以及部署 huggingface NLU 模型实现高吞吐量方案。</p><p>印象中研究 RASA 也就一年前左右，而今 LLM 和 Agent 等 AIGC 话题的火热，使得 RASA 这样的对话框架受到的关注减少。不知多久后，RASA 会变成 NLP 的历史产物。</p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 417333277@qq.com">kevinng77</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer"><a href="https://beian.miit.gov.cn/" target="_blank">沪ICP备2023027904号-1</a>&nbsp;<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" target="_blank"><img src="/assets/gongan.png">公安备案号 </a></div><div class="vp-copyright">Copyright © 2025 Kevin 吴嘉文</div></footer></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-8f289594.js" defer></script>
  </body>
</html>
