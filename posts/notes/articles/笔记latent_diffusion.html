<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0latent_diffusion.html"><meta property="og:site_name" content="è®°å¿†ç¬”ä¹¦"><meta property="og:title" content="DIFFUSION ç³»åˆ—ç¬”è®°| Latent Diffusion Model"><meta property="og:description" content="ç›¸å¯¹äº DDIM, DDPM ä»¥åŠ SDEï¼ŒHigh-Resolution Image Synthesis with Latent Diffusion Models ä¸€æ–‡é‡ç‚¹åœ¨äº latent Space å’Œ Conditioning Cross Attentionï¼Œè€Œé diffusion pipeline æµç¨‹ã€‚ ä»¥æ­¤ä¸åŒäºå‰å‡ ä»½ç¬”è®°ï¼Œæœ¬æ–‡ä¸»è¦å‚è€ƒ huggingface/diffusers ä¸­ Latent Diffusion Model åŠ Stable Diffusion çš„å®ç°ï¼Œå¯¹ LDM æ¶æ„åŠå…¶ä¸­çš„ Conditioning Cross Attention åšæ¢³ç†ã€‚"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-10-20T06:56:10.000Z"><meta property="article:author" content="Kevin å´å˜‰æ–‡"><meta property="article:tag" content="CV"><meta property="article:tag" content="Diffusion"><meta property="article:tag" content="AIGC"><meta property="article:published_time" content="2023-08-29T00:00:00.000Z"><meta property="article:modified_time" content="2023-10-20T06:56:10.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"DIFFUSION ç³»åˆ—ç¬”è®°| Latent Diffusion Model","image":[""],"datePublished":"2023-08-29T00:00:00.000Z","dateModified":"2023-10-20T06:56:10.000Z","author":[{"@type":"Person","name":"Kevin å´å˜‰æ–‡"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&display=swap" rel="stylesheet"><link rel="icon" href="/logo.svg"><title>DIFFUSION ç³»åˆ—ç¬”è®°| Latent Diffusion Model | è®°å¿†ç¬”ä¹¦</title><meta name="description" content="ç›¸å¯¹äº DDIM, DDPM ä»¥åŠ SDEï¼ŒHigh-Resolution Image Synthesis with Latent Diffusion Models ä¸€æ–‡é‡ç‚¹åœ¨äº latent Space å’Œ Conditioning Cross Attentionï¼Œè€Œé diffusion pipeline æµç¨‹ã€‚ ä»¥æ­¤ä¸åŒäºå‰å‡ ä»½ç¬”è®°ï¼Œæœ¬æ–‡ä¸»è¦å‚è€ƒ huggingface/diffusers ä¸­ Latent Diffusion Model åŠ Stable Diffusion çš„å®ç°ï¼Œå¯¹ LDM æ¶æ„åŠå…¶ä¸­çš„ Conditioning Cross Attention åšæ¢³ç†ã€‚">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-99575b2e.css" as="style"><link rel="stylesheet" href="/assets/style-99575b2e.css">
    <link rel="modulepreload" href="/assets/app-c62a9332.js"><link rel="modulepreload" href="/assets/ç¬”è®°latent_diffusion.html-5a8b4305.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/ç¬”è®°latent_diffusion.html-02702749.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><!----><!----><span class="vp-site-name">è®°å¿†ç¬”ä¹¦</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="ä¸»é¡µ" class="vp-link nav-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>ä¸»é¡µ<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="å½’æ¡£" class="vp-link nav-link nav-link" href="/timeline/"><span class="font-icon icon iconfont icon-categoryselected" style=""></span>å½’æ¡£<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/kevinng77" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" role="search" aria-label="æœç´¢"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">æœç´¢</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->DIFFUSION ç³»åˆ—ç¬”è®°| Latent Diffusion Model</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Kevin å´å˜‰æ–‡</span></span><span property="author" content="Kevin å´å˜‰æ–‡"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-08-29T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 9 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT9M"></span><span class="page-category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category7 clickable" role="navigation">çŸ¥è¯†ç¬”è®°</span><!--]--><meta property="articleSection" content="çŸ¥è¯†ç¬”è®°"></span><span class="page-tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag1 clickable" role="navigation">CV</span><span class="page-tag-item tag5 clickable" role="navigation">Diffusion</span><span class="page-tag-item tag4 clickable" role="navigation">AIGC</span><!--]--><meta property="keywords" content="CV,Diffusion,AIGC"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">æ­¤é¡µå†…å®¹<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#latent-diffusion-model">Latent Diffusion Model</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#ldm-ä¸»è¦æ€æƒ³">LDM ä¸»è¦æ€æƒ³</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#ldm-ä½¿ç”¨ç¤ºä¾‹">LDM ä½¿ç”¨ç¤ºä¾‹</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#ldm-pipeline">LDM Pipeline</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#ldm-super-resolution-pipeline">LDM Super Resolution Pipeline</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#stable-diffusion">Stable diffusion</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#sd-v1-æ¶æ„">SD v1 æ¶æ„</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#sd-v1-1-v1-5">SD v1.1 - v1.5</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#sd-v2">SD v2</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#lora">Lora</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><p>ç›¸å¯¹äº DDIM, DDPM ä»¥åŠ SDEï¼ŒHigh-Resolution Image Synthesis with Latent Diffusion Models ä¸€æ–‡é‡ç‚¹åœ¨äº latent Space å’Œ Conditioning Cross Attentionï¼Œè€Œé diffusion pipeline æµç¨‹ã€‚</p><p>ä»¥æ­¤ä¸åŒäºå‰å‡ ä»½ç¬”è®°ï¼Œæœ¬æ–‡ä¸»è¦å‚è€ƒ <a href="https://zhuanlan.zhihu.com/p/659212489/huggingface/diffusers" target="_blank" rel="noopener noreferrer">huggingface/diffusers<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> ä¸­ Latent Diffusion Model åŠ Stable Diffusion çš„å®ç°ï¼Œå¯¹ LDM æ¶æ„åŠå…¶ä¸­çš„ Conditioning Cross Attention åšæ¢³ç†ã€‚</p><p>ç³»åˆ—ç¬”è®°</p><ul><li><a href="https://zhuanlan.zhihu.com/p/650495280" target="_blank" rel="noopener noreferrer">Kevin å´å˜‰æ–‡ï¼šDiffusion|DDPM ç†è§£ã€æ•°å­¦ã€ä»£ç <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://zhuanlan.zhihu.com/p/650614674" target="_blank" rel="noopener noreferrer">Kevin å´å˜‰æ–‡ï¼šDIFFUSION ç³»åˆ—ç¬”è®°|DDIM æ•°å­¦ã€æ€è€ƒä¸ ppdiffuser ä»£ç æ¢ç´¢<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://zhuanlan.zhihu.com/p/655679978" target="_blank" rel="noopener noreferrer">Kevin å´å˜‰æ–‡ï¼šDIFFUSION ç³»åˆ—ç¬”è®°| SDEï¼ˆä¸Šï¼‰<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h2 id="latent-diffusion-model" tabindex="-1"><a class="header-anchor" href="#latent-diffusion-model" aria-hidden="true">#</a> Latent Diffusion Model</h2><p>è®ºæ–‡ï¼šHigh-Resolution Image Synthesis with Latent Diffusion Models</p><figure><img src="https://pic3.zhimg.com/80/v2-da826549375793c4f8472a54a14c1616_1440w.webp" alt="LDM æ¶æ„å›¾" tabindex="0" loading="lazy"><figcaption>LDM æ¶æ„å›¾</figcaption></figure><h3 id="ldm-ä¸»è¦æ€æƒ³" tabindex="-1"><a class="header-anchor" href="#ldm-ä¸»è¦æ€æƒ³" aria-hidden="true">#</a> LDM ä¸»è¦æ€æƒ³</h3><p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ç›´æ¥åœ¨åƒç´ é¢†åŸŸå·¥ä½œï¼Œä¼˜åŒ–å’Œæ¨æ–­éƒ½å¾ˆè´¹æ—¶ã€‚ä¸ºäº†åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸Šè®­ç»ƒå®ƒä»¬ï¼ŒLDM å…ˆä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„ AutoEncoderï¼Œå°†å›¾ç‰‡åƒç´ è½¬æ¢åˆ°äº†ç»´åº¦è¾ƒå°çš„ latent space ä¸Šï¼Œè€Œåå†è¿›è¡Œä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹æ¨ç†ä¸ä¼˜åŒ–ã€‚è¿™ç§è®­ç»ƒæ–¹å¼ä½¿å¾— LDM åœ¨ç®—åŠ›å’Œæ€§èƒ½ä¹‹é—´å¾—åˆ°äº†å¹³è¡¡ã€‚</p><p>æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥äº¤å‰æ³¨æ„åŠ›ï¼Œä½¿å¾— DMs èƒ½å¤Ÿåœ¨æ¡ä»¶ç”Ÿæˆä¸Šæœ‰ä¸é”™çš„æ•ˆæœï¼ŒåŒ…æ‹¬å¦‚æ–‡å­—ç”Ÿæˆå›¾ç‰‡ï¼Œinpainting ç­‰ã€‚</p><h3 id="ldm-ä½¿ç”¨ç¤ºä¾‹" tabindex="-1"><a class="header-anchor" href="#ldm-ä½¿ç”¨ç¤ºä¾‹" aria-hidden="true">#</a> <strong>LDM ä½¿ç”¨ç¤ºä¾‹</strong></h3><p>huggingface Diffusers å°†å„ç§ Diffusion Model Pipeline éƒ½åŒ…è£…å¥½äº†ï¼Œä½¿ç”¨ Diffusion model å°±å’Œä½¿ç”¨ Transformers ä¸€æ ·åœ°æ–¹ä¾¿ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> diffusers </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> DiffusionPipeline</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># load model and scheduler</span></span>
<span class="line"><span style="color:#24292E;">ldm </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> DiffusionPipeline.from_pretrained(</span><span style="color:#032F62;">&quot;CompVis/ldm-text2im-large-256&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;"> </span><span style="color:#6A737D;"># run pipeline in inference (sample random noise and denoise)</span></span>
<span class="line"><span style="color:#24292E;">prompt </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;A painting of a squirrel eating a burger&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">images </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> ldm([prompt], </span><span style="color:#E36209;">num_inference_steps</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">50</span><span style="color:#24292E;">, </span><span style="color:#E36209;">eta</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">guidance_scale</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">).images</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># save images</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> idx, image </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(images):</span></span>
<span class="line"><span style="color:#24292E;">    image.save(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;squirrel-</span><span style="color:#005CC5;">{</span><span style="color:#24292E;">idx</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">.png&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="ldm-pipeline" tabindex="-1"><a class="header-anchor" href="#ldm-pipeline" aria-hidden="true">#</a> LDM Pipeline</h3><p>LDM çš„ pipeline å¯ä»¥ç®€åŒ–è¡¨ç¤ºä¸ºï¼š<code>Pipeline(prompt, num_inference_steps, latents)</code>ã€‚æˆ‘ä»¬æš‚æ—¶è€ƒè™‘æ²¡æœ‰ negative prompt å’Œ åˆå§‹ latent çš„è¾“å…¥ï¼Œé‚£ä¹ˆæ•´ä¸ªé‡‡æ ·è¿‡ç¨‹å¤§è‡´å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p><ol><li>é¦–å…ˆé‡‡ç”¨äº† BERT æ¶æ„æ¨¡å‹å¯¹ prompt è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆ <code>text_hidden_state</code>ï¼›åŒæ—¶ç”Ÿæˆéšæœºå™ªå£° <code>latents</code>ã€‚</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">text_hidden_state </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LDMBERT(prompt) </span><span style="color:#6A737D;"># shape=[bs, len_seq, d_model] = [1, 77, 1280] </span></span>
<span class="line"><span style="color:#24292E;">latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> randn_tensor(latents_shape) </span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>å¯¹äº <code>&quot;CompVis/ldm-text2im-large-256&quot;</code>ï¼Œå…¶ä¸­ä½¿ç”¨äº† <code>LDMBert</code>ï¼Œ å‚è€ƒ <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion.py" target="_blank" rel="noopener noreferrer">huggignface çš„ LDMBert<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> å®ç°ï¼Œ<code>LDMBert</code> ä¸ä¼ ç»Ÿ BERT æ¶æ„ç›¸ä¼¼ï¼Œè§„æ¨¡ä¸åŒï¼ŒLDMBert é‡‡ç”¨ 32 å±‚ï¼Œ hidden_size ä¸º 1280ï¼Œå±å®æ¯” bert-base å¤§ä¸Šä¸å°‘ã€‚åŒæ—¶æ–‡æœ¬è¢« padding åˆ°äº†å›ºå®šçš„ 77 é•¿åº¦ï¼Œä»¥æ­¤æ¥ä¿è¯æ–‡å­—çš„ hidden state æ ¼å¼ä¸º <code>[batch_size, 77, 1280]</code>ã€‚</p><ol start="2"><li>ä¹‹åè¿›è¡Œä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹ backward processï¼š</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> t </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.progress_bar(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.scheduler.timesteps):</span></span>
<span class="line"><span style="color:#24292E;">    noise_pred </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.unet(latents_input, t, </span><span style="color:#E36209;">encoder_hidden_states</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">context).sample</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span class="line"><span style="color:#24292E;">    latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.scheduler.step(noise_pred, t, latents, </span><span style="color:#D73A49;">**</span><span style="color:#24292E;">extra_kwargs).prev_sample</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>å…¶ä¸­ UNET ä¸º <code>UNet2DConditionModel</code>ï¼Œä¸ä¼ ç»Ÿ Unet ä¸åŒåœ¨äºå…¶åº”ç”¨äº† Cross Attention å¯¹æ–‡å­—ä»¥åŠå›¾ç‰‡ä¿¡æ¯è¿›è¡Œç»¼åˆå¤„ç†ï¼Œä¸‹æ–‡ä¼šå¯¹æ”¹æ¨¡å—åšæ¢³ç†ã€‚scheduler å¯ä»¥é€‰ DDIM æˆ–è€…å…¶ä»–ç®—æ³•ã€‚</p><ol start="3"><li>æœ€åå¯¹ latent hidden state è¿›è¡Œ decodeï¼Œç”Ÿæˆå›¾ç‰‡ï¼š</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.vqvae.config.scaling_factor </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> latents</span></span>
<span class="line"><span style="color:#24292E;">image </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.vqvae.decode(latents).sample</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="ldm-ä¸­çš„-unet" tabindex="-1"><a class="header-anchor" href="#ldm-ä¸­çš„-unet" aria-hidden="true">#</a> LDM ä¸­çš„ UNET</h4><p>backward process ä¸­çš„ <code>self.unet(...)</code>ï¼Œå³ <code>UNET2DCondition(sample, timestep, encoder_hidden_state)</code> å‰å‘æ¨å¯¼å¯ä»¥çœ‹æˆäº”éƒ¨åˆ†ï¼Œï¼ˆä»¥ä¸‹ä»¥ <code>CompVis/ldm-text2im-large-256</code> ä¸ºä¾‹ä»‹ç»ï¼‰ï¼š</p><ul><li><strong>å‡†å¤‡ time steps</strong> ï¼šTimesteps ç¼–ç ä¿¡æ¯æ˜¯ diffusion ä¸­ predict noise residual æ¨¡å‹çš„æ ‡é…ï¼š</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># ç»è¿‡ä¸¤æ¬¡æ˜ å°„å¾—åˆ° timesteps å¯¹åº”çš„ embedding</span></span>
<span class="line"><span style="color:#24292E;">t_emb </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.time_proj(timesteps)</span></span>
<span class="line"><span style="color:#24292E;">emb </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.time_embedding(t_emb, timestep_cond)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>pre-processï¼š</strong> LDM åªç”¨äº†ä¸€ä¸ª 2D å·ç§¯å¯¹è¾“å…¥çš„ hidden state è¿›è¡Œå¤„ç†</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span></span>
<span class="line"><span style="color:#24292E;">            in_channels, block_out_channels[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">], </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">conv_in_kernel, </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">conv_in_padding</span></span>
<span class="line"><span style="color:#24292E;">        )(sample)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>down sampling</strong> ï¼šdown sampling åŒ…æ‹¬äº† 3 ä¸ª <code>CrossAttnDownBlock2D</code>, å’Œ 1 ä¸ª <code>DownBlock2D</code>ã€‚</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># down sampling å¤§è‡´å‰å‘æ¨å¯¼</span></span>
<span class="line"><span style="color:#24292E;">down_block_res_samples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (sample,)</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> downsample_block </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.down_blocks:</span></span>
<span class="line"><span style="color:#24292E;">    sample, res_samples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> downsample_block(</span><span style="color:#E36209;">hidden_states</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">sample, </span><span style="color:#E36209;">temb</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">emb, </span><span style="color:#E36209;">scale</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">lora_scale)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># ç”¨äº UNET çš„æ®‹å·®é“¾æ¥</span></span>
<span class="line"><span style="color:#24292E;">    down_block_res_samples </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> res_samples</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>å…¶ä¸­æ¯ä¸ª <code>CrossAttnDownBlock2D</code> å¤§æ¦‚å‰å‘è¿‡ç¨‹ä¸ºï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># CrossAttnDownBlock2D</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, hidden_states, temb, encoder_hidden_states</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">	output_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> ()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> resnet, attn </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">zip</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.resnets, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.attentions):</span></span>
<span class="line"><span style="color:#24292E;">        hidden_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> resnet(hidden_states, temb)</span></span>
<span class="line"><span style="color:#24292E;">        hidden_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> attn(</span></span>
<span class="line"><span style="color:#24292E;">            hidden_states,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#E36209;">encoder_hidden_states</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">encoder_hidden_states,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#E36209;">cross_attention_kwargs</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">cross_attention_kwargs,</span></span>
<span class="line"><span style="color:#24292E;">        ).sample</span></span>
<span class="line"><span style="color:#24292E;">        output_states </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> (hidden_states,)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># downsampler = Conv2D </span></span>
<span class="line"><span style="color:#24292E;">    hidden_states </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> downsampler(hidden_states)</span></span>
<span class="line"><span style="color:#24292E;">    output_states </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> (hidden_states,)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> hidden_states, output_states</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>åœ¨ <code>CompVis/ldm-text2im-large-256</code> ä¸­ï¼Œæ¯ä¸ª <code>CrossAttnDownBlock2D</code> åŒ…å«äº† 2 ä¸ª <code>attn</code>ï¼ˆ<code>Transformer2DModel</code>ï¼‰ä»¥åŠ 2 ä¸ª <code>resnet</code> ï¼ˆ<code>ResnetBlock2D</code>ï¼‰ã€‚</p><p>æ–‡å­—ä¸å›¾åƒçš„äº¤äº’å°±å‘ç”Ÿåœ¨ <code>Transformer2DModel</code> å½“ä¸­ã€‚æ¯ä¸ª <a href="https://github.com/huggingface/diffusers/blob/16b9a57d29b6dbce4f97dbf439af1663d2c54588/src/diffusers/models/transformer_2d.py#L44C6-L44C6" target="_blank" rel="noopener noreferrer">Transformer2DModel<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> å…ˆå¯¹è¾“å…¥çš„å›¾åƒæ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå°†å›¾ç‰‡æ ¼å¼ä»å¦‚ <code>(batch_size, channel, width, height)</code> æˆ– <code>(batch_size, num_image_vectors)</code> è½¬æ¢ä¸º <code>(batch_size, len_seq, hidden_size)</code>ï¼Œè€Œåå°† <code>hidden_states</code> ä¼ å…¥ 1 å±‚ä¼ ç»Ÿ Transformer layerï¼ˆé bert æˆ– GPT ç±»å‹ï¼‰ï¼Œå…ˆå¯¹å›¾åƒ <code>hidden_states</code> è¿›è¡Œ self-attentionï¼Œè€Œåç»“åˆ <code>encoder_hidden_states</code> è¿›è¡Œ cross attention å¤„ç†ã€‚</p><ul><li><strong>mid processing:</strong></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> MidBlock2DCrossAttn()(sample, </span></span>
<span class="line"><span style="color:#24292E;">                              emb,</span></span>
<span class="line"><span style="color:#24292E;">                           encoder_hidden_states)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>åœ¨ <code>CompVis/ldm-text2im-large-256</code> ä¸­ï¼Œupsampling å’Œ down sampling ä¹‹é—´é‡‡ç”¨ <a href="https://github.com/huggingface/diffusers/blob/16b9a57d29b6dbce4f97dbf439af1663d2c54588/src/diffusers/models/unet_2d_blocks.py#L572" target="_blank" rel="noopener noreferrer">MidBlock2DCrossAttn<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> è¿æ¥ï¼Œ<code>MidBlock2DCrossAttn</code> åŒ…æ‹¬äº† 1 ä¸ª 1 å±‚çš„ <code>Transformer2DModel</code> ä»¥åŠ 1 ä¸ª <code>resnet</code> <code>ResnetBlock2D</code>ã€‚</p><ul><li><strong>upsampling</strong> ï¼šupsampling é‡‡ç”¨çš„æ¨¡å— UpBlocks åŒ…æ‹¬äº† <code> (&quot;UpBlock2D&quot;, &quot;CrossAttnUpBlock2D&quot;, &quot;CrossAttnUpBlock2D&quot;, &quot;CrossAttnUpBlock2D&quot;)</code>ï¼Œå„ä¸ªæ¨¡å—çš„æ¶æ„ä¸ down sampling ä¸­çš„æ¨¡å—ç›¸ä¼¼ã€‚</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># upsample_block</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, upsample_block </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.up_blocks):</span></span>
<span class="line"><span style="color:#24292E;">    sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> upsample_block(</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#E36209;">hidden_states</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">sample,</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#E36209;">temb</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">emb,</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#E36209;">res_hidden_states_tuple</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">res_samples,</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#E36209;">upsample_size</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">upsample_size,</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#E36209;">scale</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">lora_scale,</span></span>
<span class="line"><span style="color:#24292E;">                )</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>post-process</strong></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># GroupNorm</span></span>
<span class="line"><span style="color:#24292E;">sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv_norm_out(sample)</span></span>
<span class="line"><span style="color:#6A737D;"># Silu</span></span>
<span class="line"><span style="color:#24292E;">sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv_act(sample)</span></span>
<span class="line"><span style="color:#6A737D;"># Conv2d(320, 4, kernel=(3,3), s=(1,1), padding=(1,1))</span></span>
<span class="line"><span style="color:#24292E;">sample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv_out(sample)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>æ€»ç»“èµ·æ¥ï¼Œdown samplingï¼Œmidprocessï¼Œupsampling ä¸‰ä¸ªæ­¥éª¤ä¸­éƒ½æ¶‰åŠåˆ°äº† <code>Transformer2DModel</code> ï¼Œå®ç°å¤šæ¨¡æ€çš„ä¿¡æ¯äº¤äº’ã€‚</p><h3 id="ldm-super-resolution-pipeline" tabindex="-1"><a class="header-anchor" href="#ldm-super-resolution-pipeline" aria-hidden="true">#</a> LDM Super Resolution Pipeline</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">low_res_img </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Image.open(BytesIO(response.content)).convert(</span><span style="color:#032F62;">&quot;RGB&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">low_res_img </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> low_res_img.resize((</span><span style="color:#005CC5;">128</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">128</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E36209;">upscaled_image</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pipeline(low_res_img, </span><span style="color:#E36209;">num_inference_steps</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">, </span><span style="color:#E36209;">eta</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">).images[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">upscaled_image.save(</span><span style="color:#032F62;">&quot;ldm_generated_image.png&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>å¤§è‡´å‰é¡¹æ¨å¯¼æµç¨‹å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š</p><ol><li>æ ¹æ® è¾“å…¥å›¾ç‰‡å¤§å°ï¼Œç”Ÿæˆå¯¹åº”çš„ latent å™ªéŸ³ä»¥åŠ time step embeddingï¼š</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> randn_tensor(latents_shape, </span><span style="color:#E36209;">generator</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">generator, </span><span style="color:#E36209;">device</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.device, </span><span style="color:#E36209;">dtype</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">latents_dtype)  </span><span style="color:#6A737D;"># shape ä¸è¾“å…¥å›¾ç‰‡ç›¸åŒ</span></span>
<span class="line"><span style="color:#24292E;">latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> latents </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.scheduler.init_noise_sigma</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>å°† latent ä¸åŸå§‹å›¾ç‰‡æ‹¼æ¥ï¼Œç„¶åè¿›è¡Œ diffusion åå‘æ¨å¯¼ï¼š</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> t </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.progress_bar(timesteps_tensor):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># concat latents and low resolution image in the channel dimension.</span></span>
<span class="line"><span style="color:#24292E;">    latents_input </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.cat([latents, image], </span><span style="color:#E36209;">dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    latents_input </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.scheduler.scale_model_input(latents_input, t)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># predict the noise residual</span></span>
<span class="line"><span style="color:#24292E;">    noise_pred </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.unet(latents_input, t).sample</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span class="line"><span style="color:#24292E;">    latents </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.scheduler.step(noise_pred, t, latents, </span><span style="color:#D73A49;">**</span><span style="color:#24292E;">extra_kwargs).prev_sample</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>ä½¿ç”¨ vqvae å¯¹ latent è¿›è¡Œè§£ç ï¼Œå¾—åˆ°æœ€ç»ˆå›¾ç‰‡</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># decode the image latents with the VQVAE</span></span>
<span class="line"><span style="color:#24292E;">image </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.vqvae.decode(latents).sample</span></span>
<span class="line"><span style="color:#24292E;">image </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.clamp(image, </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1.0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.0</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">image </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> image </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span></span>
<span class="line"><span style="color:#24292E;">image </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> image.cpu().permute(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">).numpy()</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="stable-diffusion" tabindex="-1"><a class="header-anchor" href="#stable-diffusion" aria-hidden="true">#</a> Stable diffusion</h2><h3 id="sd-v1-æ¶æ„" tabindex="-1"><a class="header-anchor" href="#sd-v1-æ¶æ„" aria-hidden="true">#</a> SD v1 æ¶æ„</h3><p>å‚è€ƒ <a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py" target="_blank" rel="noopener noreferrer">hugging face diffuser çš„ SD pipeline å®ç°<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ã€‚ä»¥ <code>stable-diffusion-v1-5</code> ä¸ºä¾‹ã€‚</p><ol><li><strong>Text Encoder</strong></li></ol><p>é‡‡ç”¨ <code>CLIPTextModel</code>ï¼Œæ¥è‡ªäº <a href="https://arxiv.org/pdf/2103.00020.pdf" target="_blank" rel="noopener noreferrer">CLIP<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> çš„ Text Encoder éƒ¨åˆ†ã€‚ç›¸æ¯”äºå…¶ä»–ä¼ ç»Ÿçš„ Transformer è¯­è¨€æ¨¡å‹ï¼ŒCLIP åœ¨é¢„è®­ç»ƒæ—¶ï¼Œåœ¨ text-image pair æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒã€‚prompt_embeds, negative_prompt_embeds åœ¨ç»è¿‡ç¼–ç åï¼Œshape éƒ½ä¸º <code>[batch_size, 77, 768]</code></p><ol start="2"><li><strong>Diffusion åå‘é‡‡æ ·è¿‡ç¨‹</strong></li></ol><p>SD v1.5 é‡‡æ ·è¿‡ç¨‹ä¸ LDM ç›¸ä¼¼ï¼Œå…¶ä¸­çš„ latents å¤§å°ä¸º <code>[bs, 4, 64, 64]</code>ã€‚å¯¹äº txt2imgï¼Œlatents é€šè¿‡éšæœºç”Ÿæˆï¼Œå¯¹äº img2imgï¼Œlatents é€šè¿‡ VAE æ¨¡å‹è¿›è¡Œ encodeã€‚</p><p>Unet é…ç½®ä¸ LDM ç›¸ä¼¼ï¼š</p><ul><li><p>down sampling é‡‡ç”¨ 3 ä¸ª <code>CrossAttnDownBlock2D</code>, å’Œ 1 ä¸ª <code>DownBlock2D</code>ã€‚</p></li><li><p>mid block é‡‡ç”¨ 1 ä¸ª <code>MidBlock2DCrossAttn</code>ã€‚hidden size = 1280</p></li><li><p>Up sampling é‡‡ç”¨ 1 ä¸ª <code>UpBlock2D</code> + 3 ä¸ª <code>CrossAttnUpBlock2D</code></p></li></ul><p>æ¯ä¸ª CrossAttn çš„ transformer ä¸­ï¼Œ text embedding å¤§å°ä¸º 768ï¼Œä½† Transformer æ¨¡å—çš„ <code>hidden size</code> éšç€ Unet æ·±å…¥è€Œå¢åŠ ã€‚å¦‚ down sampling é‡‡ç”¨çš„ç»´åº¦ä¸º 320, 640, 1280, 1280ã€‚é‚£ä¹ˆ 3 ä¸ª Transformer æ¨¡å—ä¸­çš„ hidden size å°±åˆ†åˆ«æ˜¯ 320, 640, 1280ã€‚</p><p>ä»¥ down sampling ä¸ºä¾‹ï¼Œåœ¨è¿›è¡Œ cross attention æ—¶å€™ï¼Œå›¾åƒçš„ hidden state ï¼ˆlatentï¼‰å¤§å°åˆ†åˆ«è¢«æ˜ å°„åˆ°äº† <code>[4096, 320]</code>ï¼Œ<code>[2014, 640]</code>ï¼Œ<code>[256, 1280]</code> ï¼Œè€Œåä¸æ–‡å­—çš„ hidden state <code>[77, 768]</code> è¿›è¡Œ cross attention è®¡ç®—ã€‚ï¼ˆä»¥ä¸Šå¼ é‡ç»´åº¦çœç•¥äº† batch sizeï¼‰</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># hidden size ä¸º 320 æ—¶å€™çš„ cross attention å•å…ƒç¤ºä¾‹</span></span>
<span class="line"><span style="color:#24292E;">Attention(</span></span>
<span class="line"><span style="color:#24292E;">(to_q): LoRACompatibleLinear(</span><span style="color:#E36209;">in_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">320</span><span style="color:#24292E;">, </span><span style="color:#E36209;">out_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">320</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">(to_k): LoRACompatibleLinear(</span><span style="color:#E36209;">in_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">768</span><span style="color:#24292E;">, </span><span style="color:#E36209;">out_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">320</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">(to_v): LoRACompatibleLinear(</span><span style="color:#E36209;">in_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">768</span><span style="color:#24292E;">, </span><span style="color:#E36209;">out_features</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">320</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿™ä¹Ÿæ˜¯ SD Unet ä¸­ Transformer2DBlock ä¸ä¼ ç»Ÿ Transformer ä¸»è¦çš„ä¸åŒï¼ŒSD Unet ä¸­çš„ Transformer2DBlock è¾“å…¥ä¸è¾“å‡ºç»´åº¦æ˜¯ä¸ä¸€æ ·çš„ã€‚</p><ol start="3"><li><strong>super resolution</strong></li></ol><p>ç”Ÿæˆå latent å¤§å°ä¸º 64 * 64ï¼Œ é€šè¿‡ VQModel è§£ç ä¸º 512*512</p><h3 id="sd-v1-1-v1-5" tabindex="-1"><a class="header-anchor" href="#sd-v1-1-v1-5" aria-hidden="true">#</a> SD v1.1 - v1.5</h3><p>stable diffusion 1.1-1.5 çš„æ¨¡å‹æ¶æ„ç›¸åŒï¼Œä»¥ä¸‹æ¬è¿ <a href="https://github.com/runwayml/stable-diffusion#weights" target="_blank" rel="noopener noreferrer">runwayml<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> çš„ stable diffusion weights æ€»ç»“ï¼š</p><ul><li><p><a href="https://huggingface.co/compvis" target="_blank" rel="noopener noreferrer"><code>sd-v1-1.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: 237k steps at resolution <code>256x256</code> on <a href="https://huggingface.co/datasets/laion/laion2B-en" target="_blank" rel="noopener noreferrer">laion2B-en<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>. 194k steps at resolution <code>512x512</code> on <a href="https://huggingface.co/datasets/laion/laion-high-resolution" target="_blank" rel="noopener noreferrer">laion-high-resolution<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> (170M examples from LAION-5B with resolution <code>&gt;= 1024x1024</code>).</p></li><li><p><a href="https://huggingface.co/compvis" target="_blank" rel="noopener noreferrer"><code>sd-v1-2.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: Resumed from <code>sd-v1-1.ckpt</code>. 515k steps at resolution <code>512x512</code> on <a href="https://laion.ai/blog/laion-aesthetics/" target="_blank" rel="noopener noreferrer">laion-aesthetics v2 5+<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> (a subset of laion2B-en with estimated aesthetics score <code>&gt; 5.0</code>, and additionally filtered to images with an original size <code>&gt;= 512x512</code>, and an estimated watermark probability <code>&lt; 0.5</code>. The watermark estimate is from the <a href="https://laion.ai/blog/laion-5b/" target="_blank" rel="noopener noreferrer">LAION-5B<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> metadata, the aesthetics score is estimated using the <a href="https://github.com/christophschuhmann/improved-aesthetic-predictor" target="_blank" rel="noopener noreferrer">LAION-Aesthetics Predictor V2<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>).</p></li><li><p><a href="https://huggingface.co/compvis" target="_blank" rel="noopener noreferrer"><code>sd-v1-3.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: Resumed from <code>sd-v1-2.ckpt</code>. 195k steps at resolution <code>512x512</code> on &quot;laion-aesthetics v2 5+&quot; and 10% dropping of the text-conditioning to improve <a href="https://arxiv.org/abs/2207.12598" target="_blank" rel="noopener noreferrer">classifier-free guidance sampling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>.</p></li><li><p><a href="https://huggingface.co/compvis" target="_blank" rel="noopener noreferrer"><code>sd-v1-4.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: Resumed from <code>sd-v1-2.ckpt</code>. 225k steps at resolution <code>512x512</code> on &quot;laion-aesthetics v2 5+&quot; and 10% dropping of the text-conditioning to improve <a href="https://arxiv.org/abs/2207.12598" target="_blank" rel="noopener noreferrer">classifier-free guidance sampling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>.</p></li><li><p><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" target="_blank" rel="noopener noreferrer"><code>sd-v1-5.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: Resumed from <code>sd-v1-2.ckpt</code>. 595k steps at resolution <code>512x512</code> on &quot;laion-aesthetics v2 5+&quot; and 10% dropping of the text-conditioning to improve <a href="https://arxiv.org/abs/2207.12598" target="_blank" rel="noopener noreferrer">classifier-free guidance sampling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>.</p></li><li><p><a href="https://huggingface.co/runwayml/stable-diffusion-inpainting" target="_blank" rel="noopener noreferrer"><code>sd-v1-5-inpainting.ckpt</code><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>: Resumed from <code>sd-v1-5.ckpt</code>. 440k steps of inpainting training at resolution <code>512x512</code> on &quot;laion-aesthetics v2 5+&quot; and 10% dropping of the text-conditioning to improve <a href="https://arxiv.org/abs/2207.12598" target="_blank" rel="noopener noreferrer">classifier-free guidance sampling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>. For inpainting, the UNet has 5 additional input channels (4 for the encoded masked-image and 1 for the mask itself) whose weights were zero-initialized after restoring the non-inpainting checkpoint. During training, we generate synthetic masks and in 25% mask everything.</p></li></ul><h3 id="sd-v2" tabindex="-1"><a class="header-anchor" href="#sd-v2" aria-hidden="true">#</a> SD v2</h3><p>å‚è€ƒ <a href="https://github.com/Stability-AI/stablediffusion" target="_blank" rel="noopener noreferrer">stability-AI ä»“åº“<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ï¼ŒSD v2 ç›¸å¯¹ v1 ç³»åˆ—æ”¹åŠ¨è¾ƒå¤§ï¼š</p><p>æ¶æ„æ–¹é¢ SD v2 ç³»åˆ—ï¼š</p><ul><li>é‡‡ç”¨äº† <a href="https://github.com/mlfoundations/open_clip" target="_blank" rel="noopener noreferrer">OpenCLIP-ViT/H<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> ä½œä¸º text encoderã€‚</li><li>Unet æ¶æ„æ”¹å˜ï¼šå…¶ä¸­ Transformer æ¨¡å—ä¸­çš„ <code>attention_head_dim</code> å˜ä¸ºäº† <code>5,10,20,20</code>ï¼ŒSD v1 ä¸­ä¸º <code>8,8,8,8</code>ã€‚<code>cross_attention_dim</code> ä» 768 å˜ä¸º 1280ã€‚åŒæ—¶åœ¨ latent hidden state è¿›å…¥ cross attention ä¹‹å‰ï¼Œé¢å¤–é‡‡ç”¨äº† <code>linear_projection</code> è¿›è¡Œ latent hidden state çš„å¤„ç†ï¼ŒSD v1 ä¸­ä¸ºå·ç§¯å±‚å¤„ç†ã€‚</li></ul><p>è®­ç»ƒæ–¹é¢ SD v2 ç³»åˆ—ï¼Œï¼ˆä»¥ä¸‹æ‹·è´äº† huggingface ä¸­ SD æ¨¡å‹ model card çš„ä»‹ç»ï¼‰ ï¼š</p><ul><li><a href="https://huggingface.co/stabilityai/stable-diffusion-2-base" target="_blank" rel="noopener noreferrer">SD 2.0-base<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ï¼šThe model is trained from scratch 550k steps at resolution <code>256x256</code> on a subset of <a href="https://laion.ai/blog/laion-5b/" target="_blank" rel="noopener noreferrer">LAION-5B<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> filtered for explicit pornographic material, using the <a href="https://github.com/LAION-AI/CLIP-based-NSFW-Detector" target="_blank" rel="noopener noreferrer">LAION-NSFW classifier<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> with <code>punsafe=0.1</code> and an <a href="https://github.com/christophschuhmann/improved-aesthetic-predictor" target="_blank" rel="noopener noreferrer">aesthetic score<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> &gt;= <code>4.5</code>. Then it is further trained for 850k steps at resolution <code>512x512</code> on the same dataset on images with resolution <code>&gt;= 512x512</code>.</li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-2" target="_blank" rel="noopener noreferrer">SD v2.0<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ï¼šThis <code>stable-diffusion-2</code> model is resumed from <a href="https://huggingface.co/stabilityai/stable-diffusion-2-base" target="_blank" rel="noopener noreferrer">stable-diffusion-2-base<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> (<code>512-base-ema.ckpt</code>) and trained for 150k steps using a <a href="https://arxiv.org/abs/2202.00512" target="_blank" rel="noopener noreferrer">v-objective<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> on the same dataset. Resumed for another 140k steps on <code>768x768</code> images.</li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-2-1" target="_blank" rel="noopener noreferrer">SD v2.1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ï¼šThis <code>stable-diffusion-2-1</code> model is fine-tuned from <a href="https://huggingface.co/stabilityai/stable-diffusion-2" target="_blank" rel="noopener noreferrer">stable-diffusion-2<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> (<code>768-v-ema.ckpt</code>) with an additional 55k steps on the same dataset (with <code>punsafe=0.1</code>), and then fine-tuned for another 155k extra steps with <code>punsafe=0.98</code>.</li></ul><h2 id="lora" tabindex="-1"><a class="header-anchor" href="#lora" aria-hidden="true">#</a> Lora</h2><p>huggingface diffuser ä¸­ Lora çš„å®ç°ä¸ huggingface/PEFT å®ç°æ–¹æ³•ç›¸ä¼¼ï¼Œæ·»åŠ  Lora åªéœ€è¦é€šè¿‡æ’°å†™è§„åˆ™ï¼Œé”å®šéœ€è¦æ”¹åŠ¨çš„ layerï¼Œå¹¶æ›¿æ¢ä¸º LoRACompatibleLayer å®ç°ï¼Œhuggingface ä¹Ÿæä¾›å¥½äº† <a href="https://link.zhihu.com/?target=https%3A//huggingface.co/docs/diffusers/training/lora" target="_blank" rel="noopener noreferrer">lora è®­ç»ƒä»£ç <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>ï¼Œå’Œ SD lora æ¨ç†æ–¹æ³•ã€‚</p><p>Diffusers ä¸­ï¼ŒSD é‡‡ç”¨ Lora çš„éƒ¨åˆ†ä½äº Unet å½“ä¸­ï¼Œå¤§éƒ¨åˆ†çš„ Lora åœ¨ Transformer æ¨¡å—å½“ä¸­ï¼ŒSD çš„ lora ä¸ NLP Lora å®ç°æ–¹å¼åŸºæœ¬ç›¸åŒï¼Œ <strong>ä¸€ä¸ªè¾ƒå¤§çš„åŒºåˆ«åœ¨äºï¼ŒSD ä¸­çš„ Lora é™¤äº†å¯¹çº¿æ€§å±‚è¿›è¡Œ Lora å åŠ å¤–ï¼Œä¹Ÿå¯¹å·ç§¯å±‚è¿›è¡Œäº† Lora æ”¹é€ </strong> ã€‚</p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">ä¸Šæ¬¡ç¼–è¾‘äº: </span><!----></div><div class="contributors"><span class="label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="contributor" title="email: 417333277@qq.com">kevinng77</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer"><a href="https://beian.miit.gov.cn/" target="_blank">æ²ªICPå¤‡2023027904å·-1</a>&nbsp;<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" target="_blank"><img src="/assets/gongan.png">å…¬å®‰å¤‡æ¡ˆå· </a></div><div class="vp-copyright">Copyright Â© 2024 Kevin å´å˜‰æ–‡</div></footer></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-c62a9332.js" defer></script>
  </body>
</html>
