<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="http://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0reproduction_summary.html"><meta property="og:site_name" content="记忆笔书"><meta property="og:title" content="NLP 模型复现经验总结"><meta property="og:description" content="以 canine 复现为例，整理总结复现过程中重要的深度学习知识点。 简介 本文章对 NLP 论文复现的流程进行总结，包括模型编写、预训练权重转换；微调时候的大型数据处理、对卡训练、混合精度训练；模型推理部署。完整复现仓库：link 模型实现 模型定位 在一切复现之前，最重要的事情就是判断这篇文章是否值得复现，内容包括："><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-03-26T07:48:04.000Z"><meta property="article:author" content="Kevin 吴嘉文"><meta property="article:tag" content="NLP"><meta property="article:published_time" content="2022-06-20T00:00:00.000Z"><meta property="article:modified_time" content="2023-03-26T07:48:04.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"NLP 模型复现经验总结","image":[""],"datePublished":"2022-06-20T00:00:00.000Z","dateModified":"2023-03-26T07:48:04.000Z","author":[{"@type":"Person","name":"Kevin 吴嘉文"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&display=swap" rel="stylesheet"><link rel="icon" href="/logo.svg"><title>NLP 模型复现经验总结 | 记忆笔书</title><meta name="description" content="以 canine 复现为例，整理总结复现过程中重要的深度学习知识点。 简介 本文章对 NLP 论文复现的流程进行总结，包括模型编写、预训练权重转换；微调时候的大型数据处理、对卡训练、混合精度训练；模型推理部署。完整复现仓库：link 模型实现 模型定位 在一切复现之前，最重要的事情就是判断这篇文章是否值得复现，内容包括：">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-99575b2e.css" as="style"><link rel="stylesheet" href="/assets/style-99575b2e.css">
    <link rel="modulepreload" href="/assets/app-2598c59c.js"><link rel="modulepreload" href="/assets/笔记reproduction_summary.html-b797e7d6.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/笔记reproduction_summary.html-3a8bb381.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><!----><!----><span class="vp-site-name">记忆笔书</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="主页" class="vp-link nav-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="归档" class="vp-link nav-link nav-link" href="/timeline/"><span class="font-icon icon iconfont icon-categoryselected" style=""></span>归档<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/kevinng77" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" role="search" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->NLP 模型复现经验总结</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Kevin 吴嘉文</span></span><span property="author" content="Kevin 吴嘉文"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-06-20T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 12 分钟</span><meta property="timeRequired" content="PT12M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category7 clickable" role="navigation">知识笔记</span><!--]--><meta property="articleSection" content="知识笔记"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag8 clickable" role="navigation">NLP</span><!--]--><meta property="keywords" content="NLP"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#简介">简介</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#模型实现">模型实现</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#模型定位">模型定位</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#模型编写">模型编写</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#预训练权重转换">预训练权重转换</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#静态图-动态图">静态图，动态图</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#数据处理">数据处理</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#数据加载">数据加载</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#相关-api">相关 API</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#h5df">H5DF</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#训练">训练</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#混合精度训练">混合精度训练</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#梯度累加">梯度累加</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#单机多卡训练">单机多卡训练</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#推理部署">推理部署</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#其他">其他</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#pdb-调试">pdb 调试</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#segmentation-fault-报错分析">segmentation fault 报错分析</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="/#windows-环境还是很多坑">windows 环境还是很多坑</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><p>以 canine 复现为例，整理总结复现过程中重要的深度学习知识点。</p><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介" aria-hidden="true">#</a> 简介</h2><p>本文章对 NLP 论文复现的流程进行总结，包括模型编写、预训练权重转换；微调时候的大型数据处理、对卡训练、混合精度训练；模型推理部署。完整复现仓库：<a href="https://github.com/kevinng77/canine_paddle" target="_blank" rel="noopener noreferrer">link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="模型实现" tabindex="-1"><a class="header-anchor" href="#模型实现" aria-hidden="true">#</a> 模型实现</h2><h3 id="模型定位" tabindex="-1"><a class="header-anchor" href="#模型定位" aria-hidden="true">#</a> 模型定位</h3><p>在一切复现之前，最重要的事情就是判断这篇文章是否值得复现，内容包括：</p><ul><li><strong>复现难度：</strong> 你是否具备复现所需要的设备？训练模型所需要的时间是否充足？</li><li><strong>模型成就水平：</strong> 模型的指标是否可信，模型拿了哪些 SOTA？评测的数据库是否权威？算法是否优雅？</li><li><strong>论文合理性：</strong> 尽量避开有坑的论文。复现前检查论文是否具备完整的源码，浏览下论文仓库 issue 区。过一下论文大致框架。时间允许的话可以跑以下官方源码。</li></ul><p>不要迷恋大厂光环，如 google 的 CANINE 论文就充满了槽点，模型架构没什么创新，模型指标也一般般。CANINE 论文中声明该模型比 TydiQA 基线采用的 mBert 高了约 2%，看似不错，但同年发布的其他 TydiQA Top 5 模型比 CANINE 指标还要高出约 7% 到 13%。再者 TydiQA 数据集较为小众，排行榜发布两年到现在也就个位数的模型投榜。因此个人认为 CANINE 有点水论文的嫌疑了。</p><p>此外从 TydiQA 源码中的算法来看，该团队的作风有些诡异。如<a href="https://github.com/google-research-datasets/tydiqa" target="_blank" rel="noopener noreferrer">官方仓库<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 中的：</p><ul><li><code>run_tydi_lib.py</code> 中在 GPU 训练过程中插入了频繁的 CPU 计算，大大降低显卡使用率；</li><li><code>postproc.py</code> 中内存管理极不合理，实际运行官方源码，你需要 120G+ 的内存；然而经过笔者的优化测试，在程序效率不变的情况下，10G+的内存就可以搞定了。</li><li><code>postproc.py</code> 中计算效率极为缓慢，文件中存在诸多与 TydiQA 任务结果无关的计算，并且没有任何优化计算的方案，笔者通过加入多线程、清理无用中间变量，将数据处理时间从官方文件的 3 小时减少到了仅 20 分钟。</li></ul><h3 id="模型编写" tabindex="-1"><a class="header-anchor" href="#模型编写" aria-hidden="true">#</a> 模型编写</h3><p>复现一定不是从绝对的零开始，大部分复现都是基于已有的算子、模型框架进行编写。如 CANINE 采用了 Transformer Encoder 作为主编码器，因此若基于 Bert 模型进行修改，1 天便能完成模型架构的编写。若是从 0 开始自己拼算子，只怕需要花上个一周甚至更久。</p><p>算子也可能存在 bug，如 paddle 的 <code>repeat_interleave</code> 就存在反向传播时候的 <code>segmentation fault</code> 问题</p><h3 id="预训练权重转换" tabindex="-1"><a class="header-anchor" href="#预训练权重转换" aria-hidden="true">#</a> 预训练权重转换</h3><p>使用 paddle 或者其他框架时，可以考虑转换已有的 huggingface 预训练权重而非自己训练预训练权重。转换好的权重可以上传至 huggingface.co （记得使用 git lfs）</p><h3 id="静态图-动态图" tabindex="-1"><a class="header-anchor" href="#静态图-动态图" aria-hidden="true">#</a> 静态图，动态图</h3><p>个人喜欢使用动态图构建框架，在实现后转为静态图进行服务部署。</p><p>相关链接：<a href="https://zhuanlan.zhihu.com/p/191648279" target="_blank" rel="noopener noreferrer">动态图，静态图<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/jit/index_cn.html" target="_blank" rel="noopener noreferrer">飞桨 动态图转静态图 <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>，<a href="https://www.paddlepaddle.org.cn/tutorials/projectdetail/1499114" target="_blank" rel="noopener noreferrer">飞桨产业级实践深度学习-<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>根据 operator 算子解析执行方式不同，模型可以分为动态图和静态图。</p><table><thead><tr><th></th><th>动态图</th><th>静态图</th></tr></thead><tbody><tr><td>编程范式</td><td>命令式编程范式</td><td>声明式编程范式</td></tr><tr><td>执行方式</td><td>用户无需预先定义完整的网络结构，每写一行网络代码，即可同时获得计算结果。</td><td>先编译后执行，用户需预先定义完整的网络结构，再对网络结构进行编译优化后，才能执行获得计算结果。</td></tr><tr><td>编程体验</td><td>可以使用 python 原生的控制流，容易开发、调试</td><td>调试不方便，开发有一定门槛，过程中的算子需要有 action（如 .run()）才会执行。</td></tr><tr><td>性能</td><td>动态图需要在 python 与 C++计算库之间频繁切换，导致了更大的时间开销。</td><td>一般采用 C++ 性能更优。</td></tr><tr><td>模型架构</td><td>无需使用占位符</td><td>静态图组网阶段并没有实际运行网络，因此并不读入数据，所以需要使用“占位符”（如 paddle.data）指明输入数据的类型、shape 等信息，以完成组网。</td></tr></tbody></table><p><strong>动态图转静态</strong></p><p>除了手动编写静态图代码外，部分框架也提供了动转静的 API，如 paddle 只需要采用 <code>paddle.jit.to_static()</code> 。动态图转静态的一部分优化内容在于使用 python 定义的控制流，如 <code>for</code>, <code>while</code> 等。</p><p><strong>paddle 动态图转静态图注意点：</strong></p><ul><li>需要注意控制流的使用方式，如 for range 等，详细可查看 <a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/jit/grammar_list_cn.html#8" target="_blank" rel="noopener noreferrer">支持语法<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。</li></ul><p>for range 中不支持参数传递 step 值，如 <code>for x in range(0,n, step):</code>，可改用 while 替代。</p><p><code>for a,b,c,d in xs:</code> 报错，采用 <code>for x in xs: a,b,c,d = x</code> 代替</p><ul><li><p>模型中比较常见的控制流转写大多数与 <code>batch_size</code> 或者 <code>x.shape</code> 相关。</p><p><code>x.shape[i]</code> 的返回值可能是固定的值，也可能是 <code>None</code> ，表示动态 shape（如 batch_size）。</p><p>如果比较明确 <code>x.shape[i]</code> 对应的是 <strong>动态 shape</strong> ，推荐使用 <code>paddle.shape(x)[i]</code>，特别是在生成 position_ids 的时候。</p></li><li><p>错误：Intel MKL function load error: cpu specific dynamic library is not loaded。环境问题，尝试 <code>conda install nomkl</code></p></li><li><p><code>paddle.jit.set_code_level()</code> 打印转换后的静态图模型代码。</p></li><li><p>若出现推理时候的维度错误，但模型动态转静态无报错，那么大概错误在于 reshape 或者 unsqeeze 时候维度出问题。1. 尽量少用 <code>axis=-1</code>；2. 检查所有的维度变换是否正确；3.检查是否使用 <code>paddle.shape(x)[i]</code>来获取动态维度，如 <code>batch_size</code>, <code>len_seq</code> 等。</p></li></ul><h2 id="数据处理" tabindex="-1"><a class="header-anchor" href="#数据处理" aria-hidden="true">#</a> 数据处理</h2><p>背景：训练数据集太大，一次性加载不进内存中。</p><h3 id="数据加载" tabindex="-1"><a class="header-anchor" href="#数据加载" aria-hidden="true">#</a> 数据加载</h3><p>场景：NLP 预训练任务，文本数据集大。</p><table><thead><tr><th>储存方式</th><th>文件格式</th><th>Dataset</th><th>备注</th><th>shuffle</th></tr></thead><tbody><tr><td>单个大文件</td><td>pickle/jsonl/txt 等</td><td>map dataset/iterable dataset</td><td>使用更好的机器，将所有样本加载到内存中。</td><td>可以</td></tr><tr><td>单个大文件</td><td>pickle/jsonl/txt 等</td><td>map dataset</td><td><a href="https://zhuanlan.zhihu.com/p/460012052" target="_blank" rel="noopener noreferrer">知乎链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> ,计算每个样本的 offset，移动指针截取样本。</td><td>可以</td></tr><tr><td>多个中文件</td><td>pickle/jsonl/txt 等</td><td>iterable dataset</td><td>每个文件储存一定数量的样本，内次加载部分样本到内存中，样本加载速度远大于楼下。</td><td>不能全局 shuffle</td></tr><tr><td>超多个小文件</td><td>pickle/jsonl/txt 等</td><td>map dataset</td><td>将每个样本储存在一个文件中，通过索引 文件名获取样本。I/O 的开销非常大。</td><td>支持全局 shuffle</td></tr><tr><td>数据库</td><td>h5df, tfrecord 等</td><td>map dataset</td><td>所有样本储存在同一数据库中，通过索引数据库获取样本。</td><td>支持全局 shuffle，但影响性能</td></tr></tbody></table><h3 id="相关-api" tabindex="-1"><a class="header-anchor" href="#相关-api" aria-hidden="true">#</a> 相关 API</h3><p><code>Dataset</code></p><p>常用的 dataset 有 <code>MapDataset</code> 和 <code>IterableDataset</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">TydiDataset</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">paddle</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">io</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">IterableDataset</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    Construct Dataset Class for Canine TydiQA task.</span></span>
<span class="line"><span style="color:#032F62;">Args:</span></span>
<span class="line"><span style="color:#032F62;">    file_names (List[int]): the names of input files.</span></span>
<span class="line"><span style="color:#032F62;">    sample_dir (str): The directory of folder storing input sample files, which contains a single</span></span>
<span class="line"><span style="color:#032F62;">        training sample respectively.</span></span>
<span class="line"><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self,</span></span>
<span class="line"><span style="color:#24292E;">                 file_names,</span></span>
<span class="line"><span style="color:#24292E;">                 sample_dir: </span><span style="color:#005CC5;">str</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;/data/tydi/train_samples&quot;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                 ):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">(TydiDataset, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">).</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.all_file_path </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> file_name </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> file_names:</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.all_file_path.append(os.path.join(sample_dir, file_name))</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__iter__</span><span style="color:#24292E;">(self):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> paddle.distributed.get_world_size() </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            file_list </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.all_file_path</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">else</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            worker_info </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> paddle.io.get_worker_info()</span></span>
<span class="line"><span style="color:#24292E;">            num_files </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.all_file_path)</span></span>
<span class="line"><span style="color:#24292E;">            files_per_worker </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">int</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">                math.ceil(num_files </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">float</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">                    worker_info.num_workers)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">            worker_id </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> worker_info.id</span></span>
<span class="line"><span style="color:#24292E;">            iter_start </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> worker_id </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> files_per_worker</span></span>
<span class="line"><span style="color:#24292E;">            iter_end </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">min</span><span style="color:#24292E;">(iter_start </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> files_per_worker, num_files)</span></span>
<span class="line"><span style="color:#24292E;">            file_list </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.all_file_path[iter_start:iter_end]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> file_name </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> file_list:</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#D73A49;">with</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">open</span><span style="color:#24292E;">(file_name,</span><span style="color:#032F62;">&quot;rb&quot;</span><span style="color:#24292E;">) </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> fp:</span></span>
<span class="line"><span style="color:#24292E;">                </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> sample </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> pickle.load(fp):</span></span>
<span class="line"><span style="color:#24292E;">                    </span><span style="color:#D73A49;">yield</span><span style="color:#24292E;"> sample</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>DataLoader </code></p><ul><li><a href="https://www.zhihu.com/question/422160231/answer/1484767204" target="_blank" rel="noopener noreferrer">num workers 和 dataloader<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> - 似乎不太起作用？个人测试对于小 batch size，提高 <code>num_worker</code> 会有部分效果提升。</li></ul><p><code>DistrubutedBatchSampler</code></p><p>多卡训练下，数据的分配是个关键问题。采用 dataset 时可以手动设置每个卡读取的样本，如上述案例代码。若使用 <code>MapDataset</code>，则可以考虑使用 <code>DistributedBatchSampler</code> 来自动分配每个卡的样本，以保证样本不重叠。</p><h3 id="h5df" tabindex="-1"><a class="header-anchor" href="#h5df" aria-hidden="true">#</a> H5DF</h3><p>Canine 的指标是根据 TydiQA 数据集进行评测的，其中 TydiQA 数据集在数据处理过程中，使用了 tfrecord + tftensor 进行数据存储。为了适配 Paddle 的训练，笔者尝试了使用 H5DF 代替 tfrecord，在数据处理过程中，H5DF 的空间占用与 tfrecord 旗鼓相当，训练过程中，H5DF 也能提供足够的速度，以保证训练效率上与从内存加载数据集的效率相近。</p><p>相比于使用 pickle 或者 jsonl + 压缩的方式储存文件。H5DF 的数据处理方式更佳优雅，笔者个人也是推荐采用 h5df 的。关于 H5DF 的经验分享，欢迎参考我的博客 <a href="http://wujiawen.xyz/archives/h5dfh5py%E6%96%87%E6%A1%A3%E5%B0%8F%E6%95%B4%E7%90%86" target="_blank" rel="noopener noreferrer">H5DF | H5py 文档小整理<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。更多详细，请参考 <a href="https://docs.h5py.org/en/stable/high/dataset.html#creating-datasets" target="_blank" rel="noopener noreferrer">HDF5 官方文档链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="训练" tabindex="-1"><a class="header-anchor" href="#训练" aria-hidden="true">#</a> 训练</h2><h3 id="混合精度训练" tabindex="-1"><a class="header-anchor" href="#混合精度训练" aria-hidden="true">#</a> 混合精度训练</h3><p>混合精度训练，短短的几行代码，在节省显存占用 40%+，训练速度翻倍的前提下，能够做到模型准确率几乎不减少！该部分笔者也在个人博客 <a href="http://wujiawen.xyz/archives/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83" target="_blank" rel="noopener noreferrer">混合精度训练<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 中进行了整理。</p><h3 id="梯度累加" tabindex="-1"><a class="header-anchor" href="#梯度累加" aria-hidden="true">#</a> 梯度累加</h3><p>可以近似地模拟大 batch：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292E;">global_step </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i, (inputs, labels) </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(training_set):</span></span>
<span class="line"><span style="color:#24292E;">  loss </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model(inputs, labels)                    </span></span>
<span class="line"><span style="color:#24292E;">  loss </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> loss </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> accumulation_steps                </span></span>
<span class="line"><span style="color:#24292E;">  loss.backward()  </span></span>
<span class="line"><span style="color:#24292E;">  global_step </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">  </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> global_step </span><span style="color:#D73A49;">%</span><span style="color:#24292E;"> accumulation_steps </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">:             </span></span>
<span class="line"><span style="color:#24292E;">      optimizer.step()                            </span></span>
<span class="line"><span style="color:#24292E;">      model.zero_grad()                           </span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="单机多卡训练" tabindex="-1"><a class="header-anchor" href="#单机多卡训练" aria-hidden="true">#</a> 单机多卡训练</h3><p>需要注意几个概念：模型并行与数据并行，Parameter Server 与 Ring All-Reduce，同步训练与异步训练。通常单机多卡采用数据并行，GPU 之间大多使用 Ring-All-reduce 进行同步。可以参考：<a href="https://zhuanlan.zhihu.com/p/56991108" target="_blank" rel="noopener noreferrer">一文说清楚 Tensorflow 分布式训练必备知识<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 等。</p><p>对于 torch，单机多卡可以使用 <code>DataParallel</code>（PS 架构，异步训练）。或者 <code>DistributedDataParallel</code> （Ring All-Reduce，同步训练）；对于 paddle，其中的 <code>DataParallel</code> 默认采用的已经是 Ring All-Reduce 了。使用单机多卡训练的操作也比较简介，通常只需要初始化多进程多卡，模型分配等环节即可，以下以 paddle 为例总结（torch 类似）。paddle 可以采用 paddle 的 spawn 或者通过 <code>paddle.distributed.launch</code> 开启多进程多卡训练。只要对单机单卡进行简单的修改即可：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6A737D;"># 添加以下语句</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> paddle </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> distributed </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> dist</span></span>
<span class="line"><span style="color:#D73A49;">if</span><span style="color:#24292E;"> dist.get_world_size() </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    dist.init_parallel_env()</span></span>
<span class="line"><span style="color:#24292E;">    model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> paddle.DataParallel(model)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通常多卡训练时的日志操作比较麻烦，常见的方法是使用 <code>get_rank()</code> 选择发布日志的进程，而后进行操作，如：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#D73A49;">if</span><span style="color:#24292E;"> dist.get_rank() </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">    paddle.save(model.state_dict(), os.path.join(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.output_dir, name))</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 只需要一个进程保存模型即可</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#D73A49;">if</span><span style="color:#24292E;"> dist.get_world_size() </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">:  </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 对所有进程的数据进行汇总，这边使用 ALL_GATHER,也可以用别的算子， 如 ALL_REDUCE</span></span>
<span class="line"><span style="color:#24292E;">    dist.all_gather(loss_list, local_loss)</span></span>
<span class="line"><span style="color:#24292E;">    dist.all_gather(dev_loss_list, dev_loss_tensor)</span></span>
<span class="line"><span style="color:#24292E;">    dist.all_gather(acc_list, acc)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> dist.get_rank() </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">        logging_loss </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (paddle.stack(loss_list).sum() </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">            loss_list)).item()</span></span>
<span class="line"><span style="color:#24292E;">        dev_loss </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (paddle.stack(dev_loss_list).sum() </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">            dev_loss_list)).item()</span></span>
<span class="line"><span style="color:#24292E;">        logging_acc </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (paddle.stack(acc_list).sum() </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(</span></span>
<span class="line"><span style="color:#24292E;">            acc_list)).item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        logger.info(</span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot;Step </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">global_step</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">/</span><span style="color:#005CC5;">{</span><span style="color:#24292E;">num_train_steps</span><span style="color:#005CC5;">}</span><span style="color:#032F62;"> train loss </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">logging_loss</span><span style="color:#D73A49;">:.4f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span></span>
<span class="line"><span style="color:#24292E;">                                            </span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot; dev loss </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">dev_loss</span><span style="color:#D73A49;">:.4f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;"> acc </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">logging_acc</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">% diff </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">logging_diff</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&quot;</span></span>
<span class="line"><span style="color:#24292E;">                                            </span><span style="color:#D73A49;">f</span><span style="color:#032F62;">&quot; time </span><span style="color:#005CC5;">{</span><span style="color:#24292E;">(time.time() </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> time1) </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">60</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">min&quot;</span></span>
<span class="line"><span style="color:#24292E;">                                            )</span></span>
<span class="line"><span style="color:#24292E;">        dist.barrier()  </span><span style="color:#6A737D;"># 阻塞其他进程，等待 0 号进程处理完毕。</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>多卡学习需要注意：</p><ul><li>batch size 与 学习率的调整</li><li>多卡下需要注意数据集的分配，可以使用 <code>DistributeBatchSampler</code> 来自动分配样本。</li><li>混合精度+多卡训练可能要预留一部分的显存出来，不然可能训练到一半发现 OOM 了</li></ul><h2 id="推理部署" tabindex="-1"><a class="header-anchor" href="#推理部署" aria-hidden="true">#</a> 推理部署</h2><p><a href="https://www.paddlepaddle.org.cn/tutorials/projectdetail/3952715" target="_blank" rel="noopener noreferrer">paddle 产业级推理部署<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="其他" tabindex="-1"><a class="header-anchor" href="#其他" aria-hidden="true">#</a> 其他</h2><h3 id="pdb-调试" tabindex="-1"><a class="header-anchor" href="#pdb-调试" aria-hidden="true">#</a> pdb 调试</h3><blockquote><p>pdb 调试更加灵活，可以使用条件判断语句，在代码中任意选择断点。这通常是 IDE 做不到的。</p></blockquote><p><strong>step1：</strong> 在想要进行调试的代码前插入<code>import pdb; pdb.set_trace()</code>开启 pdb 调试。</p><p><strong>step2：</strong> 正常运行.py 文件，在终端会出现下面类似结果，在<code>(Pdb)</code>位置后输入相应的 pdb 命令进行调试。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#24292e;">&gt; /tmp/tmpm0iw5b5d.py(9)func()</span></span>
<span class="line"><span style="color:#24292e;">-&gt; two = paddle.full(shape=[1], fill_value=2, dtype=&#39;int32&#39;)</span></span>
<span class="line"><span style="color:#24292e;">(Pdb)</span></span>
<span class="line"><span style="color:#24292e;"></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>step3：</strong> 在 pdb 交互模式下输入 l、p 等命令可以查看相应的代码、变量，进而排查相关的问题。<a href="https://docs.python.org/zh-cn/3/library/pdb.html" target="_blank" rel="noopener noreferrer">pdb 官方<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">l</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 查看当前位置的源代码</span></span>
<span class="line"><span style="color:#6F42C1;">p</span><span style="color:#24292E;"> </span><span style="color:#032F62;">expression</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 查看上下文打印 expression 的值，如 p x</span></span>
<span class="line"><span style="color:#6F42C1;">s</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 执行下一行，进入函数内部</span></span>
<span class="line"><span style="color:#6F42C1;">n</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 执行下一行，不进入函数</span></span>
<span class="line"><span style="color:#6F42C1;">r</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 执行代码到函数返回处</span></span>
<span class="line"><span style="color:#6F42C1;">b</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">30</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 在 30 行处设置断点</span></span>
<span class="line"><span style="color:#6F42C1;">c</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 执行代码，直到下一个断点</span></span>
<span class="line"><span style="color:#6F42C1;">q</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 退出调试</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="segmentation-fault-报错分析" tabindex="-1"><a class="header-anchor" href="#segmentation-fault-报错分析" aria-hidden="true">#</a> segmentation fault 报错分析</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#005CC5;">ulimit</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-c</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># 查看 core 限制大小</span></span>
<span class="line"><span style="color:#6A737D;"># 0</span></span>
<span class="line"><span style="color:#6F42C1;">cat</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/proc/sys/kernel/core_pattern</span><span style="color:#24292E;"> </span><span style="color:#6A737D;">#  查看 core 生成路径</span></span>
<span class="line"><span style="color:#6A737D;"># core</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>现象：</p><p>我们执行生成 core 的文件并不是在 linux 的目录下，而是在 windows 和 linux 共享的 hgfs 下，导致生成的 core.xxx 都是 0 字节大小。</p><p>解决： 把需要运行的程序拷贝到 linux 的<a href="https://so.csdn.net/so/search?q=%E6%A0%B9%E7%9B%AE%E5%BD%95&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">根目录<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>下运行即可。<a href="https://zhuanlan.zhihu.com/p/201330829" target="_blank" rel="noopener noreferrer">方案 1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>, <a href="https://blog.csdn.net/dzhongjie/article/details/80280192" target="_blank" rel="noopener noreferrer">方案 2<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><ul><li><p>修改 core 文件大小限制<code>ulimit -c unlimit</code></p></li><li><p>重新运行会 segmentation fault 的程序。</p></li><li><p>目录下生成 core 文件，检查 core 文件大小不为 0</p></li><li><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">gdb</span><span style="color:#24292E;"> </span><span style="color:#032F62;">`</span><span style="color:#6F42C1;">whichi</span><span style="color:#032F62;"> python`</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">core</span><span style="color:#24292E;"> </span></span>
<span class="line"><span style="color:#6A737D;"># 用 python 解释器来进行 gdb core 分析</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><p>由于 docker 容器的权限问题，默认无法产生 core 文件，需要做一些配置修改。</p><p>在宿主机上修改 core 路径</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#005CC5;">echo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;/tmp/core.%t.%e.%p&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">|</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">sudo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">tee</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/proc/sys/kernel/core_pattern</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这是因为系统在产生 Core Dump 文件的时候是根据 /proc/sys/kernel/core_pattern 的设定。而默认的设定是 |/usr/share/apport/apport %p %s %c %P，也就是用管道传给 apport。然而 Docker 里面的系统不一定有装 apport，并且 /proc 又是直接挂到 Docker 里面的，所以我们就得改成放到固定的位置去，也就是 /tmp。</p><p>另外，在 docker run 的时候要加上以下参数</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="shiki github-light" style="background-color:#fff;" tabindex="0"><code><span class="line"><span style="color:#6F42C1;">--ulimit</span><span style="color:#24292E;"> </span><span style="color:#032F62;">core=</span><span style="color:#005CC5;">-1</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--security-opt</span><span style="color:#24292E;"> </span><span style="color:#032F62;">seccomp=unconfined</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="windows-环境还是很多坑" tabindex="-1"><a class="header-anchor" href="#windows-环境还是很多坑" aria-hidden="true">#</a> windows 环境还是很多坑</h3><p>尝试了 WSL2 下进行开发，还是感觉原先纯 LINUX 的环境更适应一点。Windows WSL 下存在 git 使用不方便，文件磁盘格式问题，文件权限有限等。</p><p>linux 和 windows 换行符：导致各种错误，如 pre-commit， sh 文件解析错误，markdown 文件解析错误等。解决方法： vim 中使用 <code>:set ff=unix</code> 或者 vscode 等编辑器中设置换行符为 lr</p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 417333277@qq.com">kevinng77</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer"><a href="https://beian.miit.gov.cn/" target="_blank">沪ICP备2023027904号-1</a>&nbsp;<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" target="_blank"><img src="/assets/gongan.png">公安备案号 </a></div><div class="vp-copyright">Copyright © 2024 Kevin 吴嘉文</div></footer></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-2598c59c.js" defer></script>
  </body>
</html>
