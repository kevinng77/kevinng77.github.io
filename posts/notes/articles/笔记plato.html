<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.61" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="http://wujiawen.xyz/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html"><meta property="og:site_name" content="记忆笔书"><meta property="og:title" content="对话模型 PLATO 系列论文笔记"><meta property="og:description" content="对话模型 PLATO 系列论文笔记 最近又开始着迷对话系统了，于是花时间看了以下几个中文比较有意思的模型。本文对 PLATO，PLATO=2， PLATO-XL，PLATO-KAG 四篇论文进行笔记梳理与总结。 PLATO 论文：PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable 概述 比较早的论文了，论文一上来提出，如果直接使用 Bert 在小规模的对话数据集上微调对话任务，其效果是很差的，基于这些问题，论文给出了几点原因猜测："><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-03-26T07:48:04.000Z"><meta property="article:author" content="Kevin 吴嘉文"><meta property="article:tag" content="NLP"><meta property="article:published_time" content="2022-10-05T00:00:00.000Z"><meta property="article:modified_time" content="2023-03-26T07:48:04.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"对话模型 PLATO 系列论文笔记","image":[""],"datePublished":"2022-10-05T00:00:00.000Z","dateModified":"2023-03-26T07:48:04.000Z","author":[{"@type":"Person","name":"Kevin 吴嘉文"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;700&display=swap" rel="stylesheet"><link rel="icon" href="/logo.svg"><title>对话模型 PLATO 系列论文笔记 | 记忆笔书</title><meta name="description" content="对话模型 PLATO 系列论文笔记 最近又开始着迷对话系统了，于是花时间看了以下几个中文比较有意思的模型。本文对 PLATO，PLATO=2， PLATO-XL，PLATO-KAG 四篇论文进行笔记梳理与总结。 PLATO 论文：PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable 概述 比较早的论文了，论文一上来提出，如果直接使用 Bert 在小规模的对话数据集上微调对话任务，其效果是很差的，基于这些问题，论文给出了几点原因猜测：">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-f0172e8a.css" as="style"><link rel="stylesheet" href="/assets/style-f0172e8a.css">
    <link rel="modulepreload" href="/assets/app-16d0ff63.js"><link rel="modulepreload" href="/assets/framework-d5c0d2cb.js"><link rel="modulepreload" href="/assets/笔记plato.html-e1bf5dcb.js"><link rel="modulepreload" href="/assets/笔记plato.html-31e56f01.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container no-sidebar has-toc"><!--[--><header class="navbar" id="navbar"><div class="navbar-start"><button type="button" class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><a href="/" class="brand"><!----><!----><span class="site-name">记忆笔书</span></a><!--[--><!----><!--]--></div><div class="navbar-center"><!--[--><!----><!--]--><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/" class="nav-link" aria-label="主页"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="博文"><span class="title"><span class="font-icon icon iconfont icon-blog" style=""></span>博文</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a href="/posts/notes/" class="nav-link active" aria-label="知识笔记"><span class="font-icon icon iconfont icon-note" style=""></span>知识笔记<!----></a></li><li class="dropdown-item"><a href="/posts/hometown/" class="nav-link" aria-label="泉州忆往昔"><span class="font-icon icon iconfont icon-like" style=""></span>泉州忆往昔<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a href="/timeline/" class="nav-link" aria-label="归档"><span class="font-icon icon iconfont icon-categoryselected" style=""></span>归档<!----></a></div></nav><!--[--><!----><!--]--></div><div class="navbar-end"><!--[--><!----><!--]--><!----><div class="nav-item"><a class="repo-link" href="https://github.com/kevinng77" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><!----><!--[--><button type="button" class="search-pro-button" role="search" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="placeholder">搜索</div><div class="key-hints"><kbd class="key">Ctrl</kbd><kbd class="key">K</kbd></div></button><!--]--><!--[--><!----><!--]--><button type="button" class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside class="sidebar" id="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->对话模型 PLATO 系列论文笔记</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Kevin 吴嘉文</span></span><span property="author" content="Kevin 吴嘉文"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2022-10-05T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 10 分钟</span><meta property="timeRequired" content="PT10M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><span class="page-category-item category7 clickable" role="navigation">知识笔记</span><meta property="articleSection" content="知识笔记"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><span class="page-tag-item tag8 clickable" role="navigation">NLP</span><meta property="keywords" content="NLP"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#plato" class="router-link-active router-link-exact-active toc-link level2">PLATO</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#概述" class="router-link-active router-link-exact-active toc-link level3">概述</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#预训练方法" class="router-link-active router-link-exact-active toc-link level3">预训练方法</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#推理过程" class="router-link-active router-link-exact-active toc-link level3">推理过程</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#模型使用" class="router-link-active router-link-exact-active toc-link level3">模型使用</a></li><!----><!--]--></ul><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#plato-2" class="router-link-active router-link-exact-active toc-link level2">PLATO-2</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#预训练过程" class="router-link-active router-link-exact-active toc-link level3">预训练过程</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#推理" class="router-link-active router-link-exact-active toc-link level3">推理</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#任务式对话" class="router-link-active router-link-exact-active toc-link level3">任务式对话</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#其他" class="router-link-active router-link-exact-active toc-link level3">其他</a></li><!----><!--]--></ul><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#plato-xl" class="router-link-active router-link-exact-active toc-link level2">PLATO-XL</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#模型训练" class="router-link-active router-link-exact-active toc-link level3">模型训练</a></li><!----><!--]--></ul><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#plato-kag" class="router-link-active router-link-exact-active toc-link level2">PLATO-KAG</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#模型训练-1" class="router-link-active router-link-exact-active toc-link level3">模型训练</a></li><!----><!--]--></ul><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/notes/articles/%E7%AC%94%E8%AE%B0plato.html#参考" class="router-link-active router-link-exact-active toc-link level2">参考</a></li><!----><!--]--></ul></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="对话模型-plato-系列论文笔记" tabindex="-1"><a class="header-anchor" href="#对话模型-plato-系列论文笔记" aria-hidden="true">#</a> 对话模型 PLATO 系列论文笔记</h1><p>最近又开始着迷对话系统了，于是花时间看了以下几个中文比较有意思的模型。本文对 PLATO，PLATO=2， PLATO-XL，PLATO-KAG 四篇论文进行笔记梳理与总结。</p><h2 id="plato" tabindex="-1"><a class="header-anchor" href="#plato" aria-hidden="true">#</a> PLATO</h2><p>论文：PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</p><h3 id="概述" tabindex="-1"><a class="header-anchor" href="#概述" aria-hidden="true">#</a> 概述</h3><p>比较早的论文了，论文一上来提出，如果直接使用 Bert 在小规模的对话数据集上微调对话任务，其效果是很差的，基于这些问题，论文给出了几点原因猜测：</p><ul><li>现实对话的分布与训练文本分布的差异是非常大的。</li><li>one-to-many relationship：对于一个问题，在不同场景下，可能可以有多种不同的、正确的回答。而常规的训练过程是一个 one-to-one 对话模式的训练。</li><li>Bert 模型本身对生成任务有局限性。</li></ul><p>针对以上问题，论文提出了以下解决方案：</p><ul><li>在 Reddit 和 Twitter 数据上进行进一步预训练。</li><li>对话过程中，对于同一个问题，在不同场景下可以有不同的回答。因此 PLATO 用一个隐变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mi>K</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">z\in[1,K]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">]</span></span></span></span>，来建模 one-to-many 对话中的信息。隐变量的每个值，都会对应一种特定的对话意图。</li><li>训练时用了 UniLM 的方案，模型采用与 BERT 相似的 Transformer Encoder 模型，训练时用不同掩码来实现不同的优化目标。</li></ul><h3 id="预训练方法" tabindex="-1"><a class="header-anchor" href="#预训练方法" aria-hidden="true">#</a> 预训练方法</h3><p>预训练方法如下，采用 bert-case 作为初始权重。</p><figure><img src="/assets/img/plato/image-20220925175603731.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>如上图，每一步训练都要进行两次前向传播。第一步负责进行 response generation 任务。</p><h4 id="response-generation" tabindex="-1"><a class="header-anchor" href="#response-generation" aria-hidden="true">#</a> response generation</h4><p><strong>输入：</strong> 隐变量 latent，历史对话内容 Context，回复 Response 三者的拼接，如下图。</p><figure><img src="/assets/img/plato/image-20220925180010559.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>其中 Role Embeddings 用于标记说话的角色。(对于包含了外部知识背景的对话内容，如 Duconv 任务，额外知识对应位置的 Role Embedding 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">E_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)。Turn Embedding 用于标记当前对话轮数。</p><p><strong>隐变量的计算</strong></p><p>大致的隐变量计算过程为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>X <span class="token operator">=</span> nn<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token punctuation">[</span>context<span class="token punctuation">,</span>response<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 通过 `context, response` 拼接后的 `embedding`</span>
X <span class="token operator">=</span> gumbel_softmax<span class="token punctuation">(</span>dense<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 形状 `[batch_size, num_latent]` </span>
latent_embedding <span class="token operator">=</span> X<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>embedding_params<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>比较特别的是，在推理阶段，我们采用 <code>argmax</code> 来取代 <code>gumbel_softmax</code>。详细的隐变量计算 <a href="https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L420" target="_blank" rel="noopener noreferrer">参考代码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。</p><p><strong>优化目标：</strong></p><p>采用 UniLM 的训练方式，对 Response 位置对应的输出 hidden state 计算经典的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>N</mi><mi>L</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{NLL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mord mathnormal mtight">LL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p><p>同时对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>B</mi><mi>O</mi><mi>W</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{BOW}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">BO</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行优化。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>B</mi><mi>O</mi><mi>W</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{BOW}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">BO</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 主要思想是，我们希望隐变量位置对应的 hidden state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>z</mi></msub></mrow><annotation encoding="application/x-tex">H_z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，能够预测答案中包含了哪些 <code>token</code>。大致代码思路如下，比较特别的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>z</mi></msub></mrow><annotation encoding="application/x-tex">H_z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 通过一次线性变换后，在计算交叉熵之前被拓展到了 <code>[batch_size, len_pred, num_tokens]</code> 维度，因为最后交叉熵的输入是通过 <code>expand</code> 得来的，因此计算出的 loss 与答案的顺序没有关系。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>label <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">&quot;tgt_token&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># [batch size, len_pred]</span>

self<span class="token punctuation">.</span>bow_predictor <span class="token operator">=</span> FC<span class="token punctuation">(</span>name_scope<span class="token operator">=</span>self<span class="token punctuation">.</span>full_name<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;.bow_predictor&quot;</span><span class="token punctuation">,</span>
                                    size<span class="token operator">=</span>self<span class="token punctuation">.</span>num_token_embeddings<span class="token punctuation">,</span>  
                        <span class="token comment"># &quot;The number of tokens in vocabulary. &quot;</span>
                                    bias_attr<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

bow_logits <span class="token operator">=</span> self<span class="token punctuation">.</span>bow_predictor<span class="token punctuation">(</span>latent_embed<span class="token punctuation">)</span>  <span class="token comment"># [batch size, 1, num_tokens]</span>
outputs<span class="token punctuation">[</span><span class="token string">&quot;bow_probs&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> layers<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>bow_logits<span class="token punctuation">)</span>  <span class="token comment"># [batch size, 1, num_tokens]</span>

bow_probs <span class="token operator">=</span> F<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token string">&quot;bow_probs&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># [batch size, len_pred, num_tokens]</span>
bow_probs <span class="token operator">=</span> layers<span class="token punctuation">.</span>expand<span class="token punctuation">(</span>bow_probs<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  
<span class="token keyword">if</span> self<span class="token punctuation">.</span>label_smooth <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
    bow <span class="token operator">=</span> layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>bow_probs<span class="token punctuation">,</span> smooth_label<span class="token punctuation">,</span> soft_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               ignore_index<span class="token operator">=</span>self<span class="token punctuation">.</span>padding_idx<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    bow <span class="token operator">=</span> layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>bow_probs<span class="token punctuation">,</span> label<span class="token punctuation">,</span> ignore_index<span class="token operator">=</span>self<span class="token punctuation">.</span>padding_idx<span class="token punctuation">)</span>
            bow <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>bow<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            token_bow <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>bow<span class="token punctuation">)</span> <span class="token operator">/</span> tgt_len
            bow <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>bow<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>详细代码可以参考 <a href="https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L482" target="_blank" rel="noopener noreferrer">PLATO 源码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h4 id="response-selection" tabindex="-1"><a class="header-anchor" href="#response-selection" aria-hidden="true">#</a> <strong>Response Selection</strong></h4><p>二分类任务，通过输入隐变量位置对应的 logits,计算交叉熵，文中对这个优化目标记为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>R</mi><mi>S</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{RS}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RS</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。对于一个问答对，其正例就是本身，而负例侧是在无关的语料库中，随机的一个答案。在 <a href="https://github.com/sserdoubleh/Research/blob/b8ec015fa9e16c0a879c619ee1f2aab8a393c7bd/NLP/Dialogue-PLATO/plato/models/unified_transformer.py#L338" target="_blank" rel="noopener noreferrer">plato<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> 源码中可以发现，负例是在训练过程中创建的，即简单的采用同一个 batch 下除自身以外的其他样本作为负例。</p><p>而后通过隐变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> 对应位置的 hidden state（正样本和负样本各自有一个 hidden state）计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>R</mi><mi>S</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{RS}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RS</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 损失为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>R</mi><mi>S</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mrow><mo fence="true">(</mo><msub><mi>l</mi><mi>r</mi></msub><mo>=</mo><mn>1</mn><mo>∣</mo><mi>c</mi><mo separator="true">,</mo><mi>r</mi><mo fence="true">)</mo></mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mrow><mo fence="true">(</mo><msub><mi>l</mi><msup><mi>r</mi><mo lspace="0em" rspace="0em">−</mo></msup></msub><mo>=</mo><mn>0</mn><mo>∣</mo><mi>c</mi><mo separator="true">,</mo><msup><mi>r</mi><mo lspace="0em" rspace="0em">−</mo></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex"> \mathcal{L}_{R S}=-\log p\left(l_r=1 \mid c, r\right)-\log p\left(l_{r^{-}}=0 \mid c, r^{-}\right) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RS</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3419em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8213em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></p><p><strong>总体优化目标</strong></p><p>总体的优化目标为以上介绍的三个损失的加权平均：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mrow><mi>N</mi><mi>L</mi><mi>L</mi></mrow></msub><mo>+</mo><msub><mi>L</mi><mrow><mi>B</mi><mi>O</mi><mi>W</mi></mrow></msub><mo>+</mo><msub><mi>L</mi><mrow><mi>R</mi><mi>S</mi></mrow></msub></mrow><annotation encoding="application/x-tex"> L = L_{NLL} + L_{BOW} + L_{RS} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mord mathnormal mtight">LL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">BO</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RS</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p><p>论文中没有提三个损失的权重，源码中有用于调整各个 loss 的超参，不过这些超参默认值都是 1。整个预训练用了 8 张 V100(32G) 训练了 2 周 。具体参数可以参考原论文。</p><h3 id="推理过程" tabindex="-1"><a class="header-anchor" href="#推理过程" aria-hidden="true">#</a> 推理过程</h3><p>对于一个历史对话 <code>context</code>：</p><ul><li>首先给 <code>context</code> 添加上不同类型的 <code>latent_embed</code>。原本输入为 <code>batch size</code> 条，变换后，变成了 <code>batch size * num_latent</code> 条。</li><li>对 <code>batch_size * num_latent</code> 条输入分别进行预测，得到所有 latent 对应的回复 。</li><li>通过 Response selection 阶段训练的判别器，对所有生成进行打分，选取分数高的作为最终回复。</li></ul><h3 id="模型使用" tabindex="-1"><a class="header-anchor" href="#模型使用" aria-hidden="true">#</a> 模型使用</h3><p>PLATO 采用 <code>UnifiedTransformerModel</code>。对应的使用方法在 PaddleNLP 中可查看到。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> paddlenlp<span class="token punctuation">.</span>transformers <span class="token keyword">import</span> UnifiedTransformerModel
<span class="token keyword">from</span> paddlenlp<span class="token punctuation">.</span>transformers <span class="token keyword">import</span> UnifiedTransformerTokenizer

model <span class="token operator">=</span> UnifiedTransformerModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;plato-mini&#39;</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> UnifiedTransformerTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;plato-mini&#39;</span><span class="token punctuation">)</span>

history <span class="token operator">=</span> <span class="token string">&#39;我爱祖国&#39;</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>dialogue_encode<span class="token punctuation">(</span>
    history<span class="token punctuation">,</span>
    return_tensors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    is_split_into_words<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="plato-2" tabindex="-1"><a class="header-anchor" href="#plato-2" aria-hidden="true">#</a> PLATO-2</h2><p>来自论文 PLATO-2: Towards Building an OpeDomain Chatbot via Curriculum Learning</p><p>PLATO-2 为 PLATO 升级版，除了模型规模不同外，其与 PLATO 的主要差别在于预训练的方式。此外 PLATO-2 用的是依旧是 Transformer encoder 架构，但是采用了 <code>pre-normalization</code>。</p><p>PLATO-2 效果如下：</p><figure><img src="/assets/img/plato/image-20221002115449356.png" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><h3 id="预训练过程" tabindex="-1"><a class="header-anchor" href="#预训练过程" aria-hidden="true">#</a> 预训练过程</h3><p>文中提出了 curriculum learning 的预训练方案。</p><h4 id="step-1" tabindex="-1"><a class="header-anchor" href="#step-1" aria-hidden="true">#</a> Step 1</h4><figure><img src="/assets/img/plato/image-20220928103258849.png" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>不采用 latent embedding， 直接利用 UniLM 的方式，在正常的生成任务上优化传统的 NLL loss。</p><h4 id="step-2-1" tabindex="-1"><a class="header-anchor" href="#step-2-1" aria-hidden="true">#</a> Step 2.1</h4><figure><img src="/assets/img/plato/image-20220928103320587.png" alt="相关图片" height="300" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>首先计算 <code>latent_embed</code>，该操作于 PLATO 不同。PLATO 中计算 <code>latent_embed</code> 的方式大致为：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x <span class="token operator">=</span> nn<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token punctuation">[</span>context<span class="token punctuation">,</span> response<span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> gumbel_softmax<span class="token punctuation">(</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
latent_embed <span class="token operator">=</span> x<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>latent_embed_params<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而 PLATO-2 则采用了</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token punctuation">[</span>context<span class="token punctuation">,</span> response<span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> gumbel_softmax<span class="token punctuation">(</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
latent_embed <span class="token operator">=</span> x<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>latent_embed_params<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>差别就在于计算 <code>x</code> 过程中，PLATO-2 用的是整个 encoder 进行编码，这也会更耗时。</p><p>得到 <code>latent_embed</code> 之后，我们对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>N</mi><mi>L</mi><mi>L</mi></mrow></msub><mo>+</mo><msub><mi>L</mi><mrow><mi>B</mi><mi>O</mi><mi>W</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{NLL} + L_{BOW}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mord mathnormal mtight">LL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">BO</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行优化， <strong>优化方法与 PLATO 相同。</strong> <a href="https://github.com/PaddlePaddle/Knover/blob/ab547f0ba03c9142183d97c2ee6ed7a1c3750125/knover/models/plato.py#L151" target="_blank" rel="noopener noreferrer">参考代码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h4 id="step-2-2" tabindex="-1"><a class="header-anchor" href="#step-2-2" aria-hidden="true">#</a> Step 2.2</h4><figure><img src="/assets/img/plato/image-20220928103339039.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>额外训练一个打分器，如图所示，优化的目标和 BERT 预训练时相同，为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>M</mi><mi>L</mi><mi>M</mi></mrow></msub><mo>+</mo><msub><mi>L</mi><mrow><mi>N</mi><mi>S</mi><mi>P</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{MLM} + L_{NSP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">NSP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>N</mi><mi>S</mi><mi>P</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{NSP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">NSP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 与图中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>R</mi><mi>C</mi><mi>E</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{RCE}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">RCE</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 大同小异，原理都是预测 <code>Response</code> 是否为 <code>Context</code> 的下一句话。</p><p>该步骤与 PLATO 中的 Response Selection 对应，只是在 PLATO-2 中，优化目标多了一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>M</mi><mi>L</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{MLM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><h3 id="推理" tabindex="-1"><a class="header-anchor" href="#推理" aria-hidden="true">#</a> 推理</h3><p>推理过程同 PLATO，先生成所有 latent 对应的回复，然后在用 step 2.2 训练来的打分器打分。</p><h3 id="任务式对话" tabindex="-1"><a class="header-anchor" href="#任务式对话" aria-hidden="true">#</a> 任务式对话</h3><p>PLATO-2 在 DSTC9 的部分任务上表现出色，百度也对 PLATO-2 在该任务上的操作提供了论文。相关论文：Learning to Select External Knowledge with Multi-Scale Negative Sampling. <a href="https://arxiv.org/abs/2102.02096" target="_blank" rel="noopener noreferrer">Paper link<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>网友的笔记<a href="https://zhuanlan.zhihu.com/p/423748187" target="_blank" rel="noopener noreferrer">参考链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h3 id="其他" tabindex="-1"><a class="header-anchor" href="#其他" aria-hidden="true">#</a> 其他</h3><p>有网友提到第一阶段的预训练花了 1.8M 个 STEP，LOSS 仅下降到 2.66。作者建议 24L 模型的学习率可以用 5e-4 或者更大，Knover 中 24L PLATO 默认的学习率是 <code>1e-3</code>。</p><p>论文 STEP 2 采用了多种学习方案，但是并没有消融实验。此外作者并没有公布中文数据集的具体来源。隐约感觉，PLATO-2 的好效果绝大部分来源于语料？</p><p>PLATO-2 的 ISSUE 中提到，论文中 table 6 的 batch size 是根据 token 数量来计算的。源码中给到的 batch size 是 8169，通过语料的平均 token 长度换算过来的话，源码中的 batch size 会稍微大一些。</p><p>PLATO-2 的预训练权重目前只开源了英文版的，想要中文版的话只能自己收集中文数据集训练了。</p><h2 id="plato-xl" tabindex="-1"><a class="header-anchor" href="#plato-xl" aria-hidden="true">#</a> PLATO-XL</h2><p>来自论文 PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation</p><p>PLATO-XL 仍然采用于 PLATO-2 相同的架构，只是规模变大了，训练方法和预料也有所不同。 PLATO-XL 的训练代码似乎并没有开源，仅英文预训练权重有开源。论文中大致介绍了大模型效果更好，以及一些大模型训练及推理的解决方案。相比于 PLATO-2，PLATO-XL 似乎想说明：花里胡哨的训练，不如大模型，好语料来的管用。</p><h3 id="模型训练" tabindex="-1"><a class="header-anchor" href="#模型训练" aria-hidden="true">#</a> 模型训练</h3><p>模型的优化目标只剩下一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>N</mi><mi>L</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{NLL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mord mathnormal mtight">LL</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 了。</p><p>相比于 PLATO-2，PLATO-XL 的训练预料中，考虑到了多人对话的场景。因此文章提出了 Multi-Party Aware Pre-training，即在 <code>role_embedding</code> 中区分 2 个以上的角色（在 PLATO-2 中，只有机器和用户两个角色，因此只用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">E_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">E_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行区分）。</p><p>由于模型规模大，因此 <code>pre-normalization</code> 和 <code>scaled_initialization</code> 都被采用了，以此提高训练效果。整个训练用了 256 张 V100 32G，训练周期未知。效果如下图：</p><figure><img src="/assets/img/plato/image-20220928214127388.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>由于 PLATO-XL 模型较大，paddle 官方采用了 PaddleNLP FasterGeneration 进行高性能预测。<a href="https://github.com/PaddlePaddle/PaddleNLP/blob/develop/model_zoo/plato-xl/infer.py" target="_blank" rel="noopener noreferrer">参考代码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="plato-kag" tabindex="-1"><a class="header-anchor" href="#plato-kag" aria-hidden="true">#</a> PLATO-KAG</h2><p>来自论文 PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling。</p><p>相比于之前 PLATO 系列论文，该文主要介绍如何使用 PLATO 架构来进行具备额外知识信息的问答。<a href="https://github.com/PaddlePaddle/Knover/blob/develop/knover/models/plato_kag.py" target="_blank" rel="noopener noreferrer">代码链接<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h3 id="模型训练-1" tabindex="-1"><a class="header-anchor" href="#模型训练-1" aria-hidden="true">#</a> 模型训练</h3><p>模型训练流程如下，整个模型采用 PLATO-2 的权重进行初始化。</p><figure><img src="/assets/img/plato/image-20220929105506250.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p><strong>Knowledge Selection</strong></p><p>用同一个编码器编码 <code>Context</code> 以及 <code>Knowledge</code> 片段，得到隐状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span>。而后通过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>c</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>c</mi></msub><mi>E</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo stretchy="false">(</mo><msub><mi>W</mi><mi>z</mi></msub><mi>E</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(c,z) = (W_cE(c))^T(W_zE(z))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">))</span></span></span></span> 计算 <code>context</code> 和 <code>knowledge</code> 片段的相似度。</p><p>在计算损失时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>c</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(c,z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 计算 <code>softmax</code>，而后只对 Top K 个 <code>knowledge</code> 对应的 <code>softmax</code> 进行优化。</p><p>论文中对 不同的 K 值进行了测试，结果展示了，在训练时选择 Top 8 个相关知识片段进行训练，模型最终的 PPL 和 Recall 都会更好。</p><figure><img src="/assets/img/plato/image-20221005143858830.png" alt="相关图片" tabindex="0" loading="lazy"><figcaption>相关图片</figcaption></figure><p>但是 K 越大，对应的训练资源要求就越大，实验中 <code>k=2</code> 时，其效果也不比 <code>k=8</code> 小多少。</p><p><strong>Response Generation</strong></p><p>由于上一个任务中，选出了 Top K 个可能合适的知识片段，因此在生成任务中，我们需要对这些片段逐一进行拼接、预测和优化。</p><p>如原输入形状为 <code>[batch_size, len_seq]</code>， 那么训练过程中预测结果的形状就会是 <code>[batch_size * K, len_seq]</code></p><p><strong>Balanced Joint Training</strong></p><p>训练过程中，同时对 Knowledge Selection 和 Response Generation 进行优化。<a href="https://github.com/PaddlePaddle/Knover/blob/develop/knover/models/plato_kag.py#L343" target="_blank" rel="noopener noreferrer">参考代码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>文中提到了使用超参 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 来调整两个损失之间的权重，即整个优化目标为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>r</mi><mo>∣</mo><mi>c</mi><mo stretchy="false">)</mo><mo>∝</mo><munder><mo>∑</mo><mi>z</mi></munder><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo>∣</mo><mi>c</mi><mo stretchy="false">)</mo><msup><mrow><mo fence="true">(</mo><munderover><mo>∏</mo><mi>t</mi><mi>T</mi></munderover><msub><mi>p</mi><mi>ϕ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>∣</mo><mi>c</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">,</mo><msub><mi>r</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mi>α</mi></msup></mrow><annotation encoding="application/x-tex"> p(r \mid c) \propto \sum_z p_\theta(z \mid c)\left(\prod_t^T p_\phi\left(r_t \mid c, z, r_{&lt;t}\right)\right)^\alpha </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3em;vertical-align:-1.25em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.9em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1327em;vertical-align:-1.25em;"></span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.9em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.8826em;"><span style="top:-4.2812em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>c</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(z|c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal">c</span><span class="mclose">)</span></span></span></span> 为 Knowledge Selection 对应的概率。生成任务的概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∏</mo><mi>t</mi><mi>T</mi></msubsup><msub><mi>p</mi><mi>ϕ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>r</mi><mi>t</mi></msub><mo>∣</mo><mi>c</mi><mo separator="true">,</mo><mi>z</mi><mo separator="true">,</mo><msub><mi>r</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\prod_t^T p_\phi\left(r_t \mid c, z, r_{&lt;t}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 参数来调整。</p><p>但是在 Knover 的源代码中，笔者并没有找到这个设置，整个 PLATO-KAG 训练过程仅是简单地将 Knowledge Selection 任务和 Response Generation 任务权重简单地做了相加。</p><p>此外，模型采用 PLATO-2 的预训练权重初始化。</p><p>在推理过程中，仅仅选择相似度最高的 <code>knowledge</code> 片段进行推理。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考" aria-hidden="true">#</a> 参考</h2><p>[1] <a href="http://arxiv.org/abs/2112.12441" target="_blank" rel="noopener noreferrer">TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue Modeling on Spoken Conversations<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[2] <a href="http://arxiv.org/abs/2102.02096" target="_blank" rel="noopener noreferrer">Learning to Select External Knowledge with Multi-Scale Negative Sampling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[3] <a href="https://aclanthology.org/2021.nlp4convai-1.14" target="_blank" rel="noopener noreferrer">PLATO-KAG: Unsupervised Knowledge-Grounded Conversation via Joint Modeling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[4] <a href="http://arxiv.org/abs/2109.09519" target="_blank" rel="noopener noreferrer">PLATO-XL: Exploring the Large-scale Pre-training of Dialogue Generation<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[5] <a href="https://www.aclweb.org/anthology/2020.acl-main.9" target="_blank" rel="noopener noreferrer">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>[6] <a href="http://arxiv.org/abs/2006.16779" target="_blank" rel="noopener noreferrer">PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></div><!----><footer class="page-meta"><!----><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 417333277@qq.com">kevinng77</span><!--]--><!--]--></div></div></footer><!----><!----><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer"><a href="https://beian.miit.gov.cn/" target="_blank">闽ICP备2020021116号</a>&nbsp;<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=" target="_blank"><img src="/assets/gongan.png">闽公网安备 35058102000231号 </a></div><div class="copyright">Copyright © 2023 Kevin 吴嘉文</div></footer></div><!--]--><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-16d0ff63.js" defer></script>
  </body>
</html>
